第一次执行op
是调tf.matmul()中的ops.convert_to_tensor(a, name="a")
如下log是已经执行了context.ensure_initialized()方法
然后执行'ops.EagerTensor(value, ctx.device_name, dtype)'
此时打印如下log:
2023-01-12 09:21:35.364661: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-01-12 09:21:35.366132: I tensorflow/compiler/jit/xla_cpu_device.cc:58] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-01-12 09:21:35.366637: I tensorflow/core/common_runtime/process_util.cc:159] Session inter op parallelism threads: 8
2023-01-12 09:21:35.368988: I ./tensorflow/core/common_runtime/eager/context.h:603] Creating rendezvous using local_device_mgr.
2023-01-12 09:25:07.707794: I tensorflow/core/common_runtime/eager/context.cc:518] ContextDevicePlacementPolicy not found; returning default.
2023-01-12 09:34:36.793712: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogRawAllocation { step_id: -3 operation: "TF_NewTensor" num_bytes: 72 ptr: 94667549657600 allocation_id: 1 allocator_name: "cpu" }
2023-01-12 09:34:36.804997: I tensorflow/core/common_runtime/eager/tensor_handle.cc:253] Creating Local TensorHandle: 0x56197e5a2bf0 device: [] tensor: Tensor<type: double shape: [3,3]>
2023-01-12 09:34:36.817885: I tensorflow/core/common_runtime/eager/execute.cc:1795] op: _EagerConst is not Async.
2023-01-12 09:34:36.818810: I tensorflow/core/common_runtime/eager/context.cc:743] RunEagerOpAsFunction: 1
2023-01-12 09:34:37.252380: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "NOT_FOUND: /root/.vscode-server/extensions/ms-python.python-2022.20.1/pythonFiles/lib/python/debugpy/adapter/../../debugpy/launcher/../../debugpy.runfiles/org_tensorflow not found". *** Begin stack trace ***
        tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
        tsl::Status tsl::errors::NotFound<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*)
        tsl::PosixFileSystem::FileExists(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tsl::TransactionToken*)
        tsl::FileSystem::FileExists(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
        tsl::FileSystem::IsDirectory(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tsl::TransactionToken*)
        tsl::FileSystem::IsDirectory(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
        tsl::Env::IsDirectory(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
        ....
        tensorflow::LoadDynamicKernelsInternal()
        void std::__invoke_impl<void, void (&)()>(std::__invoke_other, void (&)())
        std::__invoke_result<void (&)()>::type std::__invoke<void (&)()>(void (&)())
        std::invoke_result<void (&)()>::type std::invoke<void (&)()>(void (&)())
        void absl::lts_20220623::base_internal::CallOnceImpl<void (&)()>(std::atomic<unsigned int>*, absl::lts_20220623::base_internal::SchedulingMode, void (&)())
        void absl::lts_20220623::call_once<void (&)()>(absl::lts_20220623::once_flag&, void (&)())
        tensorflow::LoadDynamicKernels()
        ....
        tensorflow::SupportedDeviceTypesForNode() tensorflow/core/framework/op_kernel.cc //BT设备 返回该节点上支持该op的设备,按某种优先级排序
        tensorflow::EagerContext::SelectDevice(preferredDevice,nodeDef,output) tensorflow/core/common_runtime/eager/context.cc:355
                                                      //BT设备 
                                                        三个设备来源:传入的 preferredDevice;SupportedDeviceTypesForNode()得到的节点支持该op的所有设备;'pflr_device_set->prioritized_devices()'???得到的existingDevices;
                                                        通过context.cc.SelectBestMatchingDevice()找合适的设备
                                                        若第一次找不到合适的,则考虑'AllowSoftPlacement()'去找合适的设备
        ....SetOpDevice() tensorflow/core/common_runtime/eager/execute.cc:1034//BT设备
        ....GetOrCreateKernelAndDevice() tensorflow/core/common_runtime/eager/execute.cc:1064
        ....EagerLocalExecute() tensorflow/core/common_runtime/eager/execute.cc:1411
72分支点 tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)tensorflow/core/common_runtime/eager/execute.cc:1816
        tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)tensorflow/core/common_runtime/eager/core.cc:190 //BT设备 尝试获取device,但不确定这里能否拿到???
        tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)tensorflow/core/common_runtime/eager/custom_device_op_handler.cc:55
        TFE_Execute tensorflow/c/eager/c_api.cc:886
        tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*) tensorflow/python/eager/pywrap_tensor.cc:280 
                                                    //BT算子 
                                                      创建EagerOperation:tensorflow/c/eager/c_api.cc:629.TFE_NewOp()>'unwrap(ctx)->CreateOperation()'>tensorflow/core/common_runtime/eager/core.cc.EagerContext::CreateOperation()
                                                      设置operation的相关属性:TFE_OpSetDevice,TFE_OpAddInput,TFE_OpSetAttrType, //BT设备 BT张量
        tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*) tensorflow/python/eager/pywrap_tensor.cc:288 
                                                    //BT张量 
                                                    创建包含了Tensor的TensorHandle:tensorflow/python/lib/core/py_seq_tensor.cc.PySeqToTFE_TensorHandle>'FloatConverter::Convert(ctx, obj, &state, &handle, &error)'
                                                      其实就是调EagerCtx中类似CreateFloatScalar()的方法创建Tensor然后把Tensor通过类似CreateLocalHandle()的方法封装到TensorHandle中返回,最终拿到的是可操作Tensor的TensorHandle
        tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*) tensorflow/python/eager/pywrap_tensor.cc:389 //BTBT 从缓存取TensorHandler,若没有则调ConvertToEagerTensorUncached.  ??? TFE_TensorHandleCache的K和V是什么
        EagerTensor_init  tensorflow/python/eager/pywrap_tensor.cc:498//BTBT 转py传入的参数和Ctx

*** End stack trace ***

2023-01-12 09:34:37.353427: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "NOT_FOUND: /root/.vscode-server/extensions/ms-python.python-2022.20.1/pythonFiles/lib/python/debugpy/adapter/../../debugpy/launcher/../../tensorflow/core/kernels; No such file or directory". *** Begin stack trace ***

        tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
        tsl::errors::IOError(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, int)
        tsl::PosixFileSystem::GetChildren(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tsl::TransactionToken*, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >*)
        tsl::FileSystem::GetChildren(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >*)
        tsl::Env::GetChildren(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >*)
        tensorflow::LoadDynamicKernelsInternal()
        void std::__invoke_impl<void, void (&)()>(std::__invoke_other, void (&)())
        std::__invoke_result<void (&)()>::type std::__invoke<void (&)()>(void (&)())
        std::invoke_result<void (&)()>::type std::invoke<void (&)()>(void (&)())
        void absl::lts_20220623::base_internal::CallOnceImpl<void (&)()>(std::atomic<unsigned int>*, absl::lts_20220623::base_internal::SchedulingMode, void (&)())
        void absl::lts_20220623::call_once<void (&)()>(absl::lts_20220623::once_flag&, void (&)())
        tensorflow::LoadDynamicKernels()
        ....
        tensorflow::SupportedDeviceTypesForNode(std::vector<tsl::DeviceType, std::allocator<tsl::DeviceType> > const&, tensorflow::NodeDef const&, absl::lts_20220623::InlinedVector<std::pair<tsl::DeviceType, int>, 4ul, std::allocator<std::pair<tsl::DeviceType, int> > >*, tensorflow::DeviceNameUtils::ParsedName const*)
        tensorflow::EagerContext::SelectDevice(tensorflow::DeviceNameUtils::ParsedName, tensorflow::NodeDef const&, tensorflow::Device**) const
        ....同上
        tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
        tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
        tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
        TFE_Execute
        tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
        tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
        tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
        EagerTensor_init
        _PyObject_MakeTpCall
        _PyEval_EvalFrameDefault

        _PyFunction_Vectorcall

        _PyEval_EvalFrameDefault

        _PyFunction_Vectorcall

        _PyEval_EvalFrameDefault

        _PyFunction_Vectorcall

        _PyEval_EvalFrameDefault

        _PyFunction_Vectorcall

        _PyEval_EvalFrameDefault

        _PyFunction_Vectorcall

        _PyEval_EvalFrameDefault

        _PyFunction_Vectorcall
        PyObject_Call
        _PyEval_EvalFrameDefault

        _PyFunction_Vectorcall

        _PyEval_EvalFrameDefault

        _PyFunction_Vectorcall
        _PyEval_EvalFrameDefault

        _PyFunction_Vectorcall
        _PyEval_EvalFrameDefault

        _PyFunction_Vectorcall

        _PyEval_EvalFrameDefault


        PyEval_EvalCode



        _PyEval_EvalFrameDefault

        _PyFunction_Vectorcall

        _PyEval_EvalFrameDefault

        _PyFunction_Vectorcall

        _PyEval_EvalFrameDefault

        _PyFunction_Vectorcall

        _PyEval_EvalFrameDefault
        _PyFunction_Vectorcall
        _PyEval_EvalFrameDefault
        _PyFunction_Vectorcall
        _PyEval_EvalFrameDefault

        PyEval_EvalCode


        _PyEval_EvalFrameDefault
        _PyFunction_Vectorcall
        _PyEval_EvalFrameDefault
        _PyFunction_Vectorcall

        Py_RunMain
        Py_BytesMain

        __libc_start_main
        _start
*** End stack trace ***

2023-01-12 09:34:37.459295: I tensorflow/core/common_runtime/eager/execute.cc:1036] PreferredDevice _EagerConst: /job:localhost/replica:0/task:0
2023-01-12 09:34:37.459385: I tensorflow/core/common_runtime/eager/execute.cc:1037] Placer place op [_EagerConst] on device: /job:localhost/replica:0/task:0/device:CPU:0
2023-01-12 09:34:37.465031: I tensorflow/core/common_runtime/eager/execute.cc:1039] Available kernels for _EagerConst are  device='GPU'; T in [DT_BOOL]
  device='GPU'; T in [DT_VARIANT]
  device='GPU'; T in [DT_COMPLEX128]
  device='GPU'; T in [DT_COMPLEX64]
  device='GPU'; T in [DT_INT8]
  device='GPU'; T in [DT_UINT8]
  device='GPU'; T in [DT_INT16]
  device='GPU'; T in [DT_UINT16]
  device='GPU'; T in [DT_UINT32]
  device='GPU'; T in [DT_INT64]
  device='GPU'; T in [DT_UINT64]
  device='GPU'; T in [DT_DOUBLE]
  device='GPU'; T in [DT_FLOAT]
  device='GPU'; T in [DT_BFLOAT16]
  device='GPU'; T in [DT_HALF]
  device='CPU'
  device='DEFAULT'; T in [DT_RESOURCE]
  device='DEFAULT'; T in [DT_STRING]
  device='DEFAULT'; T in [DT_INT32]
  device='DEFAULT'; T in [DT_BOOL]
  device='DEFAULT'; T in [DT_VARIANT]
  device='DEFAULT'; T in [DT_COMPLEX128]
  device='DEFAULT'; T in [DT_COMPLEX64]
  device='DEFAULT'; T in [DT_INT8]
  device='DEFAULT'; T in [DT_UINT8]
  device='DEFAULT'; T in [DT_INT16]
  device='DEFAULT'; T in [DT_UINT16]
  device='DEFAULT'; T in [DT_UINT32]
  device='DEFAULT'; T in [DT_INT64]
  device='DEFAULT'; T in [DT_UINT64]
  device='DEFAULT'; T in [DT_DOUBLE]
  device='DEFAULT'; T in [DT_FLOAT]
  device='DEFAULT'; T in [DT_BFLOAT16]
  device='DEFAULT'; T in [DT_HALF]

2023-01-12 09:34:37.465405: I tensorflow/core/common_runtime/eager/context.cc:743] RunEagerOpAsFunction: 1
2023-01-12 09:34:37.465652: I tensorflow/core/common_runtime/eager/context.cc:743] RunEagerOpAsFunction: 1
2023-01-12 09:34:37.465985: I tensorflow/core/common_runtime/eager/execute.cc:987] _EagerConst:input:0 /job:localhost/replica:0/task:0/device:CPU:0
2023-01-12 09:34:37.550549: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "NOT_FOUND: Unknown composite device: /job:localhost/replica:0/task:0/device:CPU:0". *** Begin stack trace ***

        tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)

        tensorflow::EagerContext::FindCompositeDeviceFromName(std::basic_string_view<char, std::char_traits<char> >, tensorflow::CompositeDevice**) const



        tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
        tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
        tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
        TFE_Execute
        tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
        tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
        tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
        EagerTensor_init
*** End stack trace ***

2023-01-12 09:34:37.550734: I tensorflow/core/common_runtime/eager/context.cc:743] RunEagerOpAsFunction: 1
2023-01-12 09:34:37.550771: I tensorflow/core/common_runtime/eager/execute.cc:923] ctx.RunEagerOpAsFunction(): 1
2023-01-12 09:34:37.550783: I tensorflow/core/common_runtime/eager/context.cc:743] RunEagerOpAsFunction: 1
2023-01-12 09:34:37.550812: I tensorflow/core/common_runtime/eager/context.cc:743] RunEagerOpAsFunction: 1
2023-01-12 09:34:37.550879: I tensorflow/core/common_runtime/eager/execute.cc:1118] Creating new kernel for _EagerConst on device /job:localhost/replica:0/task:0/device:CPU:0
2023-01-12 09:34:37.550916: I tensorflow/core/common_runtime/eager/execute.cc:1143] _EagerConst function_outputs_on_op_device: 0
2023-01-12 09:34:37.550951: I tensorflow/core/common_runtime/eager/execute.cc:1148] Device for [_EagerConst] already set to: /job:localhost/replica:0/task:0/device:CPU:0
2023-01-12 09:34:37.550996: I tensorflow/core/common_runtime/eager/context.cc:743] RunEagerOpAsFunction: 1
2023-01-12 09:34:37.563607: I tensorflow/core/common_runtime/eager/execute.cc:858] 
signature {
  name: "__wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0"
  input_arg {
    name: "input"
    type_attr: "T"
  }
  output_arg {
    name: "output"
    type_attr: "T"
  }
  attr {
    name: "T"
    type: "type"
  }
}
node_def {
  name: "_EagerConst"
  op: "_EagerConst"
  input: "input:0"
  device: "/job:localhost/replica:0/task:0/device:CPU:0"
  attr {
    key: "T"
    value {
      placeholder: "T"
    }
  }
}
ret {
  key: "output"
  value: "_EagerConst:output:0"
}

2023-01-12 09:34:37.589366: I tensorflow/core/framework/op.cc:130] All registered Ops:
  2023-01-12 09:34:37.589575: I tensorflow/core/framework/op.cc:132] Op<name=A; signature= -> out:float>
  2023-01-12 09:34:37.589677: I tensorflow/core/framework/op.cc:132] Op<name=Abort; signature= -> ; attr=error_msg:string,default=""; attr=exit_without_error:bool,default=false>
  2023-01-12 09:34:37.589770: I tensorflow/core/framework/op.cc:132] Op<name=Abs; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT8, DT_INT16, DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.591061: I tensorflow/core/framework/op.cc:132] Op<name=AccumulateNV2; signature=inputs:N*T -> sum:T; attr=N:int,min=1; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=shape:shape; is_commutative=true; is_aggregate=true>
  2023-01-12 09:34:37.591176: I tensorflow/core/framework/op.cc:132] Op<name=AccumulatorApplyGradient; signature=handle:Ref(string), local_step:int64, gradient:dtype -> ; attr=dtype:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:37.591263: I tensorflow/core/framework/op.cc:132] Op<name=AccumulatorNumAccumulated; signature=handle:Ref(string) -> num_accumulated:int32>
  2023-01-12 09:34:37.591340: I tensorflow/core/framework/op.cc:132] Op<name=AccumulatorSetGlobalStep; signature=handle:Ref(string), new_global_step:int64 -> >
  2023-01-12 09:34:37.591386: I tensorflow/core/framework/op.cc:132] Op<name=AccumulatorTakeGradient; signature=handle:Ref(string), num_required:int32 -> average:dtype; attr=dtype:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:37.591470: I tensorflow/core/framework/op.cc:132] Op<name=Acos; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT8, DT_INT16, DT_INT32, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.591503: I tensorflow/core/framework/op.cc:132] Op<name=Acosh; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.591528: I tensorflow/core/framework/op.cc:132] Op<name=Add; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_INT16, DT_INT32, DT_INT64, DT_COMPLEX64, DT_COMPLEX128, DT_STRING]>
  2023-01-12 09:34:37.591551: I tensorflow/core/framework/op.cc:132] Op<name=AddManySparseToTensorsMap; signature=sparse_indices:int64, sparse_values:T, sparse_shape:int64 -> sparse_handles:int64; attr=T:type; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.591584: I tensorflow/core/framework/op.cc:132] Op<name=AddN; signature=inputs:N*T -> sum:T; attr=N:int,min=1; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 16534343205130372495, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64, DT_VARIANT]; is_commutative=true; is_aggregate=true>
  2023-01-12 09:34:37.591607: I tensorflow/core/framework/op.cc:132] Op<name=AddSparseToTensorsMap; signature=sparse_indices:int64, sparse_values:T, sparse_shape:int64 -> sparse_handle:int64; attr=T:type; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.591627: I tensorflow/core/framework/op.cc:132] Op<name=AddV2; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_UINT16, DT_UINT32, DT_UINT64, DT_INT8, DT_INT16, DT_INT32, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]; is_commutative=true; is_aggregate=true>
  2023-01-12 09:34:37.591655: I tensorflow/core/framework/op.cc:132] Op<name=AdjustContrast; signature=images:T, contrast_factor:float, min_value:float, max_value:float -> output:float; attr=T:type,allowed=[DT_UINT8, DT_INT8, DT_INT16, DT_INT32, DT_INT64, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.591672: I tensorflow/core/framework/op.cc:132] Op<name=AdjustContrastv2; signature=images:T, contrast_factor:float -> output:T; attr=T:type,default=DT_FLOAT,allowed=[DT_HALF, DT_FLOAT]>
  2023-01-12 09:34:37.591688: I tensorflow/core/framework/op.cc:132] Op<name=AdjustHue; signature=images:T, delta:float -> output:T; attr=T:type,default=DT_FLOAT,allowed=[DT_HALF, DT_FLOAT]>
  2023-01-12 09:34:37.591715: I tensorflow/core/framework/op.cc:132] Op<name=AdjustSaturation; signature=images:T, scale:float -> output:T; attr=T:type,default=DT_FLOAT,allowed=[DT_HALF, DT_FLOAT]>
  2023-01-12 09:34:37.591732: I tensorflow/core/framework/op.cc:132] Op<name=All; signature=input:bool, reduction_indices:Tidx -> output:bool; attr=keep_dims:bool,default=false; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.591751: I tensorflow/core/framework/op.cc:132] Op<name=AllCandidateSampler; signature=true_classes:int64 -> sampled_candidates:int64, true_expected_count:float, sampled_expected_count:float; attr=num_true:int,min=1; attr=num_sampled:int,min=1; attr=unique:bool; attr=seed:int,default=0; attr=seed2:int,default=0; is_stateful=true>
  2023-01-12 09:34:37.591807: I tensorflow/core/framework/op.cc:132] Op<name=AllToAll; signature=input:T, group_assignment:int32 -> output:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 16534343205130372495, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64, DT_BOOL]; attr=concat_dimension:int; attr=split_dimension:int; attr=split_count:int; is_stateful=true>
  2023-01-12 09:34:37.591878: I tensorflow/core/framework/op.cc:132] Op<name=Angle; signature=input:T -> output:Tout; attr=T:type,default=DT_COMPLEX64,allowed=[DT_COMPLEX64, DT_COMPLEX128]; attr=Tout:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.591934: I tensorflow/core/framework/op.cc:132] Op<name=AnonymousHashTable; signature= -> table_handle:resource; attr=key_dtype:type; attr=value_dtype:type; is_stateful=true>
  2023-01-12 09:34:37.592000: I tensorflow/core/framework/op.cc:132] Op<name=AnonymousIterator; signature= -> handle:resource; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; is_stateful=true>
  2023-01-12 09:34:37.592036: I tensorflow/core/framework/op.cc:132] Op<name=AnonymousIteratorV2; signature= -> handle:resource, deleter:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; is_stateful=true>
  2023-01-12 09:34:37.592058: I tensorflow/core/framework/op.cc:132] Op<name=AnonymousIteratorV3; signature= -> handle:resource; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; is_stateful=true>
  2023-01-12 09:34:37.592074: I tensorflow/core/framework/op.cc:132] Op<name=AnonymousMemoryCache; signature= -> handle:resource, deleter:variant; is_stateful=true>
  2023-01-12 09:34:37.592087: I tensorflow/core/framework/op.cc:132] Op<name=AnonymousMultiDeviceIterator; signature= -> handle:resource, deleter:variant; attr=devices:list(string),min=1; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; is_stateful=true>
  2023-01-12 09:34:37.592099: I tensorflow/core/framework/op.cc:132] Op<name=AnonymousMultiDeviceIteratorV3; signature= -> handle:resource; attr=devices:list(string),min=1; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; is_stateful=true>
  2023-01-12 09:34:37.592266: I tensorflow/core/framework/op.cc:132] Op<name=AnonymousMutableDenseHashTable; signature=empty_key:key_dtype, deleted_key:key_dtype -> table_handle:resource; attr=key_dtype:type; attr=value_dtype:type; attr=value_shape:shape,default=[]; attr=initial_num_buckets:int,default=131072; attr=max_load_factor:float,default=0.8; is_stateful=true>
  2023-01-12 09:34:37.592334: I tensorflow/core/framework/op.cc:132] Op<name=AnonymousMutableHashTable; signature= -> table_handle:resource; attr=key_dtype:type; attr=value_dtype:type; is_stateful=true>
  2023-01-12 09:34:37.592382: I tensorflow/core/framework/op.cc:132] Op<name=AnonymousMutableHashTableOfTensors; signature= -> table_handle:resource; attr=key_dtype:type; attr=value_dtype:type; attr=value_shape:shape,default=[]; is_stateful=true>
  2023-01-12 09:34:37.592457: I tensorflow/core/framework/op.cc:132] Op<name=AnonymousRandomSeedGenerator; signature=seed:int64, seed2:int64 -> handle:resource, deleter:variant; is_stateful=true>
  2023-01-12 09:34:37.592571: I tensorflow/core/framework/op.cc:132] Op<name=AnonymousSeedGenerator; signature=seed:int64, seed2:int64, reshuffle:bool -> handle:resource, deleter:variant; is_stateful=true>
  2023-01-12 09:34:37.592654: I tensorflow/core/framework/op.cc:132] Op<name=Any; signature=input:bool, reduction_indices:Tidx -> output:bool; attr=keep_dims:bool,default=false; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.592759: I tensorflow/core/framework/op.cc:132] Op<name=ApplyAdaMax; signature=var:Ref(T), m:Ref(T), v:Ref(T), beta1_power:T, lr:T, beta1:T, beta2:T, epsilon:T, grad:T -> out:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=use_locking:bool,default=false>
  2023-01-12 09:34:37.592886: I tensorflow/core/framework/op.cc:132] Op<name=ApplyAdadelta; signature=var:Ref(T), accum:Ref(T), accum_update:Ref(T), lr:T, rho:T, epsilon:T, grad:T -> out:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=use_locking:bool,default=false>
  2023-01-12 09:34:37.592993: I tensorflow/core/framework/op.cc:132] Op<name=ApplyAdagrad; signature=var:Ref(T), accum:Ref(T), lr:T, grad:T -> out:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=use_locking:bool,default=false; attr=update_slots:bool,default=true>
  2023-01-12 09:34:37.593040: I tensorflow/core/framework/op.cc:132] Op<name=ApplyAdagradDA; signature=var:Ref(T), gradient_accumulator:Ref(T), gradient_squared_accumulator:Ref(T), grad:T, lr:T, l1:T, l2:T, global_step:int64 -> out:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=use_locking:bool,default=false>
  2023-01-12 09:34:37.593070: I tensorflow/core/framework/op.cc:132] Op<name=ApplyAdagradV2; signature=var:Ref(T), accum:Ref(T), lr:T, epsilon:T, grad:T -> out:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=use_locking:bool,default=false; attr=update_slots:bool,default=true>
  2023-01-12 09:34:37.593156: I tensorflow/core/framework/op.cc:132] Op<name=ApplyAdam; signature=var:Ref(T), m:Ref(T), v:Ref(T), beta1_power:T, beta2_power:T, lr:T, beta1:T, beta2:T, epsilon:T, grad:T -> out:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=use_locking:bool,default=false; attr=use_nesterov:bool,default=false>
  2023-01-12 09:34:37.593226: I tensorflow/core/framework/op.cc:132] Op<name=ApplyAddSign; signature=var:Ref(T), m:Ref(T), lr:T, alpha:T, sign_decay:T, beta:T, grad:T -> out:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=use_locking:bool,default=false>
  2023-01-12 09:34:37.593259: I tensorflow/core/framework/op.cc:132] Op<name=ApplyCenteredRMSProp; signature=var:Ref(T), mg:Ref(T), ms:Ref(T), mom:Ref(T), lr:T, rho:T, momentum:T, epsilon:T, grad:T -> out:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=use_locking:bool,default=false>
  2023-01-12 09:34:37.593327: I tensorflow/core/framework/op.cc:132] Op<name=ApplyFtrl; signature=var:Ref(T), accum:Ref(T), linear:Ref(T), grad:T, lr:T, l1:T, l2:T, lr_power:T -> out:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=use_locking:bool,default=false; attr=multiply_linear_by_lr:bool,default=false>
  2023-01-12 09:34:37.593361: I tensorflow/core/framework/op.cc:132] Op<name=ApplyFtrlV2; signature=var:Ref(T), accum:Ref(T), linear:Ref(T), grad:T, lr:T, l1:T, l2:T, l2_shrinkage:T, lr_power:T -> out:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=use_locking:bool,default=false; attr=multiply_linear_by_lr:bool,default=false>
  2023-01-12 09:34:37.593388: I tensorflow/core/framework/op.cc:132] Op<name=ApplyGradientDescent; signature=var:Ref(T), alpha:T, delta:T -> out:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=use_locking:bool,default=false>
  2023-01-12 09:34:37.593414: I tensorflow/core/framework/op.cc:132] Op<name=ApplyMomentum; signature=var:Ref(T), accum:Ref(T), lr:T, grad:T, momentum:T -> out:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=use_locking:bool,default=false; attr=use_nesterov:bool,default=false>
  2023-01-12 09:34:37.593441: I tensorflow/core/framework/op.cc:132] Op<name=ApplyPowerSign; signature=var:Ref(T), m:Ref(T), lr:T, logbase:T, sign_decay:T, beta:T, grad:T -> out:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=use_locking:bool,default=false>
  2023-01-12 09:34:37.593466: I tensorflow/core/framework/op.cc:132] Op<name=ApplyProximalAdagrad; signature=var:Ref(T), accum:Ref(T), lr:T, l1:T, l2:T, grad:T -> out:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=use_locking:bool,default=false>
  2023-01-12 09:34:37.593497: I tensorflow/core/framework/op.cc:132] Op<name=ApplyProximalGradientDescent; signature=var:Ref(T), alpha:T, l1:T, l2:T, delta:T -> out:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=use_locking:bool,default=false>
  2023-01-12 09:34:37.593526: I tensorflow/core/framework/op.cc:132] Op<name=ApplyRMSProp; signature=var:Ref(T), ms:Ref(T), mom:Ref(T), lr:T, rho:T, momentum:T, epsilon:T, grad:T -> out:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=use_locking:bool,default=false>
  2023-01-12 09:34:37.593616: I tensorflow/core/framework/op.cc:132] Op<name=ApproxTopK; signature=input:T -> values:T, indices:int32; attr=k:int,min=0; attr=reduction_dimension:int,default=-1; attr=recall_target:float,default=0.95; attr=is_max_k:bool,default=true; attr=reduction_input_size_override:int,default=-1; attr=aggregate_to_topk:bool,default=true; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT]>
  2023-01-12 09:34:37.593882: I tensorflow/core/framework/op.cc:132] Op<name=ApproximateEqual; signature=x:T, y:T -> z:bool; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=tolerance:float,default=1e-05; is_commutative=true>
  2023-01-12 09:34:37.593941: I tensorflow/core/framework/op.cc:132] Op<name=ArgMax; signature=input:T, dimension:Tidx -> output:output_type; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 16534343205130372495, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64, DT_BOOL]; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT16, DT_INT32, DT_INT64]; attr=output_type:type,default=DT_INT64,allowed=[DT_INT16, DT_UINT16, DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.594068: I tensorflow/core/framework/op.cc:132] Op<name=ArgMin; signature=input:T, dimension:Tidx -> output:output_type; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 16534343205130372495, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64, DT_BOOL]; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=output_type:type,default=DT_INT64,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.594141: I tensorflow/core/framework/op.cc:132] Op<name=AsString; signature=input:T -> output:string; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 5860732143377197644, DT_UINT64, DT_COMPLEX64, DT_COMPLEX128, DT_BOOL, DT_VARIANT]; attr=precision:int,default=-1; attr=scientific:bool,default=false; attr=shortest:bool,default=false; attr=width:int,default=-1; attr=fill:string,default="">
  2023-01-12 09:34:37.594201: I tensorflow/core/framework/op.cc:132] Op<name=Asin; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT8, DT_INT16, DT_INT32, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.594254: I tensorflow/core/framework/op.cc:132] Op<name=Asinh; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.594302: I tensorflow/core/framework/op.cc:132] Op<name=Assert; signature=condition:bool, data: -> ; attr=T:list(type),min=1; attr=summarize:int,default=3; is_stateful=true>
  2023-01-12 09:34:37.594354: I tensorflow/core/framework/op.cc:132] Op<name=AssertCardinalityDataset; signature=input_dataset:variant, cardinality:int64 -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1>
  2023-01-12 09:34:37.594444: I tensorflow/core/framework/op.cc:132] Op<name=AssertNextDataset; signature=input_dataset:variant, transformations:string -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1>
  2023-01-12 09:34:37.594525: I tensorflow/core/framework/op.cc:132] Op<name=AssertPrevDataset; signature=input_dataset:variant, transformations:string -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1>
  2023-01-12 09:34:37.594687: I tensorflow/core/framework/op.cc:132] Op<name=Assign; signature=ref:Ref(T), value:T -> output_ref:Ref(T); attr=T:type; attr=validate_shape:bool,default=true; attr=use_locking:bool,default=true; allows_uninitialized_input=true>
  2023-01-12 09:34:37.594769: I tensorflow/core/framework/op.cc:132] Op<name=AssignAdd; signature=ref:Ref(T), value:T -> output_ref:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=use_locking:bool,default=false>
  2023-01-12 09:34:37.594818: I tensorflow/core/framework/op.cc:132] Op<name=AssignAddVariableOp; signature=resource:resource, value:dtype -> ; attr=dtype:type; is_stateful=true>
  2023-01-12 09:34:37.594880: I tensorflow/core/framework/op.cc:132] Op<name=AssignSub; signature=ref:Ref(T), value:T -> output_ref:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=use_locking:bool,default=false>
  2023-01-12 09:34:37.594926: I tensorflow/core/framework/op.cc:132] Op<name=AssignSubVariableOp; signature=resource:resource, value:dtype -> ; attr=dtype:type; is_stateful=true>
  2023-01-12 09:34:37.594970: I tensorflow/core/framework/op.cc:132] Op<name=AssignVariableOp; signature=resource:resource, value:dtype -> ; attr=dtype:type; attr=validate_shape:bool,default=false; is_stateful=true>
  2023-01-12 09:34:37.595023: I tensorflow/core/framework/op.cc:132] Op<name=AssignVariableXlaConcatND; signature=resource:resource, inputs:N*T -> ; attr=T:type; attr=N:int,min=1; attr=num_concats:list(int); attr=paddings:list(int),default=[]; is_stateful=true>
  2023-01-12 09:34:37.595075: I tensorflow/core/framework/op.cc:132] Op<name=Atan; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT8, DT_INT16, DT_INT32, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.595136: I tensorflow/core/framework/op.cc:132] Op<name=Atan2; signature=y:T, x:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.595215: I tensorflow/core/framework/op.cc:132] Op<name=Atanh; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.595277: I tensorflow/core/framework/op.cc:132] Op<name=Attr; signature= -> ; attr=a:int>
  2023-01-12 09:34:37.595333: I tensorflow/core/framework/op.cc:132] Op<name=AttrBool; signature= -> ; attr=a:bool>
  2023-01-12 09:34:37.595475: I tensorflow/core/framework/op.cc:132] Op<name=AttrBoolList; signature= -> ; attr=a:list(bool)>
  2023-01-12 09:34:37.595541: I tensorflow/core/framework/op.cc:132] Op<name=AttrDefault; signature= -> ; attr=a:string,default="banana">
  2023-01-12 09:34:37.595603: I tensorflow/core/framework/op.cc:132] Op<name=AttrEmptyListDefault; signature= -> ; attr=a:list(float),default=[]>
  2023-01-12 09:34:37.595666: I tensorflow/core/framework/op.cc:132] Op<name=AttrEnum; signature= -> ; attr=a:string,allowed=["apples", "oranges"]>
  2023-01-12 09:34:37.595737: I tensorflow/core/framework/op.cc:132] Op<name=AttrEnumList; signature= -> ; attr=a:list(string),allowed=["apples", "oranges"]>
  2023-01-12 09:34:37.595787: I tensorflow/core/framework/op.cc:132] Op<name=AttrFloat; signature= -> ; attr=a:float>
  2023-01-12 09:34:37.595837: I tensorflow/core/framework/op.cc:132] Op<name=AttrListDefault; signature= -> ; attr=a:list(int),default=[5, 15]>
  2023-01-12 09:34:37.595892: I tensorflow/core/framework/op.cc:132] Op<name=AttrListMin; signature= -> ; attr=a:list(int),min=2>
  2023-01-12 09:34:37.595921: I tensorflow/core/framework/op.cc:132] Op<name=AttrListTypeDefault; signature=a:N*T, b:N*T -> ; attr=T:type,default=DT_INT32; attr=N:int,min=1>
  2023-01-12 09:34:37.595967: I tensorflow/core/framework/op.cc:132] Op<name=AttrMin; signature= -> ; attr=a:int,min=5>
  2023-01-12 09:34:37.595984: I tensorflow/core/framework/op.cc:132] Op<name=AttrPartialShape; signature= -> ; attr=a:shape>
  2023-01-12 09:34:37.596039: I tensorflow/core/framework/op.cc:132] Op<name=AttrPartialShapeList; signature= -> ; attr=a:list(shape)>
  2023-01-12 09:34:37.596100: I tensorflow/core/framework/op.cc:132] Op<name=AttrShape; signature= -> ; attr=a:shape>
  2023-01-12 09:34:37.596162: I tensorflow/core/framework/op.cc:132] Op<name=AttrShapeList; signature= -> ; attr=a:list(shape)>
  2023-01-12 09:34:37.596242: I tensorflow/core/framework/op.cc:132] Op<name=AttrTypeDefault; signature=a:T -> ; attr=T:type,default=DT_INT32>
  2023-01-12 09:34:37.596438: I tensorflow/core/framework/op.cc:132] Op<name=AudioMicrofrontend; signature=audio:int16 -> filterbanks:out_type; attr=sample_rate:int,default=16000; attr=window_size:int,default=25; attr=window_step:int,default=10; attr=num_channels:int,default=32; attr=upper_band_limit:float,default=7500; attr=lower_band_limit:float,default=125; attr=smoothing_bits:int,default=10; attr=even_smoothing:float,default=0.025; attr=odd_smoothing:float,default=0.06; attr=min_signal_remaining:float,default=0.05; attr=enable_pcan:bool,default=false; attr=pcan_strength:float,default=0.95; attr=pcan_offset:float,default=80; attr=gain_bits:int,default=21; attr=enable_log:bool,default=true; attr=scale_shift:int,default=6; attr=left_context:int,default=0; attr=right_context:int,default=0; attr=frame_stride:int,default=1; attr=zero_padding:bool,default=false; attr=out_scale:int,default=1; attr=out_type:type,default=DT_UINT16,allowed=[DT_UINT16, DT_FLOAT]>
  2023-01-12 09:34:37.596548: I tensorflow/core/framework/op.cc:132] Op<name=AudioSpectrogram; signature=input:float -> spectrogram:float; attr=window_size:int; attr=stride:int; attr=magnitude_squared:bool,default=false>
  2023-01-12 09:34:37.596629: I tensorflow/core/framework/op.cc:132] Op<name=AudioSummary; signature=tag:string, tensor:float -> summary:string; attr=sample_rate:float; attr=max_outputs:int,default=3,min=1>
  2023-01-12 09:34:37.596697: I tensorflow/core/framework/op.cc:132] Op<name=AudioSummaryV2; signature=tag:string, tensor:float, sample_rate:float -> summary:string; attr=max_outputs:int,default=3,min=1>
  2023-01-12 09:34:37.596783: I tensorflow/core/framework/op.cc:132] Op<name=AutoShardDataset; signature=input_dataset:variant, num_workers:int64, index:int64 -> handle:variant; attr=auto_shard_policy:int,default=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=num_replicas:int,default=0>
  2023-01-12 09:34:37.596880: I tensorflow/core/framework/op.cc:132] Op<name=AvgPool; signature=value:T -> output:T; attr=ksize:list(int),min=4; attr=strides:list(int),min=4; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.596962: I tensorflow/core/framework/op.cc:132] Op<name=AvgPool3D; signature=input:T -> output:T; attr=ksize:list(int),min=5; attr=strides:list(int),min=5; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NDHWC",allowed=["NDHWC", "NCDHW"]; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.597015: I tensorflow/core/framework/op.cc:132] Op<name=AvgPool3DGrad; signature=orig_input_shape:int32, grad:T -> output:T; attr=ksize:list(int),min=5; attr=strides:list(int),min=5; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NDHWC",allowed=["NDHWC", "NCDHW"]; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.597113: I tensorflow/core/framework/op.cc:132] Op<name=AvgPoolGrad; signature=orig_input_shape:int32, grad:T -> output:T; attr=ksize:list(int),min=4; attr=strides:list(int),min=4; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.597170: I tensorflow/core/framework/op.cc:132] Op<name=B; signature= -> out:float>
  2023-01-12 09:34:37.597241: I tensorflow/core/framework/op.cc:132] Op<name=BandedTriangularSolve; signature=matrix:T, rhs:T -> output:T; attr=lower:bool,default=true; attr=adjoint:bool,default=false; attr=T:type,allowed=[DT_DOUBLE, DT_FLOAT, DT_HALF, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.597315: I tensorflow/core/framework/op.cc:132] Op<name=Barrier; signature= -> handle:Ref(string); attr=component_types:list(type),min=1; attr=shapes:list(shape),default=[],min=0; attr=capacity:int,default=-1; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.597379: I tensorflow/core/framework/op.cc:132] Op<name=BarrierClose; signature=handle:Ref(string) -> ; attr=cancel_pending_enqueues:bool,default=false>
  2023-01-12 09:34:37.597438: I tensorflow/core/framework/op.cc:132] Op<name=BarrierIncompleteSize; signature=handle:Ref(string) -> size:int32>
  2023-01-12 09:34:37.597465: I tensorflow/core/framework/op.cc:132] Op<name=BarrierInsertMany; signature=handle:Ref(string), keys:string, values:T -> ; attr=T:type; attr=component_index:int>
  2023-01-12 09:34:37.597520: I tensorflow/core/framework/op.cc:132] Op<name=BarrierReadySize; signature=handle:Ref(string) -> size:int32>
  2023-01-12 09:34:37.597557: I tensorflow/core/framework/op.cc:132] Op<name=BarrierTakeMany; signature=handle:Ref(string), num_elements:int32 -> indices:int64, keys:string, values:; attr=component_types:list(type),min=1; attr=allow_small_batch:bool,default=false; attr=wait_for_incomplete:bool,default=false; attr=timeout_ms:int,default=-1>
  2023-01-12 09:34:37.597642: I tensorflow/core/framework/op.cc:132] Op<name=Batch; signature=in_tensors: -> batched_tensors:, batch_index:int64, id:int64; attr=num_batch_threads:int; attr=max_batch_size:int; attr=max_enqueued_batches:int,default=10; attr=batch_timeout_micros:int; attr=allowed_batch_sizes:list(int),default=[]; attr=grad_timeout_micros:int; attr=container:string,default=""; attr=shared_name:string,default=""; attr=batching_queue:string,default=""; attr=T:list(type),min=1; is_distributed_communication=true>
  2023-01-12 09:34:37.597717: I tensorflow/core/framework/op.cc:132] Op<name=BatchCholesky; signature=input:T -> output:T; attr=T:type,allowed=[DT_DOUBLE, DT_FLOAT]>
  2023-01-12 09:34:37.597787: I tensorflow/core/framework/op.cc:132] Op<name=BatchCholeskyGrad; signature=l:T, grad:T -> output:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.597825: I tensorflow/core/framework/op.cc:132] Op<name=BatchDataset; signature=input_dataset:variant, batch_size:int64 -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=metadata:string,default="">
  2023-01-12 09:34:37.597859: I tensorflow/core/framework/op.cc:132] Op<name=BatchDatasetV2; signature=input_dataset:variant, batch_size:int64, drop_remainder:bool -> handle:variant; attr=parallel_copy:bool,default=false; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=metadata:string,default="">
  2023-01-12 09:34:37.597884: I tensorflow/core/framework/op.cc:132] Op<name=BatchFFT; signature=input:complex64 -> output:complex64>
  2023-01-12 09:34:37.597905: I tensorflow/core/framework/op.cc:132] Op<name=BatchFFT2D; signature=input:complex64 -> output:complex64>
  2023-01-12 09:34:37.597924: I tensorflow/core/framework/op.cc:132] Op<name=BatchFFT3D; signature=input:complex64 -> output:complex64>
  2023-01-12 09:34:37.598229: I tensorflow/core/framework/op.cc:132] Op<name=BatchFunction; signature=in_tensors:, captured_tensors: -> out_tensors:; attr=f:func; attr=num_batch_threads:int; attr=max_batch_size:int; attr=batch_timeout_micros:int; attr=max_enqueued_batches:int,default=10; attr=allowed_batch_sizes:list(int),default=[]; attr=container:string,default=""; attr=shared_name:string,default=""; attr=batching_queue:string,default=""; attr=Tin:list(type),min=1; attr=Tcaptured:list(type),min=0; attr=Tout:list(type),min=1; attr=enable_large_batch_splitting:bool,default=false; is_distributed_communication=true>
  2023-01-12 09:34:37.598283: I tensorflow/core/framework/op.cc:132] Op<name=BatchIFFT; signature=input:complex64 -> output:complex64>
  2023-01-12 09:34:37.598315: I tensorflow/core/framework/op.cc:132] Op<name=BatchIFFT2D; signature=input:complex64 -> output:complex64>
  2023-01-12 09:34:37.598351: I tensorflow/core/framework/op.cc:132] Op<name=BatchIFFT3D; signature=input:complex64 -> output:complex64>
  2023-01-12 09:34:37.598429: I tensorflow/core/framework/op.cc:132] Op<name=BatchMatMul; signature=x:T, y:T -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]; attr=adj_x:bool,default=false; attr=adj_y:bool,default=false>
  2023-01-12 09:34:37.598547: I tensorflow/core/framework/op.cc:132] Op<name=BatchMatMulV2; signature=x:T, y:T -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT16, DT_INT32, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]; attr=adj_x:bool,default=false; attr=adj_y:bool,default=false>
  2023-01-12 09:34:37.598690: I tensorflow/core/framework/op.cc:132] Op<name=BatchMatMulV3; signature=x:Ta, y:Tb -> output:Tout; attr=Ta:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_INT16, DT_INT32, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]; attr=Tb:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_INT16, DT_INT32, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]; attr=Tout:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT16, DT_INT32, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]; attr=adj_x:bool,default=false; attr=adj_y:bool,default=false>
  2023-01-12 09:34:37.598725: I tensorflow/core/framework/op.cc:132] Op<name=BatchMatrixBandPart; signature=input:T, num_lower:int64, num_upper:int64 -> band:T; attr=T:type>
  2023-01-12 09:34:37.598752: I tensorflow/core/framework/op.cc:132] Op<name=BatchMatrixDeterminant; signature=input:T -> output:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.598771: I tensorflow/core/framework/op.cc:132] Op<name=BatchMatrixDiag; signature=diagonal:T -> output:T; attr=T:type>
  2023-01-12 09:34:37.598793: I tensorflow/core/framework/op.cc:132] Op<name=BatchMatrixDiagPart; signature=input:T -> diagonal:T; attr=T:type>
  2023-01-12 09:34:37.598853: I tensorflow/core/framework/op.cc:132] Op<name=BatchMatrixInverse; signature=input:T -> output:T; attr=adjoint:bool,default=false; attr=T:type,allowed=[DT_DOUBLE, DT_FLOAT]>
  2023-01-12 09:34:37.598890: I tensorflow/core/framework/op.cc:132] Op<name=BatchMatrixSetDiag; signature=input:T, diagonal:T -> output:T; attr=T:type>
  2023-01-12 09:34:37.598926: I tensorflow/core/framework/op.cc:132] Op<name=BatchMatrixSolve; signature=matrix:T, rhs:T -> output:T; attr=adjoint:bool,default=false; attr=T:type,allowed=[DT_DOUBLE, DT_FLOAT]>
  2023-01-12 09:34:37.599088: I tensorflow/core/framework/op.cc:132] Op<name=BatchMatrixSolveLs; signature=matrix:T, rhs:T, l2_regularizer:double -> output:T; attr=T:type,allowed=[DT_DOUBLE, DT_FLOAT]; attr=fast:bool,default=true>
  2023-01-12 09:34:37.599140: I tensorflow/core/framework/op.cc:132] Op<name=BatchMatrixTriangularSolve; signature=matrix:T, rhs:T -> output:T; attr=lower:bool,default=true; attr=adjoint:bool,default=false; attr=T:type,allowed=[DT_DOUBLE, DT_FLOAT]>
  2023-01-12 09:34:37.599254: I tensorflow/core/framework/op.cc:132] Op<name=BatchNormWithGlobalNormalization; signature=t:T, m:T, v:T, beta:T, gamma:T -> result:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=variance_epsilon:float; attr=scale_after_normalization:bool>
  2023-01-12 09:34:37.599370: I tensorflow/core/framework/op.cc:132] Op<name=BatchNormWithGlobalNormalizationGrad; signature=t:T, m:T, v:T, gamma:T, backprop:T -> dx:T, dm:T, dv:T, db:T, dg:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=variance_epsilon:float; attr=scale_after_normalization:bool>
  2023-01-12 09:34:37.599460: I tensorflow/core/framework/op.cc:132] Op<name=BatchSelfAdjointEig; signature=input:T -> output:T; attr=T:type,allowed=[DT_DOUBLE, DT_FLOAT]>
  2023-01-12 09:34:37.599540: I tensorflow/core/framework/op.cc:132] Op<name=BatchSelfAdjointEigV2; signature=input:T -> e:T, v:T; attr=compute_v:bool,default=true; attr=T:type,allowed=[DT_DOUBLE, DT_FLOAT]>
  2023-01-12 09:34:37.599647: I tensorflow/core/framework/op.cc:132] Op<name=BatchSvd; signature=input:T -> s:T, u:T, v:T; attr=compute_uv:bool,default=true; attr=full_matrices:bool,default=false; attr=T:type,allowed=[DT_DOUBLE, DT_FLOAT, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.599772: I tensorflow/core/framework/op.cc:132] Op<name=BatchToSpace; signature=input:T, crops:Tidx -> output:T; attr=T:type; attr=block_size:int,min=2; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.599865: I tensorflow/core/framework/op.cc:132] Op<name=BatchToSpaceND; signature=input:T, block_shape:Tblock_shape, crops:Tcrops -> output:T; attr=T:type; attr=Tblock_shape:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=Tcrops:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.599939: I tensorflow/core/framework/op.cc:132] Op<name=BesselI0; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.600046: I tensorflow/core/framework/op.cc:132] Op<name=BesselI0e; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.600133: I tensorflow/core/framework/op.cc:132] Op<name=BesselI1; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.600241: I tensorflow/core/framework/op.cc:132] Op<name=BesselI1e; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.600352: I tensorflow/core/framework/op.cc:132] Op<name=BesselJ0; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.600439: I tensorflow/core/framework/op.cc:132] Op<name=BesselJ1; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.600526: I tensorflow/core/framework/op.cc:132] Op<name=BesselK0; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.600584: I tensorflow/core/framework/op.cc:132] Op<name=BesselK0e; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.600662: I tensorflow/core/framework/op.cc:132] Op<name=BesselK1; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.600733: I tensorflow/core/framework/op.cc:132] Op<name=BesselK1e; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.600786: I tensorflow/core/framework/op.cc:132] Op<name=BesselY0; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.600846: I tensorflow/core/framework/op.cc:132] Op<name=BesselY1; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.600912: I tensorflow/core/framework/op.cc:132] Op<name=Betainc; signature=a:T, b:T, x:T -> z:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.601023: I tensorflow/core/framework/op.cc:132] Op<name=BiasAdd; signature=value:T, bias:T -> output:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]>
  2023-01-12 09:34:37.601140: I tensorflow/core/framework/op.cc:132] Op<name=BiasAddGrad; signature=out_backprop:T -> output:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]>
  2023-01-12 09:34:37.601336: I tensorflow/core/framework/op.cc:132] Op<name=BiasAddV1; signature=value:T, bias:T -> output:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:37.601525: I tensorflow/core/framework/op.cc:132] Op<name=Binary; signature=a:T, b:T -> out:T; attr=T:type>
  2023-01-12 09:34:37.601715: I tensorflow/core/framework/op.cc:132] Op<name=Bincount; signature=arr:int32, size:int32, weights:T -> bins:T; attr=T:type,allowed=[DT_INT32, DT_INT64, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.602185: I tensorflow/core/framework/op.cc:132] Op<name=Bitcast; signature=input:T -> output:type; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT64, 8575233562720600259, DT_QINT8, DT_QUINT8, DT_QINT16, DT_QUINT16, DT_QINT32]; attr=type:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT64, 8575233562720600259, DT_QINT8, DT_QUINT8, DT_QINT16, DT_QUINT16, DT_QINT32]>
  2023-01-12 09:34:37.602544: I tensorflow/core/framework/op.cc:132] Op<name=BitwiseAnd; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_INT8, DT_INT16, DT_INT32, DT_INT64, DT_UINT8, DT_UINT16, DT_UINT32, DT_UINT64]; is_commutative=true>
  2023-01-12 09:34:37.602767: I tensorflow/core/framework/op.cc:132] Op<name=BitwiseOr; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_INT8, DT_INT16, DT_INT32, DT_INT64, DT_UINT8, DT_UINT16, DT_UINT32, DT_UINT64]; is_commutative=true>
  2023-01-12 09:34:37.602864: I tensorflow/core/framework/op.cc:132] Op<name=BitwiseXor; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_INT8, DT_INT16, DT_INT32, DT_INT64, DT_UINT8, DT_UINT16, DT_UINT32, DT_UINT64]; is_commutative=true>
  2023-01-12 09:34:37.602959: I tensorflow/core/framework/op.cc:132] Op<name=BlockLSTM; signature=seq_len_max:int64, x:T, cs_prev:T, h_prev:T, w:T, wci:T, wcf:T, wco:T, b:T -> i:T, cs:T, f:T, o:T, ci:T, co:T, h:T; attr=forget_bias:float,default=1; attr=cell_clip:float,default=3; attr=use_peephole:bool,default=false; attr=T:type,allowed=[DT_HALF, DT_FLOAT]>
  2023-01-12 09:34:37.603073: I tensorflow/core/framework/op.cc:132] Op<name=BlockLSTMGrad; signature=seq_len_max:int64, x:T, cs_prev:T, h_prev:T, w:T, wci:T, wcf:T, wco:T, b:T, i:T, cs:T, f:T, o:T, ci:T, co:T, h:T, cs_grad:T, h_grad:T -> x_grad:T, cs_prev_grad:T, h_prev_grad:T, w_grad:T, wci_grad:T, wcf_grad:T, wco_grad:T, b_grad:T; attr=use_peephole:bool; attr=T:type,allowed=[DT_HALF, DT_FLOAT]>
  2023-01-12 09:34:37.603166: I tensorflow/core/framework/op.cc:132] Op<name=BlockLSTMGradV2; signature=seq_len_max:int64, x:T, cs_prev:T, h_prev:T, w:T, wci:T, wcf:T, wco:T, b:T, i:T, cs:T, f:T, o:T, ci:T, co:T, h:T, cs_grad:T, h_grad:T -> x_grad:T, cs_prev_grad:T, h_prev_grad:T, w_grad:T, wci_grad:T, wcf_grad:T, wco_grad:T, b_grad:T; attr=use_peephole:bool; attr=T:type,allowed=[DT_HALF, DT_FLOAT]>
  2023-01-12 09:34:37.603210: I tensorflow/core/framework/op.cc:132] Op<name=BlockLSTMV2; signature=seq_len_max:int64, x:T, cs_prev:T, h_prev:T, w:T, wci:T, wcf:T, wco:T, b:T -> i:T, cs:T, f:T, o:T, ci:T, co:T, h:T; attr=cell_clip:float,default=0; attr=use_peephole:bool,default=false; attr=T:type,allowed=[DT_HALF, DT_FLOAT]>
  2023-01-12 09:34:37.603231: I tensorflow/core/framework/op.cc:132] Op<name=BoostedTreesAggregateStats; signature=node_ids:int32, gradients:float, hessians:float, feature:int32 -> stats_summary:float; attr=max_splits:int,min=1; attr=num_buckets:int,min=1>
  2023-01-12 09:34:37.603248: I tensorflow/core/framework/op.cc:132] Op<name=BoostedTreesBucketize; signature=float_values:num_features*float, bucket_boundaries:num_features*float -> buckets:num_features*int32; attr=num_features:int,min=0>
  2023-01-12 09:34:37.603281: I tensorflow/core/framework/op.cc:132] Op<name=BoostedTreesCalculateBestFeatureSplit; signature=node_id_range:int32, stats_summary:float, l1:float, l2:float, tree_complexity:float, min_node_weight:float -> node_ids:int32, gains:float, feature_dimensions:int32, thresholds:int32, left_node_contribs:float, right_node_contribs:float, split_with_default_directions:string; attr=logits_dimension:int,min=1; attr=split_type:string,default="inequality",allowed=["inequality", "equality"]>
  2023-01-12 09:34:37.603338: I tensorflow/core/framework/op.cc:132] Op<name=BoostedTreesCalculateBestFeatureSplitV2; signature=node_id_range:int32, stats_summaries_list:num_features*float, split_types:string, candidate_feature_ids:int32, l1:float, l2:float, tree_complexity:float, min_node_weight:float -> node_ids:int32, gains:float, feature_ids:int32, feature_dimensions:int32, thresholds:int32, left_node_contribs:float, right_node_contribs:float, split_with_default_directions:string; attr=num_features:int,min=1; attr=logits_dimension:int,min=1>
  2023-01-12 09:34:37.603395: I tensorflow/core/framework/op.cc:132] Op<name=BoostedTreesCalculateBestGainsPerFeature; signature=node_id_range:int32, stats_summary_list:num_features*float, l1:float, l2:float, tree_complexity:float, min_node_weight:float -> node_ids_list:num_features*int32, gains_list:num_features*float, thresholds_list:num_features*int32, left_node_contribs_list:num_features*float, right_node_contribs_list:num_features*float; attr=max_splits:int,min=1; attr=num_features:int,min=1>
  2023-01-12 09:34:37.603446: I tensorflow/core/framework/op.cc:132] Op<name=BoostedTreesCenterBias; signature=tree_ensemble_handle:resource, mean_gradients:float, mean_hessians:float, l1:float, l2:float -> continue_centering:bool; is_stateful=true>
  2023-01-12 09:34:37.603463: I tensorflow/core/framework/op.cc:132] Op<name=BoostedTreesCreateEnsemble; signature=tree_ensemble_handle:resource, stamp_token:int64, tree_ensemble_serialized:string -> ; is_stateful=true>
  2023-01-12 09:34:37.603481: I tensorflow/core/framework/op.cc:132] Op<name=BoostedTreesCreateQuantileStreamResource; signature=quantile_stream_resource_handle:resource, epsilon:float, num_streams:int64 -> ; attr=max_elements:int,default=1099511627776; is_stateful=true>
  2023-01-12 09:34:37.603502: I tensorflow/core/framework/op.cc:132] Op<name=BoostedTreesDeserializeEnsemble; signature=tree_ensemble_handle:resource, stamp_token:int64, tree_ensemble_serialized:string -> ; is_stateful=true>
  2023-01-12 09:34:37.603515: I tensorflow/core/framework/op.cc:132] Op<name=BoostedTreesEnsembleResourceHandleOp; signature= -> resource:resource; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.603533: I tensorflow/core/framework/op.cc:132] Op<name=BoostedTreesExampleDebugOutputs; signature=tree_ensemble_handle:resource, bucketized_features:num_bucketized_features*int32 -> examples_debug_outputs_serialized:string; attr=num_bucketized_features:int,min=1; attr=logits_dimension:int; is_stateful=true>
  2023-01-12 09:34:37.603545: I tensorflow/core/framework/op.cc:132] Op<name=BoostedTreesFlushQuantileSummaries; signature=quantile_stream_resource_handle:resource -> summaries:num_features*float; attr=num_features:int,min=0; is_stateful=true>
  2023-01-12 09:34:37.603561: I tensorflow/core/framework/op.cc:132] Op<name=BoostedTreesGetEnsembleStates; signature=tree_ensemble_handle:resource -> stamp_token:int64, num_trees:int32, num_finalized_trees:int32, num_attempted_layers:int32, last_layer_nodes_range:int32; is_stateful=true>
  2023-01-12 09:34:37.603576: I tensorflow/core/framework/op.cc:132] Op<name=BoostedTreesMakeQuantileSummaries; signature=float_values:num_features*float, example_weights:float, epsilon:float -> summaries:num_features*float; attr=num_features:int,min=0>
  2023-01-12 09:34:37.603600: I tensorflow/core/framework/op.cc:132] Op<name=BoostedTreesMakeStatsSummary; signature=node_ids:int32, gradients:float, hessians:float, bucketized_features_list:num_features*int32 -> stats_summary:float; attr=max_splits:int,min=1; attr=num_buckets:int,min=1; attr=num_features:int,min=1>
  2023-01-12 09:34:37.603623: I tensorflow/core/framework/op.cc:132] Op<name=BoostedTreesPredict; signature=tree_ensemble_handle:resource, bucketized_features:num_bucketized_features*int32 -> logits:float; attr=num_bucketized_features:int,min=1; attr=logits_dimension:int; is_stateful=true>
  2023-01-12 09:34:37.603640: I tensorflow/core/framework/op.cc:132] Op<name=BoostedTreesQuantileStreamResourceAddSummaries; signature=quantile_stream_resource_handle:resource, summaries:num_features*float -> ; attr=num_features:int,min=0; is_stateful=true>
  2023-01-12 09:34:37.603655: I tensorflow/core/framework/op.cc:132] Op<name=BoostedTreesQuantileStreamResourceDeserialize; signature=quantile_stream_resource_handle:resource, bucket_boundaries:num_streams*float -> ; attr=num_streams:int,min=1; is_stateful=true>
  2023-01-12 09:34:37.603670: I tensorflow/core/framework/op.cc:132] Op<name=BoostedTreesQuantileStreamResourceFlush; signature=quantile_stream_resource_handle:resource, num_buckets:int64 -> ; attr=generate_quantiles:bool,default=false; is_stateful=true>
  2023-01-12 09:34:37.603685: I tensorflow/core/framework/op.cc:132] Op<name=BoostedTreesQuantileStreamResourceGetBucketBoundaries; signature=quantile_stream_resource_handle:resource -> bucket_boundaries:num_features*float; attr=num_features:int,min=0; is_stateful=true>
  2023-01-12 09:34:37.603699: I tensorflow/core/framework/op.cc:132] Op<name=BoostedTreesQuantileStreamResourceHandleOp; signature= -> resource:resource; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.603713: I tensorflow/core/framework/op.cc:132] Op<name=BoostedTreesSerializeEnsemble; signature=tree_ensemble_handle:resource -> stamp_token:int64, tree_ensemble_serialized:string; is_stateful=true>
  2023-01-12 09:34:37.603735: I tensorflow/core/framework/op.cc:132] Op<name=BoostedTreesSparseAggregateStats; signature=node_ids:int32, gradients:float, hessians:float, feature_indices:int32, feature_values:int32, feature_shape:int32 -> stats_summary_indices:int32, stats_summary_values:float, stats_summary_shape:int32; attr=max_splits:int,min=1; attr=num_buckets:int,min=1>
  2023-01-12 09:34:37.603844: I tensorflow/core/framework/op.cc:132] Op<name=BoostedTreesSparseCalculateBestFeatureSplit; signature=node_id_range:int32, stats_summary_indices:int32, stats_summary_values:float, stats_summary_shape:int32, l1:float, l2:float, tree_complexity:float, min_node_weight:float -> node_ids:int32, gains:float, feature_dimensions:int32, thresholds:int32, left_node_contribs:float, right_node_contribs:float, split_with_default_directions:string; attr=logits_dimension:int,min=1; attr=split_type:string,default="inequality",allowed=["inequality"]>
  2023-01-12 09:34:37.604033: I tensorflow/core/framework/op.cc:132] Op<name=BoostedTreesTrainingPredict; signature=tree_ensemble_handle:resource, cached_tree_ids:int32, cached_node_ids:int32, bucketized_features:num_bucketized_features*int32 -> partial_logits:float, tree_ids:int32, node_ids:int32; attr=num_bucketized_features:int,min=1; attr=logits_dimension:int; is_stateful=true>
  2023-01-12 09:34:37.606935: I tensorflow/core/framework/op.cc:132] Op<name=BoostedTreesUpdateEnsemble; signature=tree_ensemble_handle:resource, feature_ids:int32, node_ids:num_features*int32, gains:num_features*float, thresholds:num_features*int32, left_node_contribs:num_features*float, right_node_contribs:num_features*float, max_depth:int32, learning_rate:float -> ; attr=pruning_mode:int,min=0; attr=num_features:int,min=0; is_stateful=true>
  2023-01-12 09:34:37.607068: I tensorflow/core/framework/op.cc:132] Op<name=BoostedTreesUpdateEnsembleV2; signature=tree_ensemble_handle:resource, feature_ids:num_groups*int32, dimension_ids:num_features*int32, node_ids:num_features*int32, gains:num_features*float, thresholds:num_features*int32, left_node_contribs:num_features*float, right_node_contribs:num_features*float, split_types:num_features*string, max_depth:int32, learning_rate:float, pruning_mode:int32 -> ; attr=num_features:int,min=0; attr=logits_dimension:int,default=1; attr=num_groups:int,default=1,min=1; is_stateful=true>
  2023-01-12 09:34:37.607173: I tensorflow/core/framework/op.cc:132] Op<name=BroadcastArgs; signature=s0:T, s1:T -> r0:T; attr=T:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.607241: I tensorflow/core/framework/op.cc:132] Op<name=BroadcastGradientArgs; signature=s0:T, s1:T -> r0:T, r1:T; attr=T:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.607298: I tensorflow/core/framework/op.cc:132] Op<name=BroadcastTo; signature=input:T, shape:Tidx -> output:T; attr=T:type; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.607485: I tensorflow/core/framework/op.cc:132] Op<name=Bucketize; signature=input:T -> output:int32; attr=T:type,allowed=[DT_INT32, DT_INT64, DT_FLOAT, DT_DOUBLE]; attr=boundaries:list(float)>
  2023-01-12 09:34:37.607572: I tensorflow/core/framework/op.cc:132] Op<name=BytesProducedStatsDataset; signature=input_dataset:variant, tag:string -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1>
  2023-01-12 09:34:37.607611: I tensorflow/core/framework/op.cc:132] Op<name=CSRSparseMatrixComponents; signature=csr_sparse_matrix:variant, index:int32 -> row_ptrs:int32, col_inds:int32, values:type; attr=type:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.607646: I tensorflow/core/framework/op.cc:132] Op<name=CSRSparseMatrixToDense; signature=sparse_input:variant -> dense_output:type; attr=type:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.607671: I tensorflow/core/framework/op.cc:132] Op<name=CSRSparseMatrixToSparseTensor; signature=sparse_matrix:variant -> indices:int64, values:type, dense_shape:int64; attr=type:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.607700: I tensorflow/core/framework/op.cc:132] Op<name=CSVDataset; signature=filenames:string, compression_type:string, buffer_size:int64, header:bool, field_delim:string, use_quote_delim:bool, na_value:string, select_cols:int64, record_defaults: -> handle:variant; attr=output_types:list(type),min=1,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64, DT_STRING]; attr=output_shapes:list(shape),min=1; is_stateful=true>
  2023-01-12 09:34:37.607844: I tensorflow/core/framework/op.cc:132] Op<name=CSVDatasetV2; signature=filenames:string, compression_type:string, buffer_size:int64, header:bool, field_delim:string, use_quote_delim:bool, na_value:string, select_cols:int64, record_defaults:, exclude_cols:int64 -> handle:variant; attr=output_types:list(type),min=1,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64, DT_STRING]; attr=output_shapes:list(shape),min=1; is_stateful=true>
  2023-01-12 09:34:37.607958: I tensorflow/core/framework/op.cc:132] Op<name=CTCBeamSearchDecoder; signature=inputs:T, sequence_length:int32 -> decoded_indices:top_paths*int64, decoded_values:top_paths*int64, decoded_shape:top_paths*int64, log_probability:T; attr=beam_width:int,min=1; attr=top_paths:int,min=1; attr=merge_repeated:bool,default=true; attr=T:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.608018: I tensorflow/core/framework/op.cc:132] Op<name=CTCGreedyDecoder; signature=inputs:T, sequence_length:int32 -> decoded_indices:int64, decoded_values:int64, decoded_shape:int64, log_probability:T; attr=merge_repeated:bool,default=false; attr=blank_index:int,default=-1; attr=T:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.608139: I tensorflow/core/framework/op.cc:132] Op<name=CTCLoss; signature=inputs:T, labels_indices:int64, labels_values:int32, sequence_length:int32 -> loss:T, gradient:T; attr=preprocess_collapse_repeated:bool,default=false; attr=ctc_merge_repeated:bool,default=true; attr=ignore_longer_outputs_than_inputs:bool,default=false; attr=T:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.608340: I tensorflow/core/framework/op.cc:132] Op<name=CTCLossV2; signature=inputs:float, labels_indices:int64, labels_values:int32, sequence_length:int32 -> loss:float, gradient:float; attr=preprocess_collapse_repeated:bool,default=false; attr=ctc_merge_repeated:bool,default=true; attr=ignore_longer_outputs_than_inputs:bool,default=false>
  2023-01-12 09:34:37.608434: I tensorflow/core/framework/op.cc:132] Op<name=CacheDataset; signature=input_dataset:variant, filename:string -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=metadata:string,default="">
  2023-01-12 09:34:37.608602: I tensorflow/core/framework/op.cc:132] Op<name=CacheDatasetV2; signature=input_dataset:variant, filename:string, cache:resource -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=metadata:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.608702: I tensorflow/core/framework/op.cc:132] Op<name=Case; signature=branch_index:int32, input: -> output:; attr=Tin:list(type),min=0; attr=Tout:list(type),min=0; attr=branches:list(func),min=1; attr=output_shapes:list(shape),default=[]; is_stateful=true>
  2023-01-12 09:34:37.608788: I tensorflow/core/framework/op.cc:132] Op<name=Cast; signature=x:SrcT -> y:DstT; attr=SrcT:type; attr=DstT:type; attr=Truncate:bool,default=false>
  2023-01-12 09:34:37.608962: I tensorflow/core/framework/op.cc:132] Op<name=Ceil; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.609058: I tensorflow/core/framework/op.cc:132] Op<name=CheckNumerics; signature=tensor:T -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=message:string; is_stateful=true>
  2023-01-12 09:34:37.609165: I tensorflow/core/framework/op.cc:132] Op<name=CheckNumericsV2; signature=tensor:T -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=message:string; is_stateful=true>
  2023-01-12 09:34:37.609272: I tensorflow/core/framework/op.cc:132] Op<name=Cholesky; signature=input:T -> output:T; attr=T:type,allowed=[DT_DOUBLE, DT_FLOAT, DT_HALF, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.609351: I tensorflow/core/framework/op.cc:132] Op<name=CholeskyGrad; signature=l:T, grad:T -> output:T; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.609609: I tensorflow/core/framework/op.cc:132] Op<name=ChooseFastestBranchDataset; signature=input_dataset:variant, ratio_numerator:int64, ratio_denominator:int64, other_arguments: -> handle:variant; attr=Targuments:list(type),min=0; attr=num_elements_per_branch:int,min=1; attr=branches:list(func),min=1; attr=other_arguments_lengths:list(int),min=1; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1>
  2023-01-12 09:34:37.609699: I tensorflow/core/framework/op.cc:132] Op<name=ChooseFastestDataset; signature=input_datasets:N*variant -> handle:variant; attr=N:int,min=2; attr=num_experiments:int; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1>
  2023-01-12 09:34:37.609808: I tensorflow/core/framework/op.cc:132] Op<name=ClipByValue; signature=t:T, clip_value_min:T, clip_value_max:T -> output:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:37.609877: I tensorflow/core/framework/op.cc:132] Op<name=CloseSummaryWriter; signature=writer:resource -> ; is_stateful=true>
  2023-01-12 09:34:37.610908: I tensorflow/core/framework/op.cc:132] Op<name=CollateTPUEmbeddingMemory; signature=memory_configs:N*string -> merged_memory_config:string; attr=N:int,min=1; is_stateful=true>
  2023-01-12 09:34:37.610987: I tensorflow/core/framework/op.cc:132] Op<name=CollectiveAllToAllV3; signature=input:T, communicator:resource, group_assignment:int32 -> data:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT, DT_HALF, DT_DOUBLE, DT_INT32, DT_INT64]; attr=timeout_seconds:float,default=0; is_stateful=true; is_distributed_communication=true>
  2023-01-12 09:34:37.611102: I tensorflow/core/framework/op.cc:132] Op<name=CollectiveAssignGroupV2; signature=group_assignment:int32, device_index:int32, base_key:int32 -> group_size:int32, group_key:int32; is_stateful=true; is_distributed_communication=true>
  2023-01-12 09:34:37.611386: I tensorflow/core/framework/op.cc:132] Op<name=CollectiveBcastRecv; signature= -> data:T; attr=T:type,allowed=[DT_BOOL, DT_FLOAT, DT_HALF, DT_DOUBLE, DT_INT32, DT_INT64]; attr=group_size:int; attr=group_key:int; attr=instance_key:int; attr=shape:shape; attr=communication_hint:string,default="auto"; attr=timeout_seconds:float,default=0; is_stateful=true; is_distributed_communication=true>
  2023-01-12 09:34:37.611531: I tensorflow/core/framework/op.cc:132] Op<name=CollectiveBcastRecvV2; signature=group_size:int32, group_key:int32, instance_key:int32, shape:Tshape -> data:T; attr=T:type,allowed=[DT_BOOL, DT_FLOAT, DT_HALF, DT_DOUBLE, DT_INT32, DT_INT64]; attr=Tshape:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=communication_hint:string,default="auto"; attr=timeout_seconds:float,default=0; is_stateful=true; is_distributed_communication=true>
  2023-01-12 09:34:37.611749: I tensorflow/core/framework/op.cc:132] Op<name=CollectiveBcastSend; signature=input:T -> data:T; attr=T:type,allowed=[DT_BOOL, DT_FLOAT, DT_HALF, DT_DOUBLE, DT_INT32, DT_INT64]; attr=group_size:int; attr=group_key:int; attr=instance_key:int; attr=shape:shape; attr=communication_hint:string,default="auto"; attr=timeout_seconds:float,default=0; is_stateful=true; is_distributed_communication=true>
  2023-01-12 09:34:37.611899: I tensorflow/core/framework/op.cc:132] Op<name=CollectiveBcastSendV2; signature=input:T, group_size:int32, group_key:int32, instance_key:int32 -> data:T; attr=T:type,allowed=[DT_BOOL, DT_FLOAT, DT_HALF, DT_DOUBLE, DT_INT32, DT_INT64]; attr=communication_hint:string,default="auto"; attr=timeout_seconds:float,default=0; is_stateful=true; is_distributed_communication=true>
  2023-01-12 09:34:37.612007: I tensorflow/core/framework/op.cc:132] Op<name=CollectiveGather; signature=input:T -> data:T; attr=T:type,allowed=[DT_FLOAT, DT_HALF, DT_DOUBLE, DT_INT32, DT_INT64]; attr=group_size:int; attr=group_key:int; attr=instance_key:int; attr=shape:shape; attr=communication_hint:string,default="auto"; attr=timeout_seconds:float,default=0; is_stateful=true; is_distributed_communication=true>
  2023-01-12 09:34:37.612110: I tensorflow/core/framework/op.cc:132] Op<name=CollectiveGatherV2; signature=input:T, group_size:int32, group_key:int32, instance_key:int32, ordering_token:Nordering_token*resource -> data:T; attr=T:type,allowed=[DT_FLOAT, DT_HALF, DT_DOUBLE, DT_INT32, DT_INT64]; attr=communication_hint:string,default="auto"; attr=timeout_seconds:float,default=0; attr=Nordering_token:int,default=0,min=0; is_stateful=true; is_distributed_communication=true>
  2023-01-12 09:34:37.612248: I tensorflow/core/framework/op.cc:132] Op<name=CollectiveInitializeCommunicator; signature=group_key:int32, rank:int32, group_size:int32 -> communicator:resource; attr=communication_hint:string,default="auto"; attr=timeout_seconds:float,default=0; is_stateful=true; is_distributed_communication=true>
  2023-01-12 09:34:37.613109: I tensorflow/core/framework/op.cc:132] Op<name=CollectivePermute; signature=input:T, source_target_pairs:int32 -> output:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; is_stateful=true>
  2023-01-12 09:34:37.613191: I tensorflow/core/framework/op.cc:132] Op<name=CollectiveReduce; signature=input:T -> data:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT, DT_HALF, DT_DOUBLE, DT_INT32, DT_INT64]; attr=group_size:int; attr=group_key:int; attr=instance_key:int; attr=merge_op:string,allowed=["Min", "Max", "Mul", "Add"]; attr=final_op:string,allowed=["Id", "Div"]; attr=subdiv_offsets:list(int); attr=wait_for:list(int),default=[]; attr=communication_hint:string,default="auto"; attr=timeout_seconds:float,default=0; is_stateful=true; is_distributed_communication=true>
  2023-01-12 09:34:37.613265: I tensorflow/core/framework/op.cc:132] Op<name=CollectiveReduceV2; signature=input:T, group_size:int32, group_key:int32, instance_key:int32, ordering_token:Nordering_token*resource -> data:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT, DT_HALF, DT_DOUBLE, DT_INT32, DT_INT64]; attr=merge_op:string,allowed=["Min", "Max", "Mul", "Add"]; attr=final_op:string,allowed=["Id", "Div"]; attr=communication_hint:string,default="auto"; attr=timeout_seconds:float,default=0; attr=Nordering_token:int,default=0,min=0; attr=max_subdivs_per_device:int,default=-1; is_stateful=true; is_distributed_communication=true>
  2023-01-12 09:34:37.613369: I tensorflow/core/framework/op.cc:132] Op<name=CollectiveReduceV3; signature=input:T, communicator:resource, group_assignment:int32 -> data:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT, DT_HALF, DT_DOUBLE, DT_INT32, DT_INT64]; attr=reduction:string,allowed=["Min", "Max", "Mul", "Add"]; attr=timeout_seconds:float,default=0; is_stateful=true; is_distributed_communication=true>
  2023-01-12 09:34:37.613411: I tensorflow/core/framework/op.cc:132] Op<name=CombinedNonMaxSuppression; signature=boxes:float, scores:float, max_output_size_per_class:int32, max_total_size:int32, iou_threshold:float, score_threshold:float -> nmsed_boxes:float, nmsed_scores:float, nmsed_classes:float, valid_detections:int32; attr=pad_per_class:bool,default=false; attr=clip_boxes:bool,default=true>
  2023-01-12 09:34:37.613504: I tensorflow/core/framework/op.cc:132] Op<name=Complex; signature=real:T, imag:T -> out:Tout; attr=T:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_DOUBLE]; attr=Tout:type,default=DT_COMPLEX64,allowed=[DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.613587: I tensorflow/core/framework/op.cc:132] Op<name=ComplexAbs; signature=x:T -> y:Tout; attr=T:type,default=DT_COMPLEX64,allowed=[DT_COMPLEX64, DT_COMPLEX128]; attr=Tout:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.613661: I tensorflow/core/framework/op.cc:132] Op<name=ComplexStruct; signature= -> a:n_a*int32, b:n_b*int64, c:; attr=n_a:int,min=0; attr=n_b:int,min=0; attr=t_c:list(type),min=0>
  2023-01-12 09:34:37.613795: I tensorflow/core/framework/op.cc:132] Op<name=CompositeTensorVariantFromComponents; signature=components: -> encoded:variant; attr=metadata:string; attr=Tcomponents:list(type),min=0>
  2023-01-12 09:34:37.613869: I tensorflow/core/framework/op.cc:132] Op<name=CompositeTensorVariantToComponents; signature=encoded:variant -> components:; attr=metadata:string; attr=Tcomponents:list(type),min=0>
  2023-01-12 09:34:37.613942: I tensorflow/core/framework/op.cc:132] Op<name=CompressElement; signature=components: -> compressed:variant; attr=input_types:list(type),min=1>
  2023-01-12 09:34:37.614194: I tensorflow/core/framework/op.cc:132] Op<name=ComputeAccidentalHits; signature=true_classes:int64, sampled_candidates:int64 -> indices:int32, ids:int64, weights:float; attr=num_true:int; attr=seed:int,default=0; attr=seed2:int,default=0>
  2023-01-12 09:34:37.614248: I tensorflow/core/framework/op.cc:132] Op<name=ComputeBatchSize; signature=input_dataset:variant -> batch_size:int64>
  2023-01-12 09:34:37.614410: I tensorflow/core/framework/op.cc:132] Op<name=Concat; signature=concat_dim:int32, values:N*T -> output:T; attr=N:int,min=2; attr=T:type>
  2023-01-12 09:34:37.614479: I tensorflow/core/framework/op.cc:132] Op<name=ConcatOffset; signature=concat_dim:int32, shape:N*int32 -> offset:N*int32; attr=N:int,min=2>
  2023-01-12 09:34:37.614562: I tensorflow/core/framework/op.cc:132] Op<name=ConcatV2; signature=values:N*T, axis:Tidx -> output:T; attr=N:int,min=2; attr=T:type; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.614737: I tensorflow/core/framework/op.cc:132] Op<name=ConcatenateDataset; signature=input_dataset:variant, another_dataset:variant -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=metadata:string,default="">
  2023-01-12 09:34:37.615006: I tensorflow/core/framework/op.cc:132] Op<name=ConditionalAccumulator; signature= -> handle:Ref(string); attr=dtype:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=shape:shape; attr=container:string,default=""; attr=shared_name:string,default=""; attr=reduction_type:string,default="MEAN",allowed=["MEAN", "SUM"]; is_stateful=true>
  2023-01-12 09:34:37.615053: I tensorflow/core/framework/op.cc:132] Op<name=ConfigureAndInitializeGlobalTPU; signature= -> output:int32; attr=use_tfrt_host_runtime:bool,default=true; is_stateful=true>
  2023-01-12 09:34:37.615095: I tensorflow/core/framework/op.cc:132] Op<name=ConfigureDistributedTPU; signature= -> topology:string; attr=embedding_config:string,default=""; attr=tpu_embedding_config:string,default=""; attr=is_global_init:bool,default=false; attr=enable_whole_mesh_compilations:bool,default=false; attr=compilation_failure_closes_chips:bool,default=true; attr=tpu_cancellation_closes_chips:int,default=0; is_stateful=true>
  2023-01-12 09:34:37.615123: I tensorflow/core/framework/op.cc:132] Op<name=ConfigureTPUEmbedding; signature= -> ; attr=config:string; is_stateful=true>
  2023-01-12 09:34:37.615185: I tensorflow/core/framework/op.cc:132] Op<name=ConfigureTPUEmbeddingHost; signature=common_config:string, memory_config:string -> network_config:string; attr=config:string; is_stateful=true>
  2023-01-12 09:34:37.615210: I tensorflow/core/framework/op.cc:132] Op<name=ConfigureTPUEmbeddingMemory; signature=common_config:string -> memory_config:string; is_stateful=true>
  2023-01-12 09:34:37.615248: I tensorflow/core/framework/op.cc:132] Op<name=Conj; signature=input:T -> output:T; attr=T:type,default=DT_COMPLEX64,allowed=[DT_COMPLEX64, DT_COMPLEX128, DT_VARIANT]>
  2023-01-12 09:34:37.615290: I tensorflow/core/framework/op.cc:132] Op<name=ConjugateTranspose; signature=x:T, perm:Tperm -> y:T; attr=T:type; attr=Tperm:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.615426: I tensorflow/core/framework/op.cc:132] Op<name=ConnectTPUEmbeddingHosts; signature=network_configs:N*string -> ; attr=N:int,min=1; is_stateful=true>
  2023-01-12 09:34:37.615466: I tensorflow/core/framework/op.cc:132] Op<name=Const; signature= -> output:dtype; attr=value:tensor; attr=dtype:type>
  2023-01-12 09:34:37.615488: I tensorflow/core/framework/op.cc:132] Op<name=ConstructionFails; signature= -> >
  2023-01-12 09:34:37.615507: I tensorflow/core/framework/op.cc:132] Op<name=ConsumeMutexLock; signature=mutex_lock:variant -> ; is_stateful=true>
  2023-01-12 09:34:37.615551: I tensorflow/core/framework/op.cc:132] Op<name=ControlTrigger; signature= -> >
  2023-01-12 09:34:37.615619: I tensorflow/core/framework/op.cc:132] Op<name=Conv2D; signature=input:T, filter:T -> output:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE, DT_INT32]; attr=strides:list(int); attr=use_cudnn_on_gpu:bool,default=true; attr=padding:string,allowed=["SAME", "VALID", "EXPLICIT"]; attr=explicit_paddings:list(int),default=[]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=dilations:list(int),default=[1, 1, 1, 1]>
  2023-01-12 09:34:37.615862: I tensorflow/core/framework/op.cc:132] Op<name=Conv2DBackpropFilter; signature=input:T, filter_sizes:int32, out_backprop:T -> output:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]; attr=strides:list(int); attr=use_cudnn_on_gpu:bool,default=true; attr=padding:string,allowed=["SAME", "VALID", "EXPLICIT"]; attr=explicit_paddings:list(int),default=[]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=dilations:list(int),default=[1, 1, 1, 1]>
  2023-01-12 09:34:37.615983: I tensorflow/core/framework/op.cc:132] Op<name=Conv2DBackpropInput; signature=input_sizes:int32, filter:T, out_backprop:T -> output:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE, DT_INT32]; attr=strides:list(int); attr=use_cudnn_on_gpu:bool,default=true; attr=padding:string,allowed=["SAME", "VALID", "EXPLICIT"]; attr=explicit_paddings:list(int),default=[]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=dilations:list(int),default=[1, 1, 1, 1]>
  2023-01-12 09:34:37.616098: I tensorflow/core/framework/op.cc:132] Op<name=Conv3D; signature=input:T, filter:T -> output:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]; attr=strides:list(int),min=5; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NDHWC",allowed=["NDHWC", "NCDHW"]; attr=dilations:list(int),default=[1, 1, 1, 1, 1]>
  2023-01-12 09:34:37.616197: I tensorflow/core/framework/op.cc:132] Op<name=Conv3DBackpropFilter; signature=input:T, filter:T, out_backprop:T -> output:T; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=strides:list(int),min=5; attr=padding:string,allowed=["SAME", "VALID"]; attr=dilations:list(int),default=[1, 1, 1, 1, 1]>
  2023-01-12 09:34:37.616304: I tensorflow/core/framework/op.cc:132] Op<name=Conv3DBackpropFilterV2; signature=input:T, filter_sizes:int32, out_backprop:T -> output:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]; attr=strides:list(int),min=5; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NDHWC",allowed=["NDHWC", "NCDHW"]; attr=dilations:list(int),default=[1, 1, 1, 1, 1]>
  2023-01-12 09:34:37.616555: I tensorflow/core/framework/op.cc:132] Op<name=Conv3DBackpropInput; signature=input:T, filter:T, out_backprop:T -> output:T; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=strides:list(int),min=5; attr=padding:string,allowed=["SAME", "VALID"]; attr=dilations:list(int),default=[1, 1, 1, 1, 1]>
  2023-01-12 09:34:37.616764: I tensorflow/core/framework/op.cc:132] Op<name=Conv3DBackpropInputV2; signature=input_sizes:Tshape, filter:T, out_backprop:T -> output:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]; attr=strides:list(int),min=5; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NDHWC",allowed=["NDHWC", "NCDHW"]; attr=dilations:list(int),default=[1, 1, 1, 1, 1]; attr=Tshape:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.616849: I tensorflow/core/framework/op.cc:132] Op<name=Copy; signature=input:T -> output:T; attr=T:type; attr=tensor_name:string,default=""; attr=debug_ops_spec:list(string),default=[]; allows_uninitialized_input=true>
  2023-01-12 09:34:37.616925: I tensorflow/core/framework/op.cc:132] Op<name=CopyHost; signature=input:T -> output:T; attr=T:type; attr=tensor_name:string,default=""; attr=debug_ops_spec:list(string),default=[]; allows_uninitialized_input=true>
  2023-01-12 09:34:37.617503: I tensorflow/core/framework/op.cc:132] Op<name=CopyOp; signature=a:T -> b:T; attr=T:type>
  2023-01-12 09:34:37.617556: I tensorflow/core/framework/op.cc:132] Op<name=CopyToMesh; signature=input:T -> output:T; attr=layout:string; attr=source_layout:string,default=""; attr=T:type>
  2023-01-12 09:34:37.617668: I tensorflow/core/framework/op.cc:132] Op<name=Cos; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.617716: I tensorflow/core/framework/op.cc:132] Op<name=Cosh; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.617764: I tensorflow/core/framework/op.cc:132] Op<name=CountUpTo; signature=ref:Ref(T) -> output:T; attr=limit:int; attr=T:type,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.617805: I tensorflow/core/framework/op.cc:132] Op<name=CreateSummaryDbWriter; signature=writer:resource, db_uri:string, experiment_name:string, run_name:string, user_name:string -> ; is_stateful=true>
  2023-01-12 09:34:37.617840: I tensorflow/core/framework/op.cc:132] Op<name=CreateSummaryFileWriter; signature=writer:resource, logdir:string, max_queue:int32, flush_millis:int32, filename_suffix:string -> ; is_stateful=true>
  2023-01-12 09:34:37.617924: I tensorflow/core/framework/op.cc:132] Op<name=CropAndResize; signature=image:T, boxes:float, box_ind:int32, crop_size:int32 -> crops:float; attr=T:type,allowed=[DT_UINT8, DT_UINT16, DT_INT8, DT_INT16, DT_INT32, DT_INT64, DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=method:string,default="bilinear",allowed=["bilinear", "nearest"]; attr=extrapolation_value:float,default=0>
  2023-01-12 09:34:37.618026: I tensorflow/core/framework/op.cc:132] Op<name=CropAndResizeGradBoxes; signature=grads:float, image:T, boxes:float, box_ind:int32 -> output:float; attr=T:type,allowed=[DT_UINT8, DT_UINT16, DT_INT8, DT_INT16, DT_INT32, DT_INT64, DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=method:string,default="bilinear",allowed=["bilinear"]>
  2023-01-12 09:34:37.618079: I tensorflow/core/framework/op.cc:132] Op<name=CropAndResizeGradImage; signature=grads:float, boxes:float, box_ind:int32, image_size:int32 -> output:T; attr=T:type,allowed=[DT_FLOAT, DT_HALF, DT_DOUBLE]; attr=method:string,default="bilinear",allowed=["bilinear", "nearest"]>
  2023-01-12 09:34:37.618368: I tensorflow/core/framework/op.cc:132] Op<name=Cross; signature=a:T, b:T -> product:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:37.618736: I tensorflow/core/framework/op.cc:132] Op<name=CrossReplicaSum; signature=input:T, group_assignment:int32 -> output:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT32]; is_stateful=true>
  2023-01-12 09:34:37.618864: I tensorflow/core/framework/op.cc:132] Op<name=CudnnRNN; signature=input:T, input_h:T, input_c:T, params:T -> output:T, output_h:T, output_c:T, reserve_space:T; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=rnn_mode:string,default="lstm",allowed=["rnn_relu", "rnn_tanh", "lstm", "gru"]; attr=input_mode:string,default="linear_input",allowed=["linear_input", "skip_input", "auto_select"]; attr=direction:string,default="unidirectional",allowed=["unidirectional", "bidirectional"]; attr=dropout:float,default=0; attr=seed:int,default=0; attr=seed2:int,default=0; attr=is_training:bool,default=true; is_stateful=true>
  2023-01-12 09:34:37.619021: I tensorflow/core/framework/op.cc:132] Op<name=CudnnRNNBackprop; signature=input:T, input_h:T, input_c:T, params:T, output:T, output_h:T, output_c:T, output_backprop:T, output_h_backprop:T, output_c_backprop:T, reserve_space:T -> input_backprop:T, input_h_backprop:T, input_c_backprop:T, params_backprop:T; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=rnn_mode:string,default="lstm",allowed=["rnn_relu", "rnn_tanh", "lstm", "gru"]; attr=input_mode:string,default="linear_input",allowed=["linear_input", "skip_input", "auto_select"]; attr=direction:string,default="unidirectional",allowed=["unidirectional", "bidirectional"]; attr=dropout:float,default=0; attr=seed:int,default=0; attr=seed2:int,default=0; is_stateful=true>
  2023-01-12 09:34:37.619162: I tensorflow/core/framework/op.cc:132] Op<name=CudnnRNNBackpropV2; signature=input:T, input_h:T, input_c:T, params:T, output:T, output_h:T, output_c:T, output_backprop:T, output_h_backprop:T, output_c_backprop:T, reserve_space:T, host_reserved:int8 -> input_backprop:T, input_h_backprop:T, input_c_backprop:T, params_backprop:T; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=rnn_mode:string,default="lstm",allowed=["rnn_relu", "rnn_tanh", "lstm", "gru"]; attr=input_mode:string,default="linear_input",allowed=["linear_input", "skip_input", "auto_select"]; attr=direction:string,default="unidirectional",allowed=["unidirectional", "bidirectional"]; attr=dropout:float,default=0; attr=seed:int,default=0; attr=seed2:int,default=0; is_stateful=true>
  2023-01-12 09:34:37.619247: I tensorflow/core/framework/op.cc:132] Op<name=CudnnRNNBackpropV3; signature=input:T, input_h:T, input_c:T, params:T, sequence_lengths:int32, output:T, output_h:T, output_c:T, output_backprop:T, output_h_backprop:T, output_c_backprop:T, reserve_space:T, host_reserved:int8 -> input_backprop:T, input_h_backprop:T, input_c_backprop:T, params_backprop:T; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=rnn_mode:string,default="lstm",allowed=["rnn_relu", "rnn_tanh", "lstm", "gru"]; attr=input_mode:string,default="linear_input",allowed=["linear_input", "skip_input", "auto_select"]; attr=direction:string,default="unidirectional",allowed=["unidirectional", "bidirectional"]; attr=dropout:float,default=0; attr=seed:int,default=0; attr=seed2:int,default=0; attr=num_proj:int,default=0; attr=time_major:bool,default=true; is_stateful=true>
  2023-01-12 09:34:37.619306: I tensorflow/core/framework/op.cc:132] Op<name=CudnnRNNCanonicalToParams; signature=num_layers:int32, num_units:int32, input_size:int32, weights:num_params*T, biases:num_params*T -> params:T; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=num_params:int,min=1; attr=rnn_mode:string,default="lstm",allowed=["rnn_relu", "rnn_tanh", "lstm", "gru"]; attr=input_mode:string,default="linear_input",allowed=["linear_input", "skip_input", "auto_select"]; attr=direction:string,default="unidirectional",allowed=["unidirectional", "bidirectional"]; attr=dropout:float,default=0; attr=seed:int,default=0; attr=seed2:int,default=0>
  2023-01-12 09:34:37.619444: I tensorflow/core/framework/op.cc:132] Op<name=CudnnRNNCanonicalToParamsV2; signature=num_layers:int32, num_units:int32, input_size:int32, weights:num_params_weights*T, biases:num_params_biases*T -> params:T; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=num_params_weights:int,min=1; attr=num_params_biases:int,min=1; attr=rnn_mode:string,default="lstm",allowed=["rnn_relu", "rnn_tanh", "lstm", "gru"]; attr=input_mode:string,default="linear_input",allowed=["linear_input", "skip_input", "auto_select"]; attr=direction:string,default="unidirectional",allowed=["unidirectional", "bidirectional"]; attr=dropout:float,default=0; attr=seed:int,default=0; attr=seed2:int,default=0; attr=num_proj:int,default=0>
  2023-01-12 09:34:37.619562: I tensorflow/core/framework/op.cc:132] Op<name=CudnnRNNParamsSize; signature=num_layers:int32, num_units:int32, input_size:int32 -> params_size:S; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=S:type,allowed=[DT_INT32, DT_INT64]; attr=rnn_mode:string,default="lstm",allowed=["rnn_relu", "rnn_tanh", "lstm", "gru"]; attr=input_mode:string,default="linear_input",allowed=["linear_input", "skip_input", "auto_select"]; attr=direction:string,default="unidirectional",allowed=["unidirectional", "bidirectional"]; attr=dropout:float,default=0; attr=seed:int,default=0; attr=seed2:int,default=0; attr=num_proj:int,default=0>
  2023-01-12 09:34:37.619692: I tensorflow/core/framework/op.cc:132] Op<name=CudnnRNNParamsToCanonical; signature=num_layers:int32, num_units:int32, input_size:int32, params:T -> weights:num_params*T, biases:num_params*T; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=num_params:int,min=1; attr=rnn_mode:string,default="lstm",allowed=["rnn_relu", "rnn_tanh", "lstm", "gru"]; attr=input_mode:string,default="linear_input",allowed=["linear_input", "skip_input", "auto_select"]; attr=direction:string,default="unidirectional",allowed=["unidirectional", "bidirectional"]; attr=dropout:float,default=0; attr=seed:int,default=0; attr=seed2:int,default=0>
  2023-01-12 09:34:37.619757: I tensorflow/core/framework/op.cc:132] Op<name=CudnnRNNParamsToCanonicalV2; signature=num_layers:int32, num_units:int32, input_size:int32, params:T -> weights:num_params_weights*T, biases:num_params_biases*T; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=num_params_weights:int,min=1; attr=num_params_biases:int,min=1; attr=rnn_mode:string,default="lstm",allowed=["rnn_relu", "rnn_tanh", "lstm", "gru"]; attr=input_mode:string,default="linear_input",allowed=["linear_input", "skip_input", "auto_select"]; attr=direction:string,default="unidirectional",allowed=["unidirectional", "bidirectional"]; attr=dropout:float,default=0; attr=seed:int,default=0; attr=seed2:int,default=0; attr=num_proj:int,default=0>
  2023-01-12 09:34:37.619813: I tensorflow/core/framework/op.cc:132] Op<name=CudnnRNNV2; signature=input:T, input_h:T, input_c:T, params:T -> output:T, output_h:T, output_c:T, reserve_space:T, host_reserved:int8; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=rnn_mode:string,default="lstm",allowed=["rnn_relu", "rnn_tanh", "lstm", "gru"]; attr=input_mode:string,default="linear_input",allowed=["linear_input", "skip_input", "auto_select"]; attr=direction:string,default="unidirectional",allowed=["unidirectional", "bidirectional"]; attr=dropout:float,default=0; attr=seed:int,default=0; attr=seed2:int,default=0; attr=is_training:bool,default=true; is_stateful=true>
  2023-01-12 09:34:37.619929: I tensorflow/core/framework/op.cc:132] Op<name=CudnnRNNV3; signature=input:T, input_h:T, input_c:T, params:T, sequence_lengths:int32 -> output:T, output_h:T, output_c:T, reserve_space:T, host_reserved:int8; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=rnn_mode:string,default="lstm",allowed=["rnn_relu", "rnn_tanh", "lstm", "gru"]; attr=input_mode:string,default="linear_input",allowed=["linear_input", "skip_input", "auto_select"]; attr=direction:string,default="unidirectional",allowed=["unidirectional", "bidirectional"]; attr=dropout:float,default=0; attr=seed:int,default=0; attr=seed2:int,default=0; attr=num_proj:int,default=0; attr=is_training:bool,default=true; attr=time_major:bool,default=true; is_stateful=true>
  2023-01-12 09:34:37.620112: I tensorflow/core/framework/op.cc:132] Op<name=Cumprod; signature=x:T, axis:Tidx -> out:T; attr=exclusive:bool,default=false; attr=reverse:bool,default=false; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.620761: I tensorflow/core/framework/op.cc:132] Op<name=Cumsum; signature=x:T, axis:Tidx -> out:T; attr=exclusive:bool,default=false; attr=reverse:bool,default=false; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.620839: I tensorflow/core/framework/op.cc:132] Op<name=CumulativeLogsumexp; signature=x:T, axis:Tidx -> out:T; attr=exclusive:bool,default=false; attr=reverse:bool,default=false; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.620988: I tensorflow/core/framework/op.cc:132] Op<name=CustomAggregator; signature=input:float -> output:float; attr=id:string; is_stateful=true>
  2023-01-12 09:34:37.621049: I tensorflow/core/framework/op.cc:132] Op<name=DTensorAllGather; signature=input:T -> output:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_INT32, DT_UINT32, DT_INT64, DT_BOOL]; attr=input_layout:string; attr=output_layout:string>
  2023-01-12 09:34:37.621149: I tensorflow/core/framework/op.cc:132] Op<name=DTensorAllReduce; signature=input:T, group_assignment:int32 -> output:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_INT32, DT_UINT32, DT_INT64, DT_BOOL]; attr=reduce_op:string,allowed=["Min", "Max", "Mul", "Add", "Mean", "Any", "All"]; attr=device_type:string>
  2023-01-12 09:34:37.621214: I tensorflow/core/framework/op.cc:132] Op<name=DTensorAllScatter; signature=input:T -> output:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_INT32, DT_UINT32, DT_INT64, DT_BOOL]; attr=input_layout:string; attr=output_layout:string>
  2023-01-12 09:34:37.621277: I tensorflow/core/framework/op.cc:132] Op<name=DTensorReduceScatter; signature=input:T, group_assignment:int32, scatter_dimension:int32 -> output:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_INT32, DT_UINT32, DT_INT64, DT_BOOL]; attr=reduce_op:string,allowed=["Min", "Max", "Mul", "Add", "Mean", "Any", "All"]; attr=device_type:string>
  2023-01-12 09:34:37.621322: I tensorflow/core/framework/op.cc:132] Op<name=DTensorRestoreV2; signature=prefix:string, tensor_names:string, shape_and_slices:string -> tensors:; attr=input_shapes:list(shape); attr=input_layouts:list(string); attr=dtypes:list(type),min=1; is_stateful=true>
  2023-01-12 09:34:37.621394: I tensorflow/core/framework/op.cc:132] Op<name=DTensorSetGlobalTPUArray; signature=topology:string -> ; is_stateful=true>
  2023-01-12 09:34:37.621434: I tensorflow/core/framework/op.cc:132] Op<name=DataFormatDimMap; signature=x:T -> y:T; attr=T:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=src_format:string,default="NHWC"; attr=dst_format:string,default="NCHW">
  2023-01-12 09:34:37.621456: I tensorflow/core/framework/op.cc:132] Op<name=DataFormatVecPermute; signature=x:T -> y:T; attr=T:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=src_format:string,default="NHWC"; attr=dst_format:string,default="NCHW">
  2023-01-12 09:34:37.621477: I tensorflow/core/framework/op.cc:132] Op<name=DataServiceDataset; signature=dataset_id:int64, processing_mode:string, address:string, protocol:string, job_name:string, max_outstanding_requests:int64, iteration_counter:resource -> handle:variant; attr=task_refresh_interval_hint_ms:int,default=-1; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=data_transfer_protocol:string,default=""; attr=target_workers:string,default="AUTO"; attr=cross_trainer_cache_options:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.621497: I tensorflow/core/framework/op.cc:132] Op<name=DataServiceDatasetV2; signature=dataset_id:int64, processing_mode:string, address:string, protocol:string, job_name:string, consumer_index:int64, num_consumers:int64, max_outstanding_requests:int64, iteration_counter:resource -> handle:variant; attr=task_refresh_interval_hint_ms:int,default=-1; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=data_transfer_protocol:string,default=""; attr=target_workers:string,default="AUTO"; attr=cross_trainer_cache_options:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.621518: I tensorflow/core/framework/op.cc:132] Op<name=DataServiceDatasetV3; signature=dataset_id:int64, processing_mode:string, address:string, protocol:string, job_name:string, consumer_index:int64, num_consumers:int64, max_outstanding_requests:int64, iteration_counter:resource -> handle:variant; attr=task_refresh_interval_hint_ms:int,default=-1; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=data_transfer_protocol:string,default=""; attr=target_workers:string,default="AUTO"; attr=uncompress:bool,default=false; attr=uncompress_fn:func; attr=cross_trainer_cache_options:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.621638: I tensorflow/core/framework/op.cc:132] Op<name=DataServiceDatasetV4; signature=dataset_id:string, processing_mode:string, address:string, protocol:string, job_name:string, consumer_index:int64, num_consumers:int64, max_outstanding_requests:int64, iteration_counter:resource -> handle:variant; attr=task_refresh_interval_hint_ms:int,default=-1; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=data_transfer_protocol:string,default=""; attr=target_workers:string,default="AUTO"; attr=uncompress:bool,default=false; attr=uncompress_fn:func; attr=cross_trainer_cache_options:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.621757: I tensorflow/core/framework/op.cc:132] Op<name=DatasetCardinality; signature=input_dataset:variant -> cardinality:int64>
  2023-01-12 09:34:37.621893: I tensorflow/core/framework/op.cc:132] Op<name=DatasetFromGraph; signature=graph_def:string -> handle:variant>
  2023-01-12 09:34:37.621940: I tensorflow/core/framework/op.cc:132] Op<name=DatasetToGraph; signature=input_dataset:variant -> graph:string; attr=stateful_whitelist:list(string),default=[],min=0; attr=allow_stateful:bool,default=false; attr=strip_device_assignment:bool,default=false>
  2023-01-12 09:34:37.621975: I tensorflow/core/framework/op.cc:132] Op<name=DatasetToGraphV2; signature=input_dataset:variant -> graph:string; attr=external_state_policy:int,default=0; attr=strip_device_assignment:bool,default=false>
  2023-01-12 09:34:37.622046: I tensorflow/core/framework/op.cc:132] Op<name=DatasetToSingleElement; signature=dataset:variant -> components:; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=metadata:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.622079: I tensorflow/core/framework/op.cc:132] Op<name=DatasetToTFRecord; signature=input_dataset:variant, filename:string, compression_type:string -> ; is_stateful=true>
  2023-01-12 09:34:37.622158: I tensorflow/core/framework/op.cc:132] Op<name=Dawsn; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.622193: I tensorflow/core/framework/op.cc:132] Op<name=DebugGradientIdentity; signature=input:T -> output:T; attr=T:type; allows_uninitialized_input=true>
  2023-01-12 09:34:37.622218: I tensorflow/core/framework/op.cc:132] Op<name=DebugGradientRefIdentity; signature=input:Ref(T) -> output:Ref(T); attr=T:type; allows_uninitialized_input=true>
  2023-01-12 09:34:37.622255: I tensorflow/core/framework/op.cc:132] Op<name=DebugIdentity; signature=input:T -> output:T; attr=T:type; attr=device_name:string,default=""; attr=tensor_name:string,default=""; attr=debug_urls:list(string),default=[]; attr=gated_grpc:bool,default=false; allows_uninitialized_input=true>
  2023-01-12 09:34:37.622304: I tensorflow/core/framework/op.cc:132] Op<name=DebugIdentityV2; signature=input:T -> output:T; attr=T:type; attr=tfdbg_context_id:string,default=""; attr=op_name:string,default=""; attr=output_slot:int,default=-1; attr=tensor_debug_mode:int,default=-1; attr=debug_urls:list(string),default=[]; attr=circular_buffer_size:int,default=1000; attr=tfdbg_run_id:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.622652: I tensorflow/core/framework/op.cc:132] Op<name=DebugNanCount; signature=input:T -> output:int64; attr=T:type; attr=device_name:string,default=""; attr=tensor_name:string,default=""; attr=debug_urls:list(string),default=[]; attr=gated_grpc:bool,default=false; allows_uninitialized_input=true>
  2023-01-12 09:34:37.622776: I tensorflow/core/framework/op.cc:132] Op<name=DebugNumericSummary; signature=input:T -> output:double; attr=T:type; attr=device_name:string,default=""; attr=tensor_name:string,default=""; attr=debug_urls:list(string),default=[]; attr=lower_bound:float,default=-inf; attr=upper_bound:float,default=inf; attr=mute_if_healthy:bool,default=false; attr=gated_grpc:bool,default=false; allows_uninitialized_input=true>
  2023-01-12 09:34:37.622892: I tensorflow/core/framework/op.cc:132] Op<name=DebugNumericSummaryV2; signature=input:T -> output:output_dtype; attr=output_dtype:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_DOUBLE]; attr=T:type; attr=tensor_debug_mode:int,default=-1; attr=tensor_id:int,default=-1>
  2023-01-12 09:34:37.623057: I tensorflow/core/framework/op.cc:132] Op<name=DecodeAndCropJpeg; signature=contents:string, crop_window:int32 -> image:uint8; attr=channels:int,default=0; attr=ratio:int,default=1; attr=fancy_upscaling:bool,default=true; attr=try_recover_truncated:bool,default=false; attr=acceptable_fraction:float,default=1; attr=dct_method:string,default="">
  2023-01-12 09:34:37.623109: I tensorflow/core/framework/op.cc:132] Op<name=DecodeBase64; signature=input:string -> output:string>
  2023-01-12 09:34:37.623139: I tensorflow/core/framework/op.cc:132] Op<name=DecodeBmp; signature=contents:string -> image:uint8; attr=channels:int,default=0>
  2023-01-12 09:34:37.623205: I tensorflow/core/framework/op.cc:132] Op<name=DecodeCSV; signature=records:string, record_defaults: -> output:; attr=OUT_TYPE:list(type),min=1,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64, DT_STRING]; attr=field_delim:string,default=","; attr=use_quote_delim:bool,default=true; attr=na_value:string,default=""; attr=select_cols:list(int),default=[]>
  2023-01-12 09:34:37.623256: I tensorflow/core/framework/op.cc:132] Op<name=DecodeCompressed; signature=bytes:string -> output:string; attr=compression_type:string,default="">
  2023-01-12 09:34:37.623297: I tensorflow/core/framework/op.cc:132] Op<name=DecodeGif; signature=contents:string -> image:uint8>
  2023-01-12 09:34:37.623366: I tensorflow/core/framework/op.cc:132] Op<name=DecodeImage; signature=contents:string -> image:dtype; attr=channels:int,default=0; attr=dtype:type,default=DT_UINT8,allowed=[DT_UINT8, DT_UINT16, DT_FLOAT]; attr=expand_animations:bool,default=true>
  2023-01-12 09:34:37.623414: I tensorflow/core/framework/op.cc:132] Op<name=DecodeJSONExample; signature=json_examples:string -> binary_examples:string>
  2023-01-12 09:34:37.623536: I tensorflow/core/framework/op.cc:132] Op<name=DecodeJpeg; signature=contents:string -> image:uint8; attr=channels:int,default=0; attr=ratio:int,default=1; attr=fancy_upscaling:bool,default=true; attr=try_recover_truncated:bool,default=false; attr=acceptable_fraction:float,default=1; attr=dct_method:string,default="">
  2023-01-12 09:34:37.623604: I tensorflow/core/framework/op.cc:132] Op<name=DecodePaddedRaw; signature=input_bytes:string, fixed_length:int32 -> output:out_type; attr=out_type:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT16, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16]; attr=little_endian:bool,default=true>
  2023-01-12 09:34:37.623661: I tensorflow/core/framework/op.cc:132] Op<name=DecodePng; signature=contents:string -> image:dtype; attr=channels:int,default=0; attr=dtype:type,default=DT_UINT8,allowed=[DT_UINT8, DT_UINT16]>
  2023-01-12 09:34:37.623709: I tensorflow/core/framework/op.cc:132] Op<name=DecodeProtoV2; signature=bytes:string -> sizes:int32, values:; attr=message_type:string; attr=field_names:list(string); attr=output_types:list(type),min=0; attr=descriptor_source:string,default="local://"; attr=message_format:string,default="binary"; attr=sanitize:bool,default=false>
  2023-01-12 09:34:37.623759: I tensorflow/core/framework/op.cc:132] Op<name=DecodeRaw; signature=bytes:string -> output:out_type; attr=out_type:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT16, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_COMPLEX64, DT_COMPLEX128, DT_BOOL, DT_BFLOAT16]; attr=little_endian:bool,default=true>
  2023-01-12 09:34:37.623806: I tensorflow/core/framework/op.cc:132] Op<name=DecodeWav; signature=contents:string -> audio:float, sample_rate:int32; attr=desired_channels:int,default=-1; attr=desired_samples:int,default=-1>
  2023-01-12 09:34:37.623838: I tensorflow/core/framework/op.cc:132] Op<name=DeepCopy; signature=x:T -> y:T; attr=T:type; is_stateful=true>
  2023-01-12 09:34:37.627318: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6 kernel_name: "Unknown (from Proto)" tensor { dtype: DT_INT32 shape { } allocation_description { requested_bytes: 4 allocated_bytes: 4 allocator_name: "cpu" allocation_id: 2 has_single_reference: true ptr: 94667551024064 } } }
  2023-01-12 09:34:37.628102: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocation_id: 2 allocator_name: "cpu" }
  2023-01-12 09:34:37.628642: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6 kernel_name: "Unknown (from Proto)" tensor { dtype: DT_INT32 shape { } allocation_description { requested_bytes: 4 allocated_bytes: 4 allocator_name: "cpu" allocation_id: 3 has_single_reference: true ptr: 94667551025408 } } }
  2023-01-12 09:34:37.630362: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocation_id: 3 allocator_name: "cpu" }
  2023-01-12 09:34:37.630726: I tensorflow/core/framework/op.cc:132] Op<name=DefaultAttrs; signature= -> ; attr=string_val:string,default="abc"; attr=string_list_val:list(string),default=["abc", ""]; attr=int_val:int,default=123; attr=int_list_val:list(int),default=[1, 2, 3]; attr=float_val:float,default=10; attr=float_list_val:list(float),default=[10]; attr=bool_val:bool,default=true; attr=bool_list_val:list(bool),default=[true, false]; attr=type_val:type,default=DT_INT32; attr=type_list_val:list(type),default=[DT_INT32, DT_FLOAT]; attr=shape_val:shape,default=[2,1]; attr=shape_list_val:list(shape),default=[[], [1]]; attr=tensor_val:tensor,default=Tensor<type: int32 shape: [] values: 1>; attr=tensor_list_val:list(tensor),default=[Tensor<type: int32 shape: [] values: 1>]>
  2023-01-12 09:34:37.630821: I tensorflow/core/framework/op.cc:132] Op<name=DeleteIterator; signature=handle:resource, deleter:variant -> ; is_stateful=true>
  2023-01-12 09:34:37.630886: I tensorflow/core/framework/op.cc:132] Op<name=DeleteMemoryCache; signature=handle:resource, deleter:variant -> ; is_stateful=true>
  2023-01-12 09:34:37.630935: I tensorflow/core/framework/op.cc:132] Op<name=DeleteMultiDeviceIterator; signature=multi_device_iterator:resource, iterators:N*resource, deleter:variant -> ; attr=N:int,min=0; is_stateful=true>
  2023-01-12 09:34:37.630981: I tensorflow/core/framework/op.cc:132] Op<name=DeleteRandomSeedGenerator; signature=handle:resource, deleter:variant -> ; is_stateful=true>
  2023-01-12 09:34:37.630996: I tensorflow/core/framework/op.cc:132] Op<name=DeleteRpcFutureResource; signature=handle:resource, deleter:variant -> ; is_stateful=true>
  2023-01-12 09:34:37.631005: I tensorflow/core/framework/op.cc:132] Op<name=DeleteSeedGenerator; signature=handle:resource, deleter:variant -> ; is_stateful=true>
  2023-01-12 09:34:37.631014: I tensorflow/core/framework/op.cc:132] Op<name=DeleteSessionTensor; signature=handle:string -> ; is_stateful=true>
  2023-01-12 09:34:37.631042: I tensorflow/core/framework/op.cc:132] Op<name=DenseBincount; signature=input:Tidx, size:Tidx, weights:T -> output:T; attr=Tidx:type,allowed=[DT_INT32, DT_INT64]; attr=T:type,allowed=[DT_INT32, DT_INT64, DT_FLOAT, DT_DOUBLE]; attr=binary_output:bool,default=false>
  2023-01-12 09:34:37.631272: I tensorflow/core/framework/op.cc:132] Op<name=DenseCountSparseOutput; signature=values:T, weights:output_type -> output_indices:int64, output_values:output_type, output_dense_shape:int64; attr=T:type,allowed=[DT_INT32, DT_INT64]; attr=minlength:int,default=-1,min=-1; attr=maxlength:int,default=-1,min=-1; attr=binary_output:bool; attr=output_type:type,allowed=[DT_INT32, DT_INT64, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.631353: I tensorflow/core/framework/op.cc:132] Op<name=DenseToCSRSparseMatrix; signature=dense_input:T, indices:int64 -> sparse_output:variant; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.631396: I tensorflow/core/framework/op.cc:132] Op<name=DenseToDenseSetOperation; signature=set1:T, set2:T -> result_indices:int64, result_values:T, result_shape:int64; attr=set_operation:string; attr=validate_indices:bool,default=true; attr=T:type,allowed=[DT_INT8, DT_INT16, DT_INT32, DT_INT64, DT_UINT8, DT_UINT16, DT_STRING]>
  2023-01-12 09:34:37.631479: I tensorflow/core/framework/op.cc:132] Op<name=DenseToSparseBatchDataset; signature=input_dataset:variant, batch_size:int64, row_shape:int64 -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1>
  2023-01-12 09:34:37.631529: I tensorflow/core/framework/op.cc:132] Op<name=DenseToSparseSetOperation; signature=set1:T, set2_indices:int64, set2_values:T, set2_shape:int64 -> result_indices:int64, result_values:T, result_shape:int64; attr=set_operation:string; attr=validate_indices:bool,default=true; attr=T:type,allowed=[DT_INT8, DT_INT16, DT_INT32, DT_INT64, DT_UINT8, DT_UINT16, DT_STRING]>
  2023-01-12 09:34:37.631609: I tensorflow/core/framework/op.cc:132] Op<name=DepthToSpace; signature=input:T -> output:T; attr=T:type; attr=block_size:int,min=2; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW", "NCHW_VECT_C"]>
  2023-01-12 09:34:37.631676: I tensorflow/core/framework/op.cc:132] Op<name=DepthwiseConv2dNative; signature=input:T, filter:T -> output:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]; attr=strides:list(int); attr=padding:string,allowed=["SAME", "VALID", "EXPLICIT"]; attr=explicit_paddings:list(int),default=[]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=dilations:list(int),default=[1, 1, 1, 1]>
  2023-01-12 09:34:37.631744: I tensorflow/core/framework/op.cc:132] Op<name=DepthwiseConv2dNativeBackpropFilter; signature=input:T, filter_sizes:int32, out_backprop:T -> output:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]; attr=strides:list(int); attr=padding:string,allowed=["SAME", "VALID", "EXPLICIT"]; attr=explicit_paddings:list(int),default=[]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=dilations:list(int),default=[1, 1, 1, 1]>
  2023-01-12 09:34:37.631811: I tensorflow/core/framework/op.cc:132] Op<name=DepthwiseConv2dNativeBackpropInput; signature=input_sizes:int32, filter:T, out_backprop:T -> output:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]; attr=strides:list(int); attr=padding:string,allowed=["SAME", "VALID", "EXPLICIT"]; attr=explicit_paddings:list(int),default=[]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=dilations:list(int),default=[1, 1, 1, 1]>
  2023-01-12 09:34:37.631891: I tensorflow/core/framework/op.cc:132] Op<name=Dequantize; signature=input:T, min_range:float, max_range:float -> output:dtype; attr=T:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=mode:string,default="MIN_COMBINED",allowed=["MIN_COMBINED", "MIN_FIRST", "SCALED"]; attr=narrow_range:bool,default=false; attr=axis:int,default=-1; attr=dtype:type,default=DT_FLOAT,allowed=[DT_BFLOAT16, DT_FLOAT]>
  2023-01-12 09:34:37.632118: I tensorflow/core/framework/op.cc:132] Op<name=DeserializeIterator; signature=resource_handle:resource, serialized:variant -> ; is_stateful=true>
  2023-01-12 09:34:37.632161: I tensorflow/core/framework/op.cc:132] Op<name=DeserializeManySparse; signature=serialized_sparse:string -> sparse_indices:int64, sparse_values:dtype, sparse_shape:int64; attr=dtype:type>
  2023-01-12 09:34:37.632312: I tensorflow/core/framework/op.cc:132] Op<name=DeserializeSparse; signature=serialized_sparse:Tserialized -> sparse_indices:int64, sparse_values:dtype, sparse_shape:int64; attr=dtype:type; attr=Tserialized:type,default=DT_STRING,allowed=[DT_STRING, DT_VARIANT]>
  2023-01-12 09:34:37.632385: I tensorflow/core/framework/op.cc:132] Op<name=DestroyResourceOp; signature=resource:resource -> ; attr=ignore_lookup_error:bool,default=true; is_stateful=true>
  2023-01-12 09:34:37.632430: I tensorflow/core/framework/op.cc:132] Op<name=DestroyTemporaryVariable; signature=ref:Ref(T) -> value:T; attr=T:type; attr=var_name:string>
  2023-01-12 09:34:37.632462: I tensorflow/core/framework/op.cc:132] Op<name=DeviceIndex; signature= -> index:int32; attr=device_names:list(string); is_stateful=true>
  2023-01-12 09:34:37.632491: I tensorflow/core/framework/op.cc:132] Op<name=DevicePlacementOp; signature= -> device:string; is_stateful=true>
  2023-01-12 09:34:37.632540: I tensorflow/core/framework/op.cc:132] Op<name=Diag; signature=diagonal:T -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.632742: I tensorflow/core/framework/op.cc:132] Op<name=DiagPart; signature=input:T -> diagonal:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.632838: I tensorflow/core/framework/op.cc:132] Op<name=Digamma; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.633009: I tensorflow/core/framework/op.cc:132] Op<name=Dilation2D; signature=input:T, filter:T -> output:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]; attr=strides:list(int),min=4; attr=rates:list(int),min=4; attr=padding:string,allowed=["SAME", "VALID"]>
  2023-01-12 09:34:37.633140: I tensorflow/core/framework/op.cc:132] Op<name=Dilation2DBackpropFilter; signature=input:T, filter:T, out_backprop:T -> filter_backprop:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]; attr=strides:list(int),min=4; attr=rates:list(int),min=4; attr=padding:string,allowed=["SAME", "VALID"]>
  2023-01-12 09:34:37.633243: I tensorflow/core/framework/op.cc:132] Op<name=Dilation2DBackpropInput; signature=input:T, filter:T, out_backprop:T -> in_backprop:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]; attr=strides:list(int),min=4; attr=rates:list(int),min=4; attr=padding:string,allowed=["SAME", "VALID"]>
  2023-01-12 09:34:37.633323: I tensorflow/core/framework/op.cc:132] Op<name=DirectedInterleaveDataset; signature=selector_input_dataset:variant, data_input_datasets:N*variant -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=N:int,min=1; attr=stop_on_empty_dataset:bool,default=false>
  2023-01-12 09:34:37.633381: I tensorflow/core/framework/op.cc:132] Op<name=DisableCopyOnRead; signature=resource:resource -> ; is_stateful=true>
  2023-01-12 09:34:37.633435: I tensorflow/core/framework/op.cc:132] Op<name=Div; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_INT32, DT_UINT32, DT_UINT64, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.633504: I tensorflow/core/framework/op.cc:132] Op<name=DivNoNan; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_BFLOAT16, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.633610: I tensorflow/core/framework/op.cc:132] Op<name=DrawBoundingBoxes; signature=images:T, boxes:float -> output:T; attr=T:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_HALF]>
  2023-01-12 09:34:37.633679: I tensorflow/core/framework/op.cc:132] Op<name=DrawBoundingBoxesV2; signature=images:T, boxes:float, colors:float -> output:T; attr=T:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_HALF]>
  2023-01-12 09:34:37.633745: I tensorflow/core/framework/op.cc:132] Op<name=DtypeWithDefaultOp; signature=in:T -> dtype:string; attr=T:type,default=DT_UINT8; is_stateful=true>
  2023-01-12 09:34:37.633810: I tensorflow/core/framework/op.cc:132] Op<name=DummyIterationCounter; signature= -> handle:resource; is_stateful=true>
  2023-01-12 09:34:37.633879: I tensorflow/core/framework/op.cc:132] Op<name=DummyMemoryCache; signature= -> handle:resource; is_stateful=true>
  2023-01-12 09:34:37.633935: I tensorflow/core/framework/op.cc:132] Op<name=DummySeedGenerator; signature= -> handle:resource; is_stateful=true>
  2023-01-12 09:34:37.634021: I tensorflow/core/framework/op.cc:132] Op<name=DynamicEnqueueTPUEmbeddingArbitraryTensorBatch; signature=sample_indices_or_row_splits:N*T1, embedding_indices:N*T2, aggregation_weights:N*T3, mode_override:string, device_ordinal:int32 -> ; attr=T1:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=T2:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=T3:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_DOUBLE]; attr=N:int,min=1; attr=combiners:list(string),default=[]; is_stateful=true>
  2023-01-12 09:34:37.634094: I tensorflow/core/framework/op.cc:132] Op<name=DynamicPartition; signature=data:T, partitions:int32 -> outputs:num_partitions*T; attr=num_partitions:int,min=1; attr=T:type>
  2023-01-12 09:34:37.634159: I tensorflow/core/framework/op.cc:132] Op<name=DynamicStitch; signature=indices:N*int32, data:N*T -> merged:T; attr=N:int,min=1; attr=T:type>
  2023-01-12 09:34:37.634227: I tensorflow/core/framework/op.cc:132] Op<name=EagerPyFunc; signature=input: -> output:; attr=token:string; attr=is_async:bool,default=false; attr=Tin:list(type),min=0; attr=Tout:list(type),min=0; is_stateful=true>
  2023-01-12 09:34:37.634305: I tensorflow/core/framework/op.cc:132] Op<name=EditDistance; signature=hypothesis_indices:int64, hypothesis_values:T, hypothesis_shape:int64, truth_indices:int64, truth_values:T, truth_shape:int64 -> output:float; attr=normalize:bool,default=true; attr=T:type>
  2023-01-12 09:34:37.634407: I tensorflow/core/framework/op.cc:132] Op<name=Eig; signature=input:T -> e:Tout, v:Tout; attr=compute_v:bool,default=true; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]; attr=Tout:type,allowed=[DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.634477: I tensorflow/core/framework/op.cc:132] Op<name=Einsum; signature=inputs:N*T -> output:T; attr=equation:string; attr=N:int,min=1; attr=T:type>
  2023-01-12 09:34:37.634547: I tensorflow/core/framework/op.cc:132] Op<name=Elu; signature=features:T -> activations:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.634674: I tensorflow/core/framework/op.cc:132] Op<name=EluGrad; signature=gradients:T, outputs:T -> backprops:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.634739: I tensorflow/core/framework/op.cc:132] Op<name=Empty; signature=shape:int32 -> output:dtype; attr=dtype:type; attr=init:bool,default=false; is_stateful=true>
  2023-01-12 09:34:37.634812: I tensorflow/core/framework/op.cc:132] Op<name=EmptyTensorList; signature=element_shape:shape_type, max_num_elements:int32 -> handle:variant; attr=element_dtype:type; attr=shape_type:type,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.634873: I tensorflow/core/framework/op.cc:132] Op<name=EmptyTensorMap; signature= -> handle:variant>
  2023-01-12 09:34:37.634942: I tensorflow/core/framework/op.cc:132] Op<name=EncodeBase64; signature=input:string -> output:string; attr=pad:bool,default=false>
  2023-01-12 09:34:37.635022: I tensorflow/core/framework/op.cc:132] Op<name=EncodeJpeg; signature=image:uint8 -> contents:string; attr=format:string,default="",allowed=["", "grayscale", "rgb"]; attr=quality:int,default=95; attr=progressive:bool,default=false; attr=optimize_size:bool,default=false; attr=chroma_downsampling:bool,default=true; attr=density_unit:string,default="in",allowed=["in", "cm"]; attr=x_density:int,default=300; attr=y_density:int,default=300; attr=xmp_metadata:string,default="">
  2023-01-12 09:34:37.635090: I tensorflow/core/framework/op.cc:132] Op<name=EncodeJpegVariableQuality; signature=images:uint8, quality:int32 -> contents:string>
  2023-01-12 09:34:37.635164: I tensorflow/core/framework/op.cc:132] Op<name=EncodePng; signature=image:T -> contents:string; attr=compression:int,default=-1; attr=T:type,default=DT_UINT8,allowed=[DT_UINT8, DT_UINT16]>
  2023-01-12 09:34:37.635245: I tensorflow/core/framework/op.cc:132] Op<name=EncodeProto; signature=sizes:int32, values: -> bytes:string; attr=field_names:list(string); attr=message_type:string; attr=descriptor_source:string,default="local://"; attr=Tinput_types:list(type),min=1>
  2023-01-12 09:34:37.635314: I tensorflow/core/framework/op.cc:132] Op<name=EncodeWav; signature=audio:float, sample_rate:int32 -> contents:string>
  2023-01-12 09:34:37.635353: I tensorflow/core/framework/op.cc:132] Op<name=EnqueueTPUEmbeddingArbitraryTensorBatch; signature=sample_indices_or_row_splits:N*T1, embedding_indices:N*T2, aggregation_weights:N*T3, mode_override:string -> ; attr=T1:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=T2:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=T3:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_DOUBLE]; attr=N:int,min=1; attr=device_ordinal:int,default=-1; attr=combiners:list(string),default=[]; is_stateful=true>
  2023-01-12 09:34:37.635401: I tensorflow/core/framework/op.cc:132] Op<name=EnqueueTPUEmbeddingBatch; signature=batch:N*string, mode_override:string -> ; attr=N:int,min=1; attr=device_ordinal:int,default=-1; attr=combiners:list(string),default=[]; is_stateful=true>
  2023-01-12 09:34:37.635450: I tensorflow/core/framework/op.cc:132] Op<name=EnqueueTPUEmbeddingIntegerBatch; signature=batch:N*int32, mode_override:string -> ; attr=N:int,min=1; attr=device_ordinal:int,default=-1; is_stateful=true>
  2023-01-12 09:34:37.635598: I tensorflow/core/framework/op.cc:132] Op<name=EnqueueTPUEmbeddingRaggedTensorBatch; signature=sample_splits:N*T1, embedding_indices:N*T2, aggregation_weights:N*T3, mode_override:string -> ; attr=T1:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=T2:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=T3:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_DOUBLE]; attr=N:int,min=1; attr=device_ordinal:int,default=-1; attr=combiners:list(string),default=[]; attr=table_ids:list(int); attr=max_sequence_lengths:list(int),default=[]; attr=num_features:list(int),default=[]; is_stateful=true>
  2023-01-12 09:34:37.635672: I tensorflow/core/framework/op.cc:132] Op<name=EnqueueTPUEmbeddingSparseBatch; signature=sample_indices:N*T1, embedding_indices:N*T2, aggregation_weights:N*T3, mode_override:string -> ; attr=T1:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=T2:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=T3:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_DOUBLE]; attr=N:int,min=1; attr=device_ordinal:int,default=-1; attr=combiners:list(string),default=[]; is_stateful=true>
  2023-01-12 09:34:37.635762: I tensorflow/core/framework/op.cc:132] Op<name=EnqueueTPUEmbeddingSparseTensorBatch; signature=sample_indices:N*T1, embedding_indices:N*T2, aggregation_weights:N*T3, mode_override:string -> ; attr=T1:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=T2:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=T3:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_DOUBLE]; attr=N:int,min=1; attr=device_ordinal:int,default=-1; attr=combiners:list(string),default=[]; attr=table_ids:list(int); attr=max_sequence_lengths:list(int),default=[]; attr=num_features:list(int),default=[]; is_stateful=true>
  2023-01-12 09:34:37.635811: I tensorflow/core/framework/op.cc:132] Op<name=EnsureShape; signature=input:T -> output:T; attr=shape:shape; attr=T:type>
  2023-01-12 09:34:37.635864: I tensorflow/core/framework/op.cc:132] Op<name=Enter; signature=data:T -> output:T; attr=T:type; attr=frame_name:string; attr=is_constant:bool,default=false; attr=parallel_iterations:int,default=10>
  2023-01-12 09:34:37.635938: I tensorflow/core/framework/op.cc:132] Op<name=Equal; signature=x:T, y:T -> z:bool; attr=T:type; attr=incompatible_shape_error:bool,default=true; is_commutative=true>
  2023-01-12 09:34:37.636002: I tensorflow/core/framework/op.cc:132] Op<name=Erf; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.636054: I tensorflow/core/framework/op.cc:132] Op<name=Erfc; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.636132: I tensorflow/core/framework/op.cc:132] Op<name=Erfinv; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.636277: I tensorflow/core/framework/op.cc:132] Op<name=EuclideanNorm; signature=input:T, reduction_indices:Tidx -> output:T; attr=keep_dims:bool,default=false; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.636342: I tensorflow/core/framework/op.cc:132] Op<name=ExecuteTPUEmbeddingPartitioner; signature= -> common_config:string; attr=config:string; is_stateful=true>
  2023-01-12 09:34:37.636399: I tensorflow/core/framework/op.cc:132] Op<name=Exit; signature=data:T -> output:T; attr=T:type>
  2023-01-12 09:34:37.636529: I tensorflow/core/framework/op.cc:132] Op<name=Exp; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.636622: I tensorflow/core/framework/op.cc:132] Op<name=ExpandDims; signature=input:T, dim:Tdim -> output:T; attr=T:type; attr=Tdim:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.636721: I tensorflow/core/framework/op.cc:132] Op<name=ExperimentalAssertNextDataset; signature=input_dataset:variant, transformations:string -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1>
  2023-01-12 09:34:37.636811: I tensorflow/core/framework/op.cc:132] Op<name=ExperimentalAutoShardDataset; signature=input_dataset:variant, num_workers:int64, index:int64 -> handle:variant; attr=auto_shard_policy:int,default=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1>
  2023-01-12 09:34:37.636848: I tensorflow/core/framework/op.cc:132] Op<name=ExperimentalBytesProducedStatsDataset; signature=input_dataset:variant, tag:string -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1>
  2023-01-12 09:34:37.636945: I tensorflow/core/framework/op.cc:132] Op<name=ExperimentalCSVDataset; signature=filenames:string, compression_type:string, buffer_size:int64, header:bool, field_delim:string, use_quote_delim:bool, na_value:string, select_cols:int64, record_defaults: -> handle:variant; attr=output_types:list(type),min=1,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64, DT_STRING]; attr=output_shapes:list(shape),min=1; is_stateful=true>
  2023-01-12 09:34:37.637006: I tensorflow/core/framework/op.cc:132] Op<name=ExperimentalChooseFastestDataset; signature=input_datasets:N*variant -> handle:variant; attr=N:int,min=2; attr=num_experiments:int; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1>
  2023-01-12 09:34:37.637060: I tensorflow/core/framework/op.cc:132] Op<name=ExperimentalDatasetCardinality; signature=input_dataset:variant -> cardinality:int64>
  2023-01-12 09:34:37.637080: I tensorflow/core/framework/op.cc:132] Op<name=ExperimentalDatasetToTFRecord; signature=input_dataset:variant, filename:string, compression_type:string -> ; is_stateful=true>
  2023-01-12 09:34:37.637217: I tensorflow/core/framework/op.cc:132] Op<name=ExperimentalDenseToSparseBatchDataset; signature=input_dataset:variant, batch_size:int64, row_shape:int64 -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1>
  2023-01-12 09:34:37.637348: I tensorflow/core/framework/op.cc:132] Op<name=ExperimentalDirectedInterleaveDataset; signature=selector_input_dataset:variant, data_input_datasets:N*variant -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=N:int,min=1>
  2023-01-12 09:34:37.637594: I tensorflow/core/framework/op.cc:132] Op<name=ExperimentalGroupByReducerDataset; signature=input_dataset:variant, key_func_other_arguments:, init_func_other_arguments:, reduce_func_other_arguments:, finalize_func_other_arguments: -> handle:variant; attr=key_func:func; attr=init_func:func; attr=reduce_func:func; attr=finalize_func:func; attr=Tkey_func_other_arguments:list(type),min=0; attr=Tinit_func_other_arguments:list(type),min=0; attr=Treduce_func_other_arguments:list(type),min=0; attr=Tfinalize_func_other_arguments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; is_stateful=true>
  2023-01-12 09:34:37.637732: I tensorflow/core/framework/op.cc:132] Op<name=ExperimentalGroupByWindowDataset; signature=input_dataset:variant, key_func_other_arguments:, reduce_func_other_arguments:, window_size_func_other_arguments: -> handle:variant; attr=key_func:func; attr=reduce_func:func; attr=window_size_func:func; attr=Tkey_func_other_arguments:list(type),min=0; attr=Treduce_func_other_arguments:list(type),min=0; attr=Twindow_size_func_other_arguments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1>
  2023-01-12 09:34:37.637833: I tensorflow/core/framework/op.cc:132] Op<name=ExperimentalIgnoreErrorsDataset; signature=input_dataset:variant -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=log_warning:bool,default=false>
  2023-01-12 09:34:37.637941: I tensorflow/core/framework/op.cc:132] Op<name=ExperimentalIteratorGetDevice; signature=resource:resource -> device:string; is_stateful=true>
  2023-01-12 09:34:37.638015: I tensorflow/core/framework/op.cc:132] Op<name=ExperimentalLMDBDataset; signature=filenames:string -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; is_stateful=true>
  2023-01-12 09:34:37.638086: I tensorflow/core/framework/op.cc:132] Op<name=ExperimentalLatencyStatsDataset; signature=input_dataset:variant, tag:string -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1>
  2023-01-12 09:34:37.638165: I tensorflow/core/framework/op.cc:132] Op<name=ExperimentalMapAndBatchDataset; signature=input_dataset:variant, other_arguments:, batch_size:int64, num_parallel_calls:int64, drop_remainder:bool -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=preserve_cardinality:bool,default=false>
  2023-01-12 09:34:37.638254: I tensorflow/core/framework/op.cc:132] Op<name=ExperimentalMapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false>
  2023-01-12 09:34:37.638290: I tensorflow/core/framework/op.cc:132] Op<name=ExperimentalMatchingFilesDataset; signature=patterns:string -> handle:variant; is_stateful=true>
  2023-01-12 09:34:37.638364: I tensorflow/core/framework/op.cc:132] Op<name=ExperimentalMaxIntraOpParallelismDataset; signature=input_dataset:variant, max_intra_op_parallelism:int64 -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1>
  2023-01-12 09:34:37.638458: I tensorflow/core/framework/op.cc:132] Op<name=ExperimentalNonSerializableDataset; signature=input_dataset:variant -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1>
  2023-01-12 09:34:37.638523: I tensorflow/core/framework/op.cc:132] Op<name=ExperimentalParallelInterleaveDataset; signature=input_dataset:variant, other_arguments:, cycle_length:int64, block_length:int64, sloppy:bool, buffer_output_elements:int64, prefetch_input_elements:int64 -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1>
  2023-01-12 09:34:37.638572: I tensorflow/core/framework/op.cc:132] Op<name=ExperimentalParseExampleDataset; signature=input_dataset:variant, num_parallel_calls:int64, dense_defaults: -> handle:variant; attr=sparse_keys:list(string),min=0; attr=dense_keys:list(string),min=0; attr=sparse_types:list(type),min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=Tdense:list(type),min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=dense_shapes:list(shape),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=sloppy:bool,default=false>
  2023-01-12 09:34:37.638601: I tensorflow/core/framework/op.cc:132] Op<name=ExperimentalPrivateThreadPoolDataset; signature=input_dataset:variant, num_threads:int64 -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1>
  2023-01-12 09:34:37.638701: I tensorflow/core/framework/op.cc:132] Op<name=ExperimentalRandomDataset; signature=seed:int64, seed2:int64 -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; is_stateful=true>
  2023-01-12 09:34:37.638853: I tensorflow/core/framework/op.cc:132] Op<name=ExperimentalRebatchDataset; signature=input_dataset:variant, num_replicas:int64 -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_fallback:bool,default=true>
  2023-01-12 09:34:37.638943: I tensorflow/core/framework/op.cc:132] Op<name=ExperimentalScanDataset; signature=input_dataset:variant, initial_state:, other_arguments: -> handle:variant; attr=f:func; attr=Tstate:list(type),min=1; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=preserve_cardinality:bool,default=false>
  2023-01-12 09:34:37.639093: I tensorflow/core/framework/op.cc:132] Op<name=ExperimentalSetStatsAggregatorDataset; signature=input_dataset:variant, stats_aggregator:resource, tag:string, counter_prefix:string -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; is_stateful=true>
  2023-01-12 09:34:37.639186: I tensorflow/core/framework/op.cc:132] Op<name=ExperimentalSleepDataset; signature=input_dataset:variant, sleep_microseconds:int64 -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1>
  2023-01-12 09:34:37.639227: I tensorflow/core/framework/op.cc:132] Op<name=ExperimentalSlidingWindowDataset; signature=input_dataset:variant, window_size:int64, window_shift:int64, window_stride:int64 -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1>
  2023-01-12 09:34:37.639294: I tensorflow/core/framework/op.cc:132] Op<name=ExperimentalSqlDataset; signature=driver_name:string, data_source_name:string, query:string -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; is_stateful=true>
  2023-01-12 09:34:37.639368: I tensorflow/core/framework/op.cc:132] Op<name=ExperimentalStatsAggregatorHandle; signature= -> handle:resource; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.639480: I tensorflow/core/framework/op.cc:132] Op<name=ExperimentalStatsAggregatorSummary; signature=iterator:resource -> summary:string; is_stateful=true>
  2023-01-12 09:34:37.639551: I tensorflow/core/framework/op.cc:132] Op<name=ExperimentalTakeWhileDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=predicate:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1>
  2023-01-12 09:34:37.639579: I tensorflow/core/framework/op.cc:132] Op<name=ExperimentalThreadPoolDataset; signature=input_dataset:variant, thread_pool:resource -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; is_stateful=true>
  2023-01-12 09:34:37.639600: I tensorflow/core/framework/op.cc:132] Op<name=ExperimentalThreadPoolHandle; signature= -> handle:resource; attr=num_threads:int; attr=max_intra_op_parallelism:int,default=1; attr=display_name:string; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.639657: I tensorflow/core/framework/op.cc:132] Op<name=ExperimentalUnbatchDataset; signature=input_dataset:variant -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1>
  2023-01-12 09:34:37.639690: I tensorflow/core/framework/op.cc:132] Op<name=ExperimentalUniqueDataset; signature=input_dataset:variant -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1>
  2023-01-12 09:34:37.639761: I tensorflow/core/framework/op.cc:132] Op<name=Expint; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.639794: I tensorflow/core/framework/op.cc:132] Op<name=Expm1; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.639868: I tensorflow/core/framework/op.cc:132] Op<name=ExtractGlimpse; signature=input:float, size:int32, offsets:float -> glimpse:float; attr=centered:bool,default=true; attr=normalized:bool,default=true; attr=uniform_noise:bool,default=true; attr=noise:string,default="uniform">
  2023-01-12 09:34:37.639933: I tensorflow/core/framework/op.cc:132] Op<name=ExtractGlimpseV2; signature=input:float, size:int32, offsets:float -> glimpse:float; attr=centered:bool,default=true; attr=normalized:bool,default=true; attr=uniform_noise:bool,default=true; attr=noise:string,default="uniform">
  2023-01-12 09:34:37.640012: I tensorflow/core/framework/op.cc:132] Op<name=ExtractImagePatches; signature=images:T -> patches:T; attr=ksizes:list(int),min=4; attr=strides:list(int),min=4; attr=rates:list(int),min=4; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT8, 13426711389993069653, DT_UINT32, DT_UINT64, DT_COMPLEX64, DT_COMPLEX128, DT_BOOL]; attr=padding:string,allowed=["SAME", "VALID"]>
  2023-01-12 09:34:37.640103: I tensorflow/core/framework/op.cc:132] Op<name=ExtractJpegShape; signature=contents:string -> image_shape:output_type; attr=output_type:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.640207: I tensorflow/core/framework/op.cc:132] Op<name=ExtractVolumePatches; signature=input:T -> patches:T; attr=ksizes:list(int),min=5; attr=strides:list(int),min=5; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]; attr=padding:string,allowed=["SAME", "VALID"]>
  2023-01-12 09:34:37.640255: I tensorflow/core/framework/op.cc:132] Op<name=FFT; signature=input:Tcomplex -> output:Tcomplex; attr=Tcomplex:type,default=DT_COMPLEX64,allowed=[DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.640322: I tensorflow/core/framework/op.cc:132] Op<name=FFT2D; signature=input:Tcomplex -> output:Tcomplex; attr=Tcomplex:type,default=DT_COMPLEX64,allowed=[DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.640354: I tensorflow/core/framework/op.cc:132] Op<name=FFT3D; signature=input:Tcomplex -> output:Tcomplex; attr=Tcomplex:type,default=DT_COMPLEX64,allowed=[DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.640442: I tensorflow/core/framework/op.cc:132] Op<name=FIFOQueue; signature= -> handle:Ref(string); attr=component_types:list(type),min=1; attr=shapes:list(shape),default=[],min=0; attr=capacity:int,default=-1; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.640526: I tensorflow/core/framework/op.cc:132] Op<name=FIFOQueueV2; signature= -> handle:resource; attr=component_types:list(type),min=1; attr=shapes:list(shape),default=[],min=0; attr=capacity:int,default=-1; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.640556: I tensorflow/core/framework/op.cc:132] Op<name=Fact; signature= -> fact:string>
  2023-01-12 09:34:37.640575: I tensorflow/core/framework/op.cc:132] Op<name=FakeParam; signature= -> output:dtype; attr=dtype:type; attr=shape:shape>
  2023-01-12 09:34:37.640613: I tensorflow/core/framework/op.cc:132] Op<name=FakeQuantWithMinMaxArgs; signature=inputs:float -> outputs:float; attr=min:float,default=-6; attr=max:float,default=6; attr=num_bits:int,default=8; attr=narrow_range:bool,default=false>
  2023-01-12 09:34:37.640700: I tensorflow/core/framework/op.cc:132] Op<name=FakeQuantWithMinMaxArgsGradient; signature=gradients:float, inputs:float -> backprops:float; attr=min:float,default=-6; attr=max:float,default=6; attr=num_bits:int,default=8; attr=narrow_range:bool,default=false>
  2023-01-12 09:34:37.640761: I tensorflow/core/framework/op.cc:132] Op<name=FakeQuantWithMinMaxVars; signature=inputs:float, min:float, max:float -> outputs:float; attr=num_bits:int,default=8; attr=narrow_range:bool,default=false>
  2023-01-12 09:34:37.640814: I tensorflow/core/framework/op.cc:132] Op<name=FakeQuantWithMinMaxVarsGradient; signature=gradients:float, inputs:float, min:float, max:float -> backprops_wrt_input:float, backprop_wrt_min:float, backprop_wrt_max:float; attr=num_bits:int,default=8; attr=narrow_range:bool,default=false>
  2023-01-12 09:34:37.640920: I tensorflow/core/framework/op.cc:132] Op<name=FakeQuantWithMinMaxVarsPerChannel; signature=inputs:float, min:float, max:float -> outputs:float; attr=num_bits:int,default=8; attr=narrow_range:bool,default=false>
  2023-01-12 09:34:37.641009: I tensorflow/core/framework/op.cc:132] Op<name=FakeQuantWithMinMaxVarsPerChannelGradient; signature=gradients:float, inputs:float, min:float, max:float -> backprops_wrt_input:float, backprop_wrt_min:float, backprop_wrt_max:float; attr=num_bits:int,default=8; attr=narrow_range:bool,default=false>
  2023-01-12 09:34:37.641027: I tensorflow/core/framework/op.cc:132] Op<name=FakeQueue; signature=resource:resource -> handle:Ref(string); is_stateful=true>
  2023-01-12 09:34:37.683400: I tensorflow/core/framework/op.cc:132] Op<name=FileSystemSetConfiguration; signature=scheme:string, key:string, value:string -> ; is_stateful=true>
  2023-01-12 09:34:37.683541: I tensorflow/core/framework/op.cc:132] Op<name=Fill; signature=dims:index_type, value:T -> output:T; attr=T:type; attr=index_type:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.683678: I tensorflow/core/framework/op.cc:132] Op<name=FilterByLastComponentDataset; signature=input_dataset:variant -> output:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1>
  2023-01-12 09:34:37.683735: I tensorflow/core/framework/op.cc:132] Op<name=FilterDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=predicate:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=metadata:string,default="">
  2023-01-12 09:34:37.683785: I tensorflow/core/framework/op.cc:132] Op<name=FinalizeDataset; signature=input_dataset:variant -> handle:variant; attr=has_captured_ref:bool,default=false; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1>
  2023-01-12 09:34:37.683833: I tensorflow/core/framework/op.cc:132] Op<name=FinalizeTPUEmbedding; signature=common_config:string, memory_config:string -> ; is_stateful=true>
  2023-01-12 09:34:37.684111: I tensorflow/core/framework/op.cc:132] Op<name=Fingerprint; signature=data:T, method:string -> fingerprint:uint8; attr=T:type>
  2023-01-12 09:34:37.684577: I tensorflow/core/framework/op.cc:132] Op<name=FiveFloatOutputs; signature= -> a:float, b:float, c:float, d:float, e:float>
  2023-01-12 09:34:37.684810: I tensorflow/core/framework/op.cc:132] Op<name=FixedLengthRecordDataset; signature=filenames:string, header_bytes:int64, record_bytes:int64, footer_bytes:int64, buffer_size:int64 -> handle:variant; attr=metadata:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.684979: I tensorflow/core/framework/op.cc:132] Op<name=FixedLengthRecordDatasetV2; signature=filenames:string, header_bytes:int64, record_bytes:int64, footer_bytes:int64, buffer_size:int64, compression_type:string -> handle:variant; attr=metadata:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.685149: I tensorflow/core/framework/op.cc:132] Op<name=FixedLengthRecordReader; signature= -> reader_handle:Ref(string); attr=header_bytes:int,default=0; attr=record_bytes:int; attr=footer_bytes:int,default=0; attr=hop_bytes:int,default=0; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.685433: I tensorflow/core/framework/op.cc:132] Op<name=FixedLengthRecordReaderV2; signature= -> reader_handle:resource; attr=header_bytes:int,default=0; attr=record_bytes:int; attr=footer_bytes:int,default=0; attr=hop_bytes:int,default=0; attr=container:string,default=""; attr=shared_name:string,default=""; attr=encoding:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.685783: I tensorflow/core/framework/op.cc:132] Op<name=FixedUnigramCandidateSampler; signature=true_classes:int64 -> sampled_candidates:int64, true_expected_count:float, sampled_expected_count:float; attr=num_true:int,min=1; attr=num_sampled:int,min=1; attr=unique:bool; attr=range_max:int,min=1; attr=vocab_file:string,default=""; attr=distortion:float,default=1; attr=num_reserved_ids:int,default=0; attr=num_shards:int,default=1,min=1; attr=shard:int,default=0,min=0; attr=unigrams:list(float),default=[]; attr=seed:int,default=0; attr=seed2:int,default=0; is_stateful=true>
  2023-01-12 09:34:37.686028: I tensorflow/core/framework/op.cc:132] Op<name=FlatMapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=metadata:string,default="">
  2023-01-12 09:34:37.686125: I tensorflow/core/framework/op.cc:132] Op<name=FloatInput; signature=a:float -> >
  2023-01-12 09:34:37.686195: I tensorflow/core/framework/op.cc:132] Op<name=FloatOutput; signature= -> a:float>
  2023-01-12 09:34:37.686244: I tensorflow/core/framework/op.cc:132] Op<name=FloatOutputStringOutput; signature= -> a:float, b:string>
  2023-01-12 09:34:37.686334: I tensorflow/core/framework/op.cc:132] Op<name=Floor; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.686413: I tensorflow/core/framework/op.cc:132] Op<name=FloorDiv; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_INT32, DT_UINT32, DT_UINT64, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.686477: I tensorflow/core/framework/op.cc:132] Op<name=FloorMod; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_INT8, DT_INT16, DT_INT32, DT_INT64, DT_UINT8, DT_UINT16, DT_UINT32, DT_UINT64, DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.686525: I tensorflow/core/framework/op.cc:132] Op<name=FlushSummaryWriter; signature=writer:resource -> ; is_stateful=true>
  2023-01-12 09:34:37.686574: I tensorflow/core/framework/op.cc:132] Op<name=Foo1; signature=a:float, b:int32, c:int32 -> d:float, e:int32>
  2023-01-12 09:34:37.686604: I tensorflow/core/framework/op.cc:132] Op<name=Foo2; signature=a:float, b:string, c:string -> d:float, e:int32>
  2023-01-12 09:34:37.686738: I tensorflow/core/framework/op.cc:132] Op<name=Foo3; signature=a:float, b:string, c:float -> d:float, e:int32>
  2023-01-12 09:34:37.686877: I tensorflow/core/framework/op.cc:132] Op<name=For; signature=start:int32, limit:int32, delta:int32, input: -> output:; attr=T:list(type),min=0; attr=body:func>
  2023-01-12 09:34:37.686993: I tensorflow/core/framework/op.cc:132] Op<name=FractionalAvgPool; signature=value:T -> output:T, row_pooling_sequence:int64, col_pooling_sequence:int64; attr=pooling_ratio:list(float),min=4; attr=pseudo_random:bool,default=false; attr=overlapping:bool,default=false; attr=deterministic:bool,default=false; attr=seed:int,default=0; attr=seed2:int,default=0; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.687157: I tensorflow/core/framework/op.cc:132] Op<name=FractionalAvgPoolGrad; signature=orig_input_tensor_shape:int64, out_backprop:T, row_pooling_sequence:int64, col_pooling_sequence:int64 -> output:T; attr=overlapping:bool,default=false; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.687287: I tensorflow/core/framework/op.cc:132] Op<name=FractionalMaxPool; signature=value:T -> output:T, row_pooling_sequence:int64, col_pooling_sequence:int64; attr=pooling_ratio:list(float),min=4; attr=pseudo_random:bool,default=false; attr=overlapping:bool,default=false; attr=deterministic:bool,default=false; attr=seed:int,default=0; attr=seed2:int,default=0; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.687463: I tensorflow/core/framework/op.cc:132] Op<name=FractionalMaxPoolGrad; signature=orig_input:T, orig_output:T, out_backprop:T, row_pooling_sequence:int64, col_pooling_sequence:int64 -> output:T; attr=overlapping:bool,default=false; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.687552: I tensorflow/core/framework/op.cc:132] Op<name=FresnelCos; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.687682: I tensorflow/core/framework/op.cc:132] Op<name=FresnelSin; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.687763: I tensorflow/core/framework/op.cc:132] Op<name=FuncAttr; signature= -> ; attr=f:func>
  2023-01-12 09:34:37.687786: I tensorflow/core/framework/op.cc:132] Op<name=FuncListAttr; signature= -> ; attr=f:list(func)>
  2023-01-12 09:34:37.687894: I tensorflow/core/framework/op.cc:132] Op<name=FusedBatchNorm; signature=x:T, scale:T, offset:T, mean:T, variance:T -> y:T, batch_mean:T, batch_variance:T, reserve_space_1:T, reserve_space_2:T; attr=T:type,allowed=[DT_FLOAT]; attr=epsilon:float,default=0.0001; attr=exponential_avg_factor:float,default=1; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=is_training:bool,default=true>
  2023-01-12 09:34:37.688040: I tensorflow/core/framework/op.cc:132] Op<name=FusedBatchNormGrad; signature=y_backprop:T, x:T, scale:T, reserve_space_1:T, reserve_space_2:T -> x_backprop:T, scale_backprop:T, offset_backprop:T, reserve_space_3:T, reserve_space_4:T; attr=T:type,allowed=[DT_FLOAT]; attr=epsilon:float,default=0.0001; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=is_training:bool,default=true>
  2023-01-12 09:34:37.688241: I tensorflow/core/framework/op.cc:132] Op<name=FusedBatchNormGradV2; signature=y_backprop:T, x:T, scale:float, reserve_space_1:U, reserve_space_2:U -> x_backprop:T, scale_backprop:U, offset_backprop:U, reserve_space_3:U, reserve_space_4:U; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT]; attr=U:type,allowed=[DT_FLOAT]; attr=epsilon:float,default=0.0001; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=is_training:bool,default=true>
  2023-01-12 09:34:37.688354: I tensorflow/core/framework/op.cc:132] Op<name=FusedBatchNormGradV3; signature=y_backprop:T, x:T, scale:float, reserve_space_1:U, reserve_space_2:U, reserve_space_3:U -> x_backprop:T, scale_backprop:U, offset_backprop:U, reserve_space_4:U, reserve_space_5:U; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT]; attr=U:type,allowed=[DT_FLOAT]; attr=epsilon:float,default=0.0001; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW", "NDHWC", "NCDHW"]; attr=is_training:bool,default=true>
  2023-01-12 09:34:37.688442: I tensorflow/core/framework/op.cc:132] Op<name=FusedBatchNormV2; signature=x:T, scale:U, offset:U, mean:U, variance:U -> y:T, batch_mean:U, batch_variance:U, reserve_space_1:U, reserve_space_2:U; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT]; attr=U:type,allowed=[DT_FLOAT]; attr=epsilon:float,default=0.0001; attr=exponential_avg_factor:float,default=1; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=is_training:bool,default=true>
  2023-01-12 09:34:37.688527: I tensorflow/core/framework/op.cc:132] Op<name=FusedBatchNormV3; signature=x:T, scale:U, offset:U, mean:U, variance:U -> y:T, batch_mean:U, batch_variance:U, reserve_space_1:U, reserve_space_2:U, reserve_space_3:U; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT]; attr=U:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=epsilon:float,default=0.0001; attr=exponential_avg_factor:float,default=1; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW", "NDHWC", "NCDHW"]; attr=is_training:bool,default=true>
  2023-01-12 09:34:37.688702: I tensorflow/core/framework/op.cc:132] Op<name=FusedPadConv2D; signature=input:T, paddings:int32, filter:T -> output:T; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=mode:string,allowed=["REFLECT", "SYMMETRIC"]; attr=strides:list(int); attr=padding:string,allowed=["SAME", "VALID"]>
  2023-01-12 09:34:37.688869: I tensorflow/core/framework/op.cc:132] Op<name=FusedResizeAndPadConv2D; signature=input:T, size:int32, paddings:int32, filter:T -> output:T; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=resize_align_corners:bool,default=false; attr=mode:string,allowed=["REFLECT", "SYMMETRIC"]; attr=strides:list(int); attr=padding:string,allowed=["SAME", "VALID"]>
  2023-01-12 09:34:37.688902: I tensorflow/core/framework/op.cc:132] Op<name=GRUBlockCell; signature=x:T, h_prev:T, w_ru:T, w_c:T, b_ru:T, b_c:T -> r:T, u:T, c:T, h:T; attr=T:type,allowed=[DT_FLOAT]>
  2023-01-12 09:34:37.688923: I tensorflow/core/framework/op.cc:132] Op<name=GRUBlockCellGrad; signature=x:T, h_prev:T, w_ru:T, w_c:T, b_ru:T, b_c:T, r:T, u:T, c:T, d_h:T -> d_x:T, d_h_prev:T, d_c_bar:T, d_r_bar_u_bar:T; attr=T:type,allowed=[DT_FLOAT]>
  2023-01-12 09:34:37.688942: I tensorflow/core/framework/op.cc:132] Op<name=Gather; signature=params:Tparams, indices:Tindices -> output:Tparams; attr=validate_indices:bool,default=true; attr=Tparams:type; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.688978: I tensorflow/core/framework/op.cc:132] Op<name=GatherNd; signature=params:Tparams, indices:Tindices -> output:Tparams; attr=Tparams:type; attr=Tindices:type,allowed=[DT_INT16, DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.689024: I tensorflow/core/framework/op.cc:132] Op<name=GatherV2; signature=params:Tparams, indices:Tindices, axis:Taxis -> output:Tparams; attr=batch_dims:int,default=0; attr=Tparams:type; attr=Tindices:type,allowed=[DT_INT16, DT_INT32, DT_INT64]; attr=Taxis:type,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.689064: I tensorflow/core/framework/op.cc:132] Op<name=GenerateBoundingBoxProposals; signature=scores:float, bbox_deltas:float, image_info:float, anchors:float, nms_threshold:float, pre_nms_topn:int32, min_size:float -> rois:float, roi_probabilities:float; attr=post_nms_topn:int,default=300>
  2023-01-12 09:34:37.689098: I tensorflow/core/framework/op.cc:132] Op<name=GenerateVocabRemapping; signature=new_vocab_file:string, old_vocab_file:string -> remapping:int64, num_present:int32; attr=new_vocab_offset:int,min=0; attr=num_new_vocab:int,min=0; attr=old_vocab_size:int,default=-1,min=-1>
  2023-01-12 09:34:37.689138: I tensorflow/core/framework/op.cc:132] Op<name=GeneratorDataset; signature=init_func_other_args:, next_func_other_args:, finalize_func_other_args: -> handle:variant; attr=init_func:func; attr=next_func:func; attr=finalize_func:func; attr=Tinit_func_args:list(type),min=0; attr=Tnext_func_args:list(type),min=0; attr=Tfinalize_func_args:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=metadata:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.689178: I tensorflow/core/framework/op.cc:132] Op<name=GetDeadline; signature= -> deadline_from_epoch_micros:int64>
  2023-01-12 09:34:37.689207: I tensorflow/core/framework/op.cc:132] Op<name=GetElementAtIndex; signature=dataset:variant, index:int64 -> components:; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1>
  2023-01-12 09:34:37.689231: I tensorflow/core/framework/op.cc:132] Op<name=GetOptions; signature=input_dataset:variant -> serialized_options:string>
  2023-01-12 09:34:37.689249: I tensorflow/core/framework/op.cc:132] Op<name=GetSessionHandle; signature=value:T -> handle:string; attr=T:type; is_stateful=true>
  2023-01-12 09:34:37.689304: I tensorflow/core/framework/op.cc:132] Op<name=GetSessionHandleV2; signature=value:T -> handle:resource; attr=T:type; is_stateful=true>
  2023-01-12 09:34:37.689383: I tensorflow/core/framework/op.cc:132] Op<name=GetSessionTensor; signature=handle:string -> value:dtype; attr=dtype:type; is_stateful=true>
  2023-01-12 09:34:37.689409: I tensorflow/core/framework/op.cc:132] Op<name=GraphDefVersion; signature= -> version:int32; is_stateful=true>
  2023-01-12 09:34:37.689441: I tensorflow/core/framework/op.cc:132] Op<name=Greater; signature=x:T, y:T -> z:bool; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:37.689471: I tensorflow/core/framework/op.cc:132] Op<name=GreaterEqual; signature=x:T, y:T -> z:bool; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:37.689508: I tensorflow/core/framework/op.cc:132] Op<name=GroupByReducerDataset; signature=input_dataset:variant, key_func_other_arguments:, init_func_other_arguments:, reduce_func_other_arguments:, finalize_func_other_arguments: -> handle:variant; attr=key_func:func; attr=init_func:func; attr=reduce_func:func; attr=finalize_func:func; attr=Tkey_func_other_arguments:list(type),min=0; attr=Tinit_func_other_arguments:list(type),min=0; attr=Treduce_func_other_arguments:list(type),min=0; attr=Tfinalize_func_other_arguments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; is_stateful=true>
  2023-01-12 09:34:37.689543: I tensorflow/core/framework/op.cc:132] Op<name=GroupByWindowDataset; signature=input_dataset:variant, key_func_other_arguments:, reduce_func_other_arguments:, window_size_func_other_arguments: -> handle:variant; attr=key_func:func; attr=reduce_func:func; attr=window_size_func:func; attr=Tkey_func_other_arguments:list(type),min=0; attr=Treduce_func_other_arguments:list(type),min=0; attr=Twindow_size_func_other_arguments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=metadata:string,default="">
  2023-01-12 09:34:37.689616: I tensorflow/core/framework/op.cc:132] Op<name=GuaranteeConst; signature=input:T -> output:T; attr=T:type; is_stateful=true>
  2023-01-12 09:34:37.689656: I tensorflow/core/framework/op.cc:132] Op<name=HSVToRGB; signature=images:T -> output:T; attr=T:type,default=DT_FLOAT,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.689717: I tensorflow/core/framework/op.cc:132] Op<name=HashTable; signature= -> table_handle:Ref(string); attr=container:string,default=""; attr=shared_name:string,default=""; attr=use_node_name_sharing:bool,default=false; attr=key_dtype:type; attr=value_dtype:type; is_stateful=true>
  2023-01-12 09:34:37.689750: I tensorflow/core/framework/op.cc:132] Op<name=HashTableV2; signature= -> table_handle:resource; attr=container:string,default=""; attr=shared_name:string,default=""; attr=use_node_name_sharing:bool,default=false; attr=key_dtype:type; attr=value_dtype:type; is_stateful=true>
  2023-01-12 09:34:37.689788: I tensorflow/core/framework/op.cc:132] Op<name=HistogramFixedWidth; signature=values:T, value_range:T, nbins:int32 -> out:dtype; attr=T:type,allowed=[DT_INT32, DT_INT64, DT_FLOAT, DT_DOUBLE]; attr=dtype:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.689857: I tensorflow/core/framework/op.cc:132] Op<name=HistogramSummary; signature=tag:string, values:T -> summary:string; attr=T:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:37.689877: I tensorflow/core/framework/op.cc:132] Op<name=HostConst; signature= -> output:dtype; attr=value:tensor; attr=dtype:type>
  2023-01-12 09:34:37.689893: I tensorflow/core/framework/op.cc:132] Op<name=IFFT; signature=input:Tcomplex -> output:Tcomplex; attr=Tcomplex:type,default=DT_COMPLEX64,allowed=[DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.689910: I tensorflow/core/framework/op.cc:132] Op<name=IFFT2D; signature=input:Tcomplex -> output:Tcomplex; attr=Tcomplex:type,default=DT_COMPLEX64,allowed=[DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.689954: I tensorflow/core/framework/op.cc:132] Op<name=IFFT3D; signature=input:Tcomplex -> output:Tcomplex; attr=Tcomplex:type,default=DT_COMPLEX64,allowed=[DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.690237: I tensorflow/core/framework/op.cc:132] Op<name=IRFFT; signature=input:Tcomplex, fft_length:int32 -> output:Treal; attr=Treal:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_DOUBLE]; attr=Tcomplex:type,default=DT_COMPLEX64,allowed=[DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.690487: I tensorflow/core/framework/op.cc:132] Op<name=IRFFT2D; signature=input:Tcomplex, fft_length:int32 -> output:Treal; attr=Treal:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_DOUBLE]; attr=Tcomplex:type,default=DT_COMPLEX64,allowed=[DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.690704: I tensorflow/core/framework/op.cc:132] Op<name=IRFFT3D; signature=input:Tcomplex, fft_length:int32 -> output:Treal; attr=Treal:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_DOUBLE]; attr=Tcomplex:type,default=DT_COMPLEX64,allowed=[DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.690844: I tensorflow/core/framework/op.cc:132] Op<name=Identity; signature=input:T -> output:T; attr=T:type>
  2023-01-12 09:34:37.690955: I tensorflow/core/framework/op.cc:132] Op<name=IdentityN; signature=input: -> output:; attr=T:list(type),min=1>
  2023-01-12 09:34:37.691049: I tensorflow/core/framework/op.cc:132] Op<name=IdentityReader; signature= -> reader_handle:Ref(string); attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.691141: I tensorflow/core/framework/op.cc:132] Op<name=IdentityReaderV2; signature= -> reader_handle:resource; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.691252: I tensorflow/core/framework/op.cc:132] Op<name=If; signature=cond:Tcond, input: -> output:; attr=Tcond:type; attr=Tin:list(type),min=0; attr=Tout:list(type),min=0; attr=then_branch:func; attr=else_branch:func; attr=output_shapes:list(shape),default=[]; is_stateful=true>
  2023-01-12 09:34:37.691402: I tensorflow/core/framework/op.cc:132] Op<name=Igamma; signature=a:T, x:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.691482: I tensorflow/core/framework/op.cc:132] Op<name=IgammaGradA; signature=a:T, x:T -> z:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.691602: I tensorflow/core/framework/op.cc:132] Op<name=Igammac; signature=a:T, x:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.691682: I tensorflow/core/framework/op.cc:132] Op<name=IgnoreErrorsDataset; signature=input_dataset:variant -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=log_warning:bool,default=false>
  2023-01-12 09:34:37.691772: I tensorflow/core/framework/op.cc:132] Op<name=Imag; signature=input:T -> output:Tout; attr=T:type,default=DT_COMPLEX64,allowed=[DT_COMPLEX64, DT_COMPLEX128]; attr=Tout:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.691900: I tensorflow/core/framework/op.cc:132] Op<name=ImageProjectiveTransformV2; signature=images:dtype, transforms:float, output_shape:int32 -> transformed_images:dtype; attr=dtype:type,allowed=[DT_UINT8, DT_INT32, DT_INT64, DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=interpolation:string; attr=fill_mode:string,default="CONSTANT">
  2023-01-12 09:34:37.692021: I tensorflow/core/framework/op.cc:132] Op<name=ImageProjectiveTransformV3; signature=images:dtype, transforms:float, output_shape:int32, fill_value:float -> transformed_images:dtype; attr=dtype:type,allowed=[DT_UINT8, DT_INT32, DT_INT64, DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=interpolation:string; attr=fill_mode:string,default="CONSTANT">
  2023-01-12 09:34:37.693730: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6 kernel_name: "Unknown (from Proto)" tensor { dtype: DT_UINT8 shape { dim { size: 4 } } allocation_description { requested_bytes: 4 allocated_bytes: 4 allocator_name: "cpu" allocation_id: 4 has_single_reference: true ptr: 94667551032320 } } }
  2023-01-12 09:34:37.694024: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocation_id: 4 allocator_name: "cpu" }
  2023-01-12 09:34:37.694129: I tensorflow/core/framework/op.cc:132] Op<name=ImageSummary; signature=tag:string, tensor:T -> summary:string; attr=max_images:int,default=3,min=1; attr=T:type,default=DT_FLOAT,allowed=[DT_UINT8, DT_FLOAT, DT_HALF, DT_DOUBLE]; attr=bad_color:tensor,default=Tensor<type: uint8 shape: [4] values: 255 0 0...>>
  2023-01-12 09:34:37.694220: I tensorflow/core/framework/op.cc:132] Op<name=ImmutableConst; signature= -> tensor:dtype; attr=dtype:type; attr=shape:shape; attr=memory_region_name:string>
  2023-01-12 09:34:37.694289: I tensorflow/core/framework/op.cc:132] Op<name=ImportEvent; signature=writer:resource, event:string -> ; is_stateful=true>
  2023-01-12 09:34:37.694345: I tensorflow/core/framework/op.cc:132] Op<name=InPolymorphicTwice; signature=a:N*T, b:M*T -> ; attr=T:type,default=DT_INT32; attr=N:int,min=0; attr=M:int,min=0>
  2023-01-12 09:34:37.694459: I tensorflow/core/framework/op.cc:132] Op<name=InTopK; signature=predictions:float, targets:T -> precision:bool; attr=k:int; attr=T:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.694557: I tensorflow/core/framework/op.cc:132] Op<name=InTopKV2; signature=predictions:float, targets:T, k:T -> precision:bool; attr=T:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.694635: I tensorflow/core/framework/op.cc:132] Op<name=InfeedDequeue; signature= -> output:dtype; attr=dtype:type; attr=shape:shape; is_stateful=true>
  2023-01-12 09:34:37.694773: I tensorflow/core/framework/op.cc:132] Op<name=InfeedDequeueTuple; signature= -> outputs:; attr=dtypes:list(type),min=1; attr=shapes:list(shape); is_stateful=true>
  2023-01-12 09:34:37.694875: I tensorflow/core/framework/op.cc:132] Op<name=InfeedEnqueue; signature=input:dtype -> ; attr=dtype:type; attr=shape:shape,default=[]; attr=layout:list(int),default=[]; attr=device_ordinal:int,default=-1; is_stateful=true>
  2023-01-12 09:34:37.694912: I tensorflow/core/framework/op.cc:132] Op<name=InfeedEnqueuePrelinearizedBuffer; signature=input:variant -> ; attr=device_ordinal:int,default=-1>
  2023-01-12 09:34:37.694946: I tensorflow/core/framework/op.cc:132] Op<name=InfeedEnqueueTuple; signature=inputs: -> ; attr=dtypes:list(type),min=1; attr=shapes:list(shape); attr=layouts:list(int),default=[]; attr=device_ordinal:int,default=-1; is_stateful=true>
  2023-01-12 09:34:37.694974: I tensorflow/core/framework/op.cc:132] Op<name=InitializeTable; signature=table_handle:Ref(string), keys:Tkey, values:Tval -> ; attr=Tkey:type; attr=Tval:type>
  2023-01-12 09:34:37.695777: I tensorflow/core/framework/op.cc:132] Op<name=InitializeTableFromDataset; signature=table_handle:resource, dataset:variant -> ; is_stateful=true>
  2023-01-12 09:34:37.695837: I tensorflow/core/framework/op.cc:132] Op<name=InitializeTableFromTextFile; signature=table_handle:Ref(string), filename:string -> ; attr=key_index:int,min=-2; attr=value_index:int,min=-2; attr=vocab_size:int,default=-1,min=-1; attr=delimiter:string,default="\t"; attr=offset:int,default=0>
  2023-01-12 09:34:37.695908: I tensorflow/core/framework/op.cc:132] Op<name=InitializeTableFromTextFileV2; signature=table_handle:resource, filename:string -> ; attr=key_index:int,min=-2; attr=value_index:int,min=-2; attr=vocab_size:int,default=-1,min=-1; attr=delimiter:string,default="\t"; attr=offset:int,default=0; is_stateful=true>
  2023-01-12 09:34:37.695954: I tensorflow/core/framework/op.cc:132] Op<name=InitializeTableV2; signature=table_handle:resource, keys:Tkey, values:Tval -> ; attr=Tkey:type; attr=Tval:type; is_stateful=true>
  2023-01-12 09:34:37.695991: I tensorflow/core/framework/op.cc:132] Op<name=InplaceAdd; signature=x:T, i:int32, v:T -> y:T; attr=T:type>
  2023-01-12 09:34:37.696040: I tensorflow/core/framework/op.cc:132] Op<name=InplaceSub; signature=x:T, i:int32, v:T -> y:T; attr=T:type>
  2023-01-12 09:34:37.696116: I tensorflow/core/framework/op.cc:132] Op<name=InplaceUpdate; signature=x:T, i:int32, v:T -> y:T; attr=T:type>
  2023-01-12 09:34:37.696157: I tensorflow/core/framework/op.cc:132] Op<name=Int64Output; signature= -> out:int64>
  2023-01-12 09:34:37.696200: I tensorflow/core/framework/op.cc:132] Op<name=IntAttr; signature= -> out:int64; attr=foo:int,default=1>
  2023-01-12 09:34:37.696237: I tensorflow/core/framework/op.cc:132] Op<name=IntInput; signature=a:int32 -> >
  2023-01-12 09:34:37.696276: I tensorflow/core/framework/op.cc:132] Op<name=IntInputFloatInput; signature=a:int32, b:float -> >
  2023-01-12 09:34:37.696386: I tensorflow/core/framework/op.cc:132] Op<name=IntInputIntOutput; signature=a:int32 -> b:int32>
  2023-01-12 09:34:37.696485: I tensorflow/core/framework/op.cc:132] Op<name=IntOutput; signature= -> a:int32>
  2023-01-12 09:34:37.696516: I tensorflow/core/framework/op.cc:132] Op<name=IntOutputFloatOutput; signature= -> a:int32, b:float>
  2023-01-12 09:34:37.696601: I tensorflow/core/framework/op.cc:132] Op<name=InterleaveDataset; signature=input_dataset:variant, other_arguments:, cycle_length:int64, block_length:int64 -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=metadata:string,default="">
  2023-01-12 09:34:37.696672: I tensorflow/core/framework/op.cc:132] Op<name=Inv; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT8, DT_INT16, DT_INT32, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.696723: I tensorflow/core/framework/op.cc:132] Op<name=InvGrad; signature=y:T, dy:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.696762: I tensorflow/core/framework/op.cc:132] Op<name=Invert; signature=x:T -> y:T; attr=T:type,allowed=[DT_INT8, DT_INT16, DT_INT32, DT_INT64, DT_UINT8, DT_UINT16, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:37.696800: I tensorflow/core/framework/op.cc:132] Op<name=InvertPermutation; signature=x:T -> y:T; attr=T:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.696980: I tensorflow/core/framework/op.cc:132] Op<name=IsBoostedTreesEnsembleInitialized; signature=tree_ensemble_handle:resource -> is_initialized:bool; is_stateful=true>
  2023-01-12 09:34:37.697065: I tensorflow/core/framework/op.cc:132] Op<name=IsBoostedTreesQuantileStreamResourceInitialized; signature=quantile_stream_resource_handle:resource -> is_initialized:bool; is_stateful=true>
  2023-01-12 09:34:37.697165: I tensorflow/core/framework/op.cc:132] Op<name=IsFinite; signature=x:T -> y:bool; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.697263: I tensorflow/core/framework/op.cc:132] Op<name=IsInf; signature=x:T -> y:bool; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.697487: I tensorflow/core/framework/op.cc:132] Op<name=IsNan; signature=x:T -> y:bool; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.697593: I tensorflow/core/framework/op.cc:132] Op<name=IsResourceHandleRefCounting; signature=handle:resource -> result:bool; is_stateful=true>
  2023-01-12 09:34:37.697704: I tensorflow/core/framework/op.cc:132] Op<name=IsTPUEmbeddingInitialized; signature= -> is_tpu_embedding_initialized:bool; attr=config:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.697810: I tensorflow/core/framework/op.cc:132] Op<name=IsTensorFloat32Enabled; signature= -> enabled:bool; is_stateful=true>
  2023-01-12 09:34:37.697906: I tensorflow/core/framework/op.cc:132] Op<name=IsVariableInitialized; signature=ref:Ref(dtype) -> is_initialized:bool; attr=dtype:type; allows_uninitialized_input=true>
  2023-01-12 09:34:37.698112: I tensorflow/core/framework/op.cc:132] Op<name=IsotonicRegression; signature=input:T -> output:output_dtype, segments:int32; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]; attr=output_dtype:type,default=DT_FLOAT,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.698256: I tensorflow/core/framework/op.cc:132] Op<name=Iterator; signature= -> handle:resource; attr=shared_name:string; attr=container:string; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; is_stateful=true>
  2023-01-12 09:34:37.698385: I tensorflow/core/framework/op.cc:132] Op<name=IteratorFromStringHandle; signature=string_handle:string -> resource_handle:resource; attr=output_types:list(type),default=[],min=0; attr=output_shapes:list(shape),default=[],min=0; is_stateful=true>
  2023-01-12 09:34:37.698595: I tensorflow/core/framework/op.cc:132] Op<name=IteratorFromStringHandleV2; signature=string_handle:string -> resource_handle:resource; attr=output_types:list(type),default=[],min=0; attr=output_shapes:list(shape),default=[],min=0; is_stateful=true>
  2023-01-12 09:34:37.698632: I tensorflow/core/framework/op.cc:132] Op<name=IteratorGetDevice; signature=resource:resource -> device:string; is_stateful=true>
  2023-01-12 09:34:37.698649: I tensorflow/core/framework/op.cc:132] Op<name=IteratorGetNext; signature=iterator:resource -> components:; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; is_stateful=true>
  2023-01-12 09:34:37.698661: I tensorflow/core/framework/op.cc:132] Op<name=IteratorGetNextAsOptional; signature=iterator:resource -> optional:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; is_stateful=true>
  2023-01-12 09:34:37.698672: I tensorflow/core/framework/op.cc:132] Op<name=IteratorGetNextSync; signature=iterator:resource -> components:; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; is_stateful=true>
  2023-01-12 09:34:37.698681: I tensorflow/core/framework/op.cc:132] Op<name=IteratorToStringHandle; signature=resource_handle:resource -> string_handle:string; is_stateful=true>
  2023-01-12 09:34:37.698718: I tensorflow/core/framework/op.cc:132] Op<name=IteratorV2; signature= -> handle:resource; attr=shared_name:string; attr=container:string; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; is_stateful=true>
  2023-01-12 09:34:37.698737: I tensorflow/core/framework/op.cc:132] Op<name=KMC2ChainInitialization; signature=distances:float, seed:int64 -> index:int64>
  2023-01-12 09:34:37.698750: I tensorflow/core/framework/op.cc:132] Op<name=KernelLabel; signature= -> result:string>
  2023-01-12 09:34:37.698776: I tensorflow/core/framework/op.cc:132] Op<name=KernelLabelRequired; signature=input:int32 -> result:string>
  2023-01-12 09:34:37.698808: I tensorflow/core/framework/op.cc:132] Op<name=KmeansPlusPlusInitialization; signature=points:float, num_to_sample:int64, seed:int64, num_retries_per_sample:int64 -> samples:float>
  2023-01-12 09:34:37.698867: I tensorflow/core/framework/op.cc:132] Op<name=KthOrderStatistic; signature=input:float -> output:float; attr=k:int>
  2023-01-12 09:34:37.698912: I tensorflow/core/framework/op.cc:132] Op<name=L2Loss; signature=t:T -> output:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.698953: I tensorflow/core/framework/op.cc:132] Op<name=LMDBDataset; signature=filenames:string -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; is_stateful=true>
  2023-01-12 09:34:37.699014: I tensorflow/core/framework/op.cc:132] Op<name=LMDBReader; signature= -> reader_handle:Ref(string); attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.699534: I tensorflow/core/framework/op.cc:132] Op<name=LRN; signature=input:T -> output:T; attr=depth_radius:int,default=5; attr=bias:float,default=1; attr=alpha:float,default=1; attr=beta:float,default=0.5; attr=T:type,default=DT_FLOAT,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT]>
  2023-01-12 09:34:37.699919: I tensorflow/core/framework/op.cc:132] Op<name=LRNGrad; signature=input_grads:T, input_image:T, output_image:T -> output:T; attr=depth_radius:int,default=5; attr=bias:float,default=1; attr=alpha:float,default=1; attr=beta:float,default=0.5; attr=T:type,default=DT_FLOAT,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT]>
  2023-01-12 09:34:37.700211: I tensorflow/core/framework/op.cc:132] Op<name=LSTMBlockCell; signature=x:T, cs_prev:T, h_prev:T, w:T, wci:T, wcf:T, wco:T, b:T -> i:T, cs:T, f:T, o:T, ci:T, co:T, h:T; attr=forget_bias:float,default=1; attr=cell_clip:float,default=3; attr=use_peephole:bool,default=false; attr=T:type,allowed=[DT_HALF, DT_FLOAT]>
  2023-01-12 09:34:37.700355: I tensorflow/core/framework/op.cc:132] Op<name=LSTMBlockCellGrad; signature=x:T, cs_prev:T, h_prev:T, w:T, wci:T, wcf:T, wco:T, b:T, i:T, cs:T, f:T, o:T, ci:T, co:T, cs_grad:T, h_grad:T -> cs_prev_grad:T, dicfo:T, wci_grad:T, wcf_grad:T, wco_grad:T; attr=use_peephole:bool; attr=T:type,allowed=[DT_HALF, DT_FLOAT]>
  2023-01-12 09:34:37.700406: I tensorflow/core/framework/op.cc:132] Op<name=LatencyStatsDataset; signature=input_dataset:variant, tag:string -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1>
  2023-01-12 09:34:37.700507: I tensorflow/core/framework/op.cc:132] Op<name=LeakyRelu; signature=features:T -> activations:T; attr=alpha:float,default=0.2; attr=T:type,default=DT_FLOAT,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.700568: I tensorflow/core/framework/op.cc:132] Op<name=LeakyReluGrad; signature=gradients:T, features:T -> backprops:T; attr=alpha:float,default=0.2; attr=T:type,default=DT_FLOAT,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.700629: I tensorflow/core/framework/op.cc:132] Op<name=LearnedUnigramCandidateSampler; signature=true_classes:int64 -> sampled_candidates:int64, true_expected_count:float, sampled_expected_count:float; attr=num_true:int,min=1; attr=num_sampled:int,min=1; attr=unique:bool; attr=range_max:int,min=1; attr=seed:int,default=0; attr=seed2:int,default=0; is_stateful=true>
  2023-01-12 09:34:37.700691: I tensorflow/core/framework/op.cc:132] Op<name=LeftShift; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_INT8, DT_INT16, DT_INT32, DT_INT64, DT_UINT8, DT_UINT16, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:37.700847: I tensorflow/core/framework/op.cc:132] Op<name=LegacyParallelInterleaveDatasetV2; signature=input_dataset:variant, other_arguments:, cycle_length:int64, block_length:int64, buffer_output_elements:int64, prefetch_input_elements:int64 -> handle:variant; attr=f:func; attr=deterministic:string,default="default"; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=metadata:string,default="">
  2023-01-12 09:34:37.700891: I tensorflow/core/framework/op.cc:132] Op<name=Less; signature=x:T, y:T -> z:bool; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:37.700925: I tensorflow/core/framework/op.cc:132] Op<name=LessEqual; signature=x:T, y:T -> z:bool; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:37.700946: I tensorflow/core/framework/op.cc:132] Op<name=Lgamma; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.700969: I tensorflow/core/framework/op.cc:132] Op<name=LinSpace; signature=start:T, stop:T, num:Tidx -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.700984: I tensorflow/core/framework/op.cc:132] Op<name=ListDataset; signature=tensors: -> handle:variant; attr=Tinput_types:list(type),min=1; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=metadata:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.701000: I tensorflow/core/framework/op.cc:132] Op<name=ListDiff; signature=x:T, y:T -> out:T, idx:out_idx; attr=T:type; attr=out_idx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.701078: I tensorflow/core/framework/op.cc:132] Op<name=ListInput; signature=a:N*T -> ; attr=N:int,min=1; attr=T:type>
  2023-01-12 09:34:37.701109: I tensorflow/core/framework/op.cc:132] Op<name=ListOutput; signature= -> a:; attr=T:list(type),min=1>
  2023-01-12 09:34:37.701155: I tensorflow/core/framework/op.cc:132] Op<name=LoadAllTPUEmbeddingParameters; signature=parameters:NumTables*float, auxiliary1:NumTables*float, auxiliary2:NumTables*float, auxiliary3:NumTables*float, auxiliary4:NumTables*float, auxiliary5:NumTables*float, auxiliary6:NumTables*float, auxiliary7:NumTables*float -> ; attr=NumTables:int,min=1; attr=config:string; attr=num_shards:int; attr=shard_id:int; is_stateful=true>
  2023-01-12 09:34:37.701190: I tensorflow/core/framework/op.cc:132] Op<name=LoadAndRemapMatrix; signature=ckpt_path:string, old_tensor_name:string, row_remapping:int64, col_remapping:int64, initializing_values:float -> output_matrix:float; attr=num_rows:int,min=0; attr=num_cols:int,min=1; attr=max_rows_in_memory:int,default=-1; is_stateful=true>
  2023-01-12 09:34:37.701221: I tensorflow/core/framework/op.cc:132] Op<name=LoadDataset; signature=path:string, reader_func_other_args: -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=compression:string,default=""; attr=reader_func:func; attr=Treader_func_args:list(type),min=0; is_stateful=true>
  2023-01-12 09:34:37.704257: I tensorflow/core/framework/op.cc:132] Op<name=LoadTPUEmbeddingADAMParameters; signature=parameters:float, momenta:float, velocities:float -> ; attr=table_id:int,default=-1; attr=table_name:string,default=""; attr=num_shards:int; attr=shard_id:int; attr=config:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.704560: I tensorflow/core/framework/op.cc:132] Op<name=LoadTPUEmbeddingAdadeltaParameters; signature=parameters:float, accumulators:float, updates:float -> ; attr=table_id:int,default=-1; attr=table_name:string,default=""; attr=num_shards:int; attr=shard_id:int; attr=config:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.704699: I tensorflow/core/framework/op.cc:132] Op<name=LoadTPUEmbeddingAdagradMomentumParameters; signature=parameters:float, accumulators:float, momenta:float -> ; attr=table_id:int,default=-1; attr=table_name:string,default=""; attr=num_shards:int; attr=shard_id:int; attr=config:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.704798: I tensorflow/core/framework/op.cc:132] Op<name=LoadTPUEmbeddingAdagradParameters; signature=parameters:float, accumulators:float -> ; attr=table_id:int,default=-1; attr=table_name:string,default=""; attr=num_shards:int; attr=shard_id:int; attr=config:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.704880: I tensorflow/core/framework/op.cc:132] Op<name=LoadTPUEmbeddingCenteredRMSPropParameters; signature=parameters:float, ms:float, mom:float, mg:float -> ; attr=table_id:int,default=-1; attr=table_name:string,default=""; attr=num_shards:int; attr=shard_id:int; attr=config:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.704986: I tensorflow/core/framework/op.cc:132] Op<name=LoadTPUEmbeddingFTRLParameters; signature=parameters:float, accumulators:float, linears:float -> ; attr=table_id:int,default=-1; attr=table_name:string,default=""; attr=num_shards:int; attr=shard_id:int; attr=config:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.705084: I tensorflow/core/framework/op.cc:132] Op<name=LoadTPUEmbeddingFrequencyEstimatorParameters; signature=parameters:float, last_hit_step:float -> ; attr=table_id:int,default=-1; attr=table_name:string,default=""; attr=num_shards:int; attr=shard_id:int; attr=config:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.705164: I tensorflow/core/framework/op.cc:132] Op<name=LoadTPUEmbeddingMDLAdagradLightParameters; signature=parameters:float, accumulators:float, weights:float, benefits:float -> ; attr=table_id:int,default=-1; attr=table_name:string,default=""; attr=num_shards:int; attr=shard_id:int; attr=config:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.705213: I tensorflow/core/framework/op.cc:132] Op<name=LoadTPUEmbeddingMomentumParameters; signature=parameters:float, momenta:float -> ; attr=table_id:int,default=-1; attr=table_name:string,default=""; attr=num_shards:int; attr=shard_id:int; attr=config:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.705255: I tensorflow/core/framework/op.cc:132] Op<name=LoadTPUEmbeddingProximalAdagradParameters; signature=parameters:float, accumulators:float -> ; attr=table_id:int,default=-1; attr=table_name:string,default=""; attr=num_shards:int; attr=shard_id:int; attr=config:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.705299: I tensorflow/core/framework/op.cc:132] Op<name=LoadTPUEmbeddingProximalYogiParameters; signature=parameters:float, v:float, m:float -> ; attr=table_id:int,default=-1; attr=table_name:string,default=""; attr=num_shards:int; attr=shard_id:int; attr=config:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.705366: I tensorflow/core/framework/op.cc:132] Op<name=LoadTPUEmbeddingRMSPropParameters; signature=parameters:float, ms:float, mom:float -> ; attr=table_id:int,default=-1; attr=table_name:string,default=""; attr=num_shards:int; attr=shard_id:int; attr=config:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.705409: I tensorflow/core/framework/op.cc:132] Op<name=LoadTPUEmbeddingStochasticGradientDescentParameters; signature=parameters:float -> ; attr=table_id:int,default=-1; attr=table_name:string,default=""; attr=num_shards:int; attr=shard_id:int; attr=config:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.705581: I tensorflow/core/framework/op.cc:132] Op<name=Log; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.705877: I tensorflow/core/framework/op.cc:132] Op<name=Log1p; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.707199: I tensorflow/core/framework/op.cc:132] Op<name=LogMatrixDeterminant; signature=input:T -> sign:T, log_abs_determinant:T; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.707693: I tensorflow/core/framework/op.cc:132] Op<name=LogSoftmax; signature=logits:T -> logsoftmax:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.707848: I tensorflow/core/framework/op.cc:132] Op<name=LogUniformCandidateSampler; signature=true_classes:int64 -> sampled_candidates:int64, true_expected_count:float, sampled_expected_count:float; attr=num_true:int,min=1; attr=num_sampled:int,min=1; attr=unique:bool; attr=range_max:int,min=1; attr=seed:int,default=0; attr=seed2:int,default=0; is_stateful=true>
  2023-01-12 09:34:37.707923: I tensorflow/core/framework/op.cc:132] Op<name=LogicalAnd; signature=x:bool, y:bool -> z:bool; is_commutative=true>
  2023-01-12 09:34:37.707981: I tensorflow/core/framework/op.cc:132] Op<name=LogicalNot; signature=x:bool -> y:bool>
  2023-01-12 09:34:37.708018: I tensorflow/core/framework/op.cc:132] Op<name=LogicalOr; signature=x:bool, y:bool -> z:bool; is_commutative=true>
  2023-01-12 09:34:37.708043: I tensorflow/core/framework/op.cc:132] Op<name=LookupTableExport; signature=table_handle:Ref(string) -> keys:Tkeys, values:Tvalues; attr=Tkeys:type; attr=Tvalues:type>
  2023-01-12 09:34:37.708068: I tensorflow/core/framework/op.cc:132] Op<name=LookupTableExportV2; signature=table_handle:resource -> keys:Tkeys, values:Tvalues; attr=Tkeys:type; attr=Tvalues:type; is_stateful=true>
  2023-01-12 09:34:37.708091: I tensorflow/core/framework/op.cc:132] Op<name=LookupTableFind; signature=table_handle:Ref(string), keys:Tin, default_value:Tout -> values:Tout; attr=Tin:type; attr=Tout:type>
  2023-01-12 09:34:37.708116: I tensorflow/core/framework/op.cc:132] Op<name=LookupTableFindV2; signature=table_handle:resource, keys:Tin, default_value:Tout -> values:Tout; attr=Tin:type; attr=Tout:type; is_stateful=true>
  2023-01-12 09:34:37.708137: I tensorflow/core/framework/op.cc:132] Op<name=LookupTableImport; signature=table_handle:Ref(string), keys:Tin, values:Tout -> ; attr=Tin:type; attr=Tout:type>
  2023-01-12 09:34:37.708159: I tensorflow/core/framework/op.cc:132] Op<name=LookupTableImportV2; signature=table_handle:resource, keys:Tin, values:Tout -> ; attr=Tin:type; attr=Tout:type; is_stateful=true>
  2023-01-12 09:34:37.708181: I tensorflow/core/framework/op.cc:132] Op<name=LookupTableInsert; signature=table_handle:Ref(string), keys:Tin, values:Tout -> ; attr=Tin:type; attr=Tout:type>
  2023-01-12 09:34:37.708202: I tensorflow/core/framework/op.cc:132] Op<name=LookupTableInsertV2; signature=table_handle:resource, keys:Tin, values:Tout -> ; attr=Tin:type; attr=Tout:type; is_stateful=true>
  2023-01-12 09:34:37.708224: I tensorflow/core/framework/op.cc:132] Op<name=LookupTableRemoveV2; signature=table_handle:resource, keys:Tin -> ; attr=Tin:type; is_stateful=true>
  2023-01-12 09:34:37.708244: I tensorflow/core/framework/op.cc:132] Op<name=LookupTableSize; signature=table_handle:Ref(string) -> size:int64>
  2023-01-12 09:34:37.708261: I tensorflow/core/framework/op.cc:132] Op<name=LookupTableSizeV2; signature=table_handle:resource -> size:int64; is_stateful=true>
  2023-01-12 09:34:37.708281: I tensorflow/core/framework/op.cc:132] Op<name=LoopCond; signature=input:bool -> output:bool>
  2023-01-12 09:34:37.708322: I tensorflow/core/framework/op.cc:132] Op<name=LowerBound; signature=sorted_inputs:T, values:T -> output:out_type; attr=T:type; attr=out_type:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.708362: I tensorflow/core/framework/op.cc:132] Op<name=Lu; signature=input:T -> lu:T, p:output_idx_type; attr=T:type,allowed=[DT_DOUBLE, DT_FLOAT, DT_HALF, DT_COMPLEX64, DT_COMPLEX128]; attr=output_idx_type:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.708440: I tensorflow/core/framework/op.cc:132] Op<name=MakeIterator; signature=dataset:variant, iterator:resource -> ; is_stateful=true>
  2023-01-12 09:34:37.708475: I tensorflow/core/framework/op.cc:132] Op<name=MakeUnique; signature=input:float -> output:float>
  2023-01-12 09:34:37.708496: I tensorflow/core/framework/op.cc:132] Op<name=MakeWeakResourceHandle; signature=handle:resource -> dup:resource; is_stateful=true>
  2023-01-12 09:34:37.708545: I tensorflow/core/framework/op.cc:132] Op<name=MapAndBatchDataset; signature=input_dataset:variant, other_arguments:, batch_size:int64, num_parallel_calls:int64, drop_remainder:bool -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=preserve_cardinality:bool,default=false; attr=metadata:string,default="">
  2023-01-12 09:34:37.708651: I tensorflow/core/framework/op.cc:132] Op<name=MapClear; signature= -> ; attr=capacity:int,default=0,min=0; attr=memory_limit:int,default=0,min=0; attr=dtypes:list(type); attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.708706: I tensorflow/core/framework/op.cc:132] Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=metadata:string,default="">
  2023-01-12 09:34:37.708767: I tensorflow/core/framework/op.cc:132] Op<name=MapDefun; signature=arguments:, captured_inputs: -> output:; attr=Targuments:list(type),min=1; attr=Tcaptured:list(type),default=[],min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=f:func; attr=max_intra_op_parallelism:int,default=1>
  2023-01-12 09:34:37.708816: I tensorflow/core/framework/op.cc:132] Op<name=MapIncompleteSize; signature= -> size:int32; attr=capacity:int,default=0,min=0; attr=memory_limit:int,default=0,min=0; attr=dtypes:list(type); attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.708859: I tensorflow/core/framework/op.cc:132] Op<name=MapPeek; signature=key:int64, indices:int32 -> values:; attr=capacity:int,default=0,min=0; attr=memory_limit:int,default=0,min=0; attr=dtypes:list(type),min=1; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.708904: I tensorflow/core/framework/op.cc:132] Op<name=MapSize; signature= -> size:int32; attr=capacity:int,default=0,min=0; attr=memory_limit:int,default=0,min=0; attr=dtypes:list(type); attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.709158: I tensorflow/core/framework/op.cc:132] Op<name=MapStage; signature=key:int64, indices:int32, values: -> ; attr=capacity:int,default=0,min=0; attr=memory_limit:int,default=0,min=0; attr=dtypes:list(type); attr=fake_dtypes:list(type),min=1; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.709233: I tensorflow/core/framework/op.cc:132] Op<name=MapUnstage; signature=key:int64, indices:int32 -> values:; attr=capacity:int,default=0,min=0; attr=memory_limit:int,default=0,min=0; attr=dtypes:list(type),min=1; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.709285: I tensorflow/core/framework/op.cc:132] Op<name=MapUnstageNoKey; signature=indices:int32 -> key:int64, values:; attr=capacity:int,default=0,min=0; attr=memory_limit:int,default=0,min=0; attr=dtypes:list(type),min=1; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.709340: I tensorflow/core/framework/op.cc:132] Op<name=MatMul; signature=a:T, b:T -> product:T; attr=transpose_a:bool,default=false; attr=transpose_b:bool,default=false; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.709376: I tensorflow/core/framework/op.cc:132] Op<name=MatchingFiles; signature=pattern:string -> filenames:string>
  2023-01-12 09:34:37.709599: I tensorflow/core/framework/op.cc:132] Op<name=MatchingFilesDataset; signature=patterns:string -> handle:variant; is_stateful=true>
  2023-01-12 09:34:37.709738: I tensorflow/core/framework/op.cc:132] Op<name=MatrixBandPart; signature=input:T, num_lower:Tindex, num_upper:Tindex -> band:T; attr=T:type; attr=Tindex:type,default=DT_INT64,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.709814: I tensorflow/core/framework/op.cc:132] Op<name=MatrixDeterminant; signature=input:T -> output:T; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.709873: I tensorflow/core/framework/op.cc:132] Op<name=MatrixDiag; signature=diagonal:T -> output:T; attr=T:type>
  2023-01-12 09:34:37.709936: I tensorflow/core/framework/op.cc:132] Op<name=MatrixDiagPart; signature=input:T -> diagonal:T; attr=T:type>
  2023-01-12 09:34:37.710017: I tensorflow/core/framework/op.cc:132] Op<name=MatrixDiagPartV2; signature=input:T, k:int32, padding_value:T -> diagonal:T; attr=T:type>
  2023-01-12 09:34:37.710083: I tensorflow/core/framework/op.cc:132] Op<name=MatrixDiagPartV3; signature=input:T, k:int32, padding_value:T -> diagonal:T; attr=T:type; attr=align:string,default="RIGHT_LEFT",allowed=["LEFT_RIGHT", "RIGHT_LEFT", "LEFT_LEFT", "RIGHT_RIGHT"]>
  2023-01-12 09:34:37.710219: I tensorflow/core/framework/op.cc:132] Op<name=MatrixDiagV2; signature=diagonal:T, k:int32, num_rows:int32, num_cols:int32, padding_value:T -> output:T; attr=T:type>
  2023-01-12 09:34:37.710311: I tensorflow/core/framework/op.cc:132] Op<name=MatrixDiagV3; signature=diagonal:T, k:int32, num_rows:int32, num_cols:int32, padding_value:T -> output:T; attr=T:type; attr=align:string,default="RIGHT_LEFT",allowed=["LEFT_RIGHT", "RIGHT_LEFT", "LEFT_LEFT", "RIGHT_RIGHT"]>
  2023-01-12 09:34:37.710365: I tensorflow/core/framework/op.cc:132] Op<name=MatrixExponential; signature=input:T -> output:T; attr=T:type,allowed=[DT_DOUBLE, DT_FLOAT, DT_HALF, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.710913: I tensorflow/core/framework/op.cc:132] Op<name=MatrixInverse; signature=input:T -> output:T; attr=adjoint:bool,default=false; attr=T:type,allowed=[DT_DOUBLE, DT_FLOAT, DT_HALF, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.710951: I tensorflow/core/framework/op.cc:132] Op<name=MatrixLogarithm; signature=input:T -> output:T; attr=T:type,allowed=[DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.710970: I tensorflow/core/framework/op.cc:132] Op<name=MatrixSetDiag; signature=input:T, diagonal:T -> output:T; attr=T:type>
  2023-01-12 09:34:37.710994: I tensorflow/core/framework/op.cc:132] Op<name=MatrixSetDiagV2; signature=input:T, diagonal:T, k:int32 -> output:T; attr=T:type>
  2023-01-12 09:34:37.711057: I tensorflow/core/framework/op.cc:132] Op<name=MatrixSetDiagV3; signature=input:T, diagonal:T, k:int32 -> output:T; attr=T:type; attr=align:string,default="RIGHT_LEFT",allowed=["LEFT_RIGHT", "RIGHT_LEFT", "LEFT_LEFT", "RIGHT_RIGHT"]>
  2023-01-12 09:34:37.711121: I tensorflow/core/framework/op.cc:132] Op<name=MatrixSolve; signature=matrix:T, rhs:T -> output:T; attr=adjoint:bool,default=false; attr=T:type,allowed=[DT_DOUBLE, DT_FLOAT, DT_HALF, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.711156: I tensorflow/core/framework/op.cc:132] Op<name=MatrixSolveLs; signature=matrix:T, rhs:T, l2_regularizer:double -> output:T; attr=T:type,allowed=[DT_DOUBLE, DT_FLOAT, DT_HALF, DT_COMPLEX64, DT_COMPLEX128]; attr=fast:bool,default=true>
  2023-01-12 09:34:37.711183: I tensorflow/core/framework/op.cc:132] Op<name=MatrixSquareRoot; signature=input:T -> output:T; attr=T:type,allowed=[DT_DOUBLE, DT_FLOAT, DT_HALF, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.711260: I tensorflow/core/framework/op.cc:132] Op<name=MatrixTriangularSolve; signature=matrix:T, rhs:T -> output:T; attr=lower:bool,default=true; attr=adjoint:bool,default=false; attr=T:type,allowed=[DT_BFLOAT16, DT_DOUBLE, DT_FLOAT, DT_HALF, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.711383: I tensorflow/core/framework/op.cc:132] Op<name=Max; signature=input:T, reduction_indices:Tidx -> output:T; attr=keep_dims:bool,default=false; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 12026250066093653660, DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.711531: I tensorflow/core/framework/op.cc:132] Op<name=MaxIntraOpParallelismDataset; signature=input_dataset:variant, max_intra_op_parallelism:int64 -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1>
  2023-01-12 09:34:37.711607: I tensorflow/core/framework/op.cc:132] Op<name=MaxPool; signature=input:T -> output:T; attr=T:type,default=DT_FLOAT,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64, DT_UINT8, DT_INT16, DT_INT8, DT_UINT16, DT_QINT8]; attr=ksize:list(int),min=4; attr=strides:list(int),min=4; attr=padding:string,allowed=["SAME", "VALID", "EXPLICIT"]; attr=explicit_paddings:list(int),default=[]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW", "NCHW_VECT_C"]>
  2023-01-12 09:34:37.711661: I tensorflow/core/framework/op.cc:132] Op<name=MaxPool3D; signature=input:T -> output:T; attr=ksize:list(int),min=5; attr=strides:list(int),min=5; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NDHWC",allowed=["NDHWC", "NCDHW"]; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT]>
  2023-01-12 09:34:37.711734: I tensorflow/core/framework/op.cc:132] Op<name=MaxPool3DGrad; signature=orig_input:TInput, orig_output:TInput, grad:T -> output:T; attr=ksize:list(int),min=5; attr=strides:list(int),min=5; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NDHWC",allowed=["NDHWC", "NCDHW"]; attr=T:type,default=DT_FLOAT,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT]; attr=TInput:type,default=DT_FLOAT,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT]>
  2023-01-12 09:34:37.711811: I tensorflow/core/framework/op.cc:132] Op<name=MaxPool3DGradGrad; signature=orig_input:T, orig_output:T, grad:T -> output:T; attr=ksize:list(int),min=5; attr=strides:list(int),min=5; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NDHWC",allowed=["NDHWC", "NCDHW"]; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:37.711902: I tensorflow/core/framework/op.cc:132] Op<name=MaxPoolGrad; signature=orig_input:T, orig_output:T, grad:T -> output:T; attr=ksize:list(int),min=4; attr=strides:list(int),min=4; attr=padding:string,allowed=["SAME", "VALID", "EXPLICIT"]; attr=explicit_paddings:list(int),default=[]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=T:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:37.712001: I tensorflow/core/framework/op.cc:132] Op<name=MaxPoolGradGrad; signature=orig_input:T, orig_output:T, grad:T -> output:T; attr=ksize:list(int),min=4; attr=strides:list(int),min=4; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:37.712064: I tensorflow/core/framework/op.cc:132] Op<name=MaxPoolGradGradV2; signature=orig_input:T, orig_output:T, grad:T, ksize:int32, strides:int32 -> output:T; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:37.712187: I tensorflow/core/framework/op.cc:132] Op<name=MaxPoolGradGradWithArgmax; signature=input:T, grad:T, argmax:Targmax -> output:T; attr=ksize:list(int),min=4; attr=strides:list(int),min=4; attr=padding:string,allowed=["SAME", "VALID"]; attr=include_batch_in_index:bool,default=false; attr=Targmax:type,allowed=[DT_INT32, DT_INT64]; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:37.712279: I tensorflow/core/framework/op.cc:132] Op<name=MaxPoolGradV2; signature=orig_input:T, orig_output:T, grad:T, ksize:int32, strides:int32 -> output:T; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=T:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:37.712403: I tensorflow/core/framework/op.cc:132] Op<name=MaxPoolGradWithArgmax; signature=input:T, grad:T, argmax:Targmax -> output:T; attr=ksize:list(int),min=4; attr=strides:list(int),min=4; attr=padding:string,allowed=["SAME", "VALID"]; attr=include_batch_in_index:bool,default=false; attr=Targmax:type,allowed=[DT_INT32, DT_INT64]; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:37.712611: I tensorflow/core/framework/op.cc:132] Op<name=MaxPoolV2; signature=input:T, ksize:int32, strides:int32 -> output:T; attr=T:type,default=DT_FLOAT,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64, DT_UINT8, DT_INT16, DT_INT8, DT_UINT16, DT_QINT8]; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW", "NCHW_VECT_C"]>
  2023-01-12 09:34:37.712714: I tensorflow/core/framework/op.cc:132] Op<name=MaxPoolWithArgmax; signature=input:T -> output:T, argmax:Targmax; attr=ksize:list(int),min=4; attr=strides:list(int),min=4; attr=Targmax:type,default=DT_INT64,allowed=[DT_INT32, DT_INT64]; attr=padding:string,allowed=["SAME", "VALID"]; attr=include_batch_in_index:bool,default=false; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:37.712785: I tensorflow/core/framework/op.cc:132] Op<name=Maximum; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT8, DT_UINT8, DT_INT16, DT_UINT16, DT_INT32, DT_UINT32, DT_INT64, DT_UINT64]>
  2023-01-12 09:34:37.712893: I tensorflow/core/framework/op.cc:132] Op<name=Mean; signature=input:T, reduction_indices:Tidx -> output:T; attr=keep_dims:bool,default=false; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.713002: I tensorflow/core/framework/op.cc:132] Op<name=Merge; signature=inputs:N*T -> output:T, value_index:int32; attr=T:type; attr=N:int,min=1>
  2023-01-12 09:34:37.713096: I tensorflow/core/framework/op.cc:132] Op<name=MergeSummary; signature=inputs:N*string -> summary:string; attr=N:int,min=1>
  2023-01-12 09:34:37.713145: I tensorflow/core/framework/op.cc:132] Op<name=MergeV2Checkpoints; signature=checkpoint_prefixes:string, destination_prefix:string -> ; attr=delete_old_dirs:bool,default=true; attr=allow_missing_files:bool,default=false; is_stateful=true>
  2023-01-12 09:34:37.713292: I tensorflow/core/framework/op.cc:132] Op<name=Mfcc; signature=spectrogram:float, sample_rate:int32 -> output:float; attr=upper_frequency_limit:float,default=4000; attr=lower_frequency_limit:float,default=20; attr=filterbank_channel_count:int,default=40; attr=dct_coefficient_count:int,default=13>
  2023-01-12 09:34:37.713412: I tensorflow/core/framework/op.cc:132] Op<name=Min; signature=input:T, reduction_indices:Tidx -> output:T; attr=keep_dims:bool,default=false; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 12026250066093653660, DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.713526: I tensorflow/core/framework/op.cc:132] Op<name=Minimum; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT8, DT_UINT8, DT_INT16, DT_UINT16, DT_INT32, DT_UINT32, DT_INT64, DT_UINT64]>
  2023-01-12 09:34:37.713655: I tensorflow/core/framework/op.cc:132] Op<name=MirrorPad; signature=input:T, paddings:Tpaddings -> output:T; attr=T:type; attr=Tpaddings:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=mode:string,allowed=["REFLECT", "SYMMETRIC"]>
  2023-01-12 09:34:37.713727: I tensorflow/core/framework/op.cc:132] Op<name=MirrorPadGrad; signature=input:T, paddings:Tpaddings -> output:T; attr=T:type; attr=Tpaddings:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=mode:string,allowed=["REFLECT", "SYMMETRIC"]>
  2023-01-12 09:34:37.713776: I tensorflow/core/framework/op.cc:132] Op<name=MixedStruct; signature= -> a:n_a*int32, b:float; attr=n_a:int,min=0>
  2023-01-12 09:34:37.713883: I tensorflow/core/framework/op.cc:132] Op<name=MlirPassthroughOp; signature=inputs: -> outputs:; attr=mlir_module:string; attr=Tinputs:list(type),min=0; attr=Toutputs:list(type),min=0>
  2023-01-12 09:34:37.713940: I tensorflow/core/framework/op.cc:132] Op<name=Mod; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_INT32, DT_INT64, DT_HALF, DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.713986: I tensorflow/core/framework/op.cc:132] Op<name=ModelDataset; signature=input_dataset:variant -> handle:variant; attr=algorithm:int,default=0; attr=cpu_budget:int,default=0; attr=ram_budget:int,default=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1>
  2023-01-12 09:34:37.714081: I tensorflow/core/framework/op.cc:132] Op<name=Mul; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_INT32, DT_UINT32, DT_UINT64, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]; is_commutative=true>
  2023-01-12 09:34:37.714149: I tensorflow/core/framework/op.cc:132] Op<name=MulNoNan; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.714209: I tensorflow/core/framework/op.cc:132] Op<name=MultiDeviceIterator; signature= -> handle:resource; attr=devices:list(string),min=1; attr=shared_name:string; attr=container:string; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; is_stateful=true>
  2023-01-12 09:34:37.714259: I tensorflow/core/framework/op.cc:132] Op<name=MultiDeviceIteratorFromStringHandle; signature=string_handle:string -> multi_device_iterator:resource; attr=output_types:list(type),default=[],min=0; attr=output_shapes:list(shape),default=[],min=0; is_stateful=true>
  2023-01-12 09:34:37.714314: I tensorflow/core/framework/op.cc:132] Op<name=MultiDeviceIteratorGetNextFromShard; signature=multi_device_iterator:resource, shard_num:int32, incarnation_id:int64 -> components:; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; is_stateful=true>
  2023-01-12 09:34:37.714359: I tensorflow/core/framework/op.cc:132] Op<name=MultiDeviceIteratorInit; signature=dataset:variant, multi_device_iterator:resource, max_buffer_size:int64 -> incarnation_id:int64; is_stateful=true>
  2023-01-12 09:34:37.714400: I tensorflow/core/framework/op.cc:132] Op<name=MultiDeviceIteratorToStringHandle; signature=multi_device_iterator:resource -> string_handle:string; is_stateful=true>
  2023-01-12 09:34:37.714503: I tensorflow/core/framework/op.cc:132] Op<name=Multinomial; signature=logits:T, num_samples:int32 -> output:output_dtype; attr=seed:int,default=0; attr=seed2:int,default=0; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]; attr=output_dtype:type,default=DT_INT64,allowed=[DT_INT32, DT_INT64]; is_stateful=true>
  2023-01-12 09:34:37.714626: I tensorflow/core/framework/op.cc:132] Op<name=MutableDenseHashTable; signature=empty_key:key_dtype -> table_handle:Ref(string); attr=container:string,default=""; attr=shared_name:string,default=""; attr=use_node_name_sharing:bool,default=false; attr=key_dtype:type; attr=value_dtype:type; attr=value_shape:shape,default=[]; attr=initial_num_buckets:int,default=131072; attr=max_load_factor:float,default=0.8; is_stateful=true>
  2023-01-12 09:34:37.714872: I tensorflow/core/framework/op.cc:132] Op<name=MutableDenseHashTableV2; signature=empty_key:key_dtype, deleted_key:key_dtype -> table_handle:resource; attr=container:string,default=""; attr=shared_name:string,default=""; attr=use_node_name_sharing:bool,default=false; attr=key_dtype:type; attr=value_dtype:type; attr=value_shape:shape,default=[]; attr=initial_num_buckets:int,default=131072; attr=max_load_factor:float,default=0.8; is_stateful=true>
  2023-01-12 09:34:37.714985: I tensorflow/core/framework/op.cc:132] Op<name=MutableHashTable; signature= -> table_handle:Ref(string); attr=container:string,default=""; attr=shared_name:string,default=""; attr=use_node_name_sharing:bool,default=false; attr=key_dtype:type; attr=value_dtype:type; is_stateful=true>
  2023-01-12 09:34:37.715099: I tensorflow/core/framework/op.cc:132] Op<name=MutableHashTableOfTensors; signature= -> table_handle:Ref(string); attr=container:string,default=""; attr=shared_name:string,default=""; attr=use_node_name_sharing:bool,default=false; attr=key_dtype:type; attr=value_dtype:type; attr=value_shape:shape,default=[]; is_stateful=true>
  2023-01-12 09:34:37.715168: I tensorflow/core/framework/op.cc:132] Op<name=MutableHashTableOfTensorsV2; signature= -> table_handle:resource; attr=container:string,default=""; attr=shared_name:string,default=""; attr=use_node_name_sharing:bool,default=false; attr=key_dtype:type; attr=value_dtype:type; attr=value_shape:shape,default=[]; is_stateful=true>
  2023-01-12 09:34:37.715212: I tensorflow/core/framework/op.cc:132] Op<name=MutableHashTableV2; signature= -> table_handle:resource; attr=container:string,default=""; attr=shared_name:string,default=""; attr=use_node_name_sharing:bool,default=false; attr=key_dtype:type; attr=value_dtype:type; is_stateful=true>
  2023-01-12 09:34:37.715311: I tensorflow/core/framework/op.cc:132] Op<name=MutexLock; signature=mutex:resource -> mutex_lock:variant; is_stateful=true>
  2023-01-12 09:34:37.715358: I tensorflow/core/framework/op.cc:132] Op<name=MutexV2; signature= -> resource:resource; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.715535: I tensorflow/core/framework/op.cc:132] Op<name=NInPolymorphicTwice; signature=a:N*T, b:N*T -> ; attr=T:type; attr=N:int,min=0>
  2023-01-12 09:34:37.715602: I tensorflow/core/framework/op.cc:132] Op<name=NInTwice; signature=a:N*int32, b:N*string -> ; attr=N:int,min=0>
  2023-01-12 09:34:37.715660: I tensorflow/core/framework/op.cc:132] Op<name=NInTwoTypeVariables; signature=a:N*S, b:N*T -> ; attr=S:type; attr=T:type; attr=N:int,min=0>
  2023-01-12 09:34:37.715753: I tensorflow/core/framework/op.cc:132] Op<name=NIntsIn; signature=a:N*int32 -> ; attr=N:int,min=2>
  2023-01-12 09:34:37.715818: I tensorflow/core/framework/op.cc:132] Op<name=NIntsOut; signature= -> a:N*int32; attr=N:int,min=2>
  2023-01-12 09:34:37.715863: I tensorflow/core/framework/op.cc:132] Op<name=NIntsOutDefault; signature= -> a:N*int32; attr=N:int,default=3,min=2>
  2023-01-12 09:34:37.715902: I tensorflow/core/framework/op.cc:132] Op<name=NPolymorphicIn; signature=a:N*T -> ; attr=T:type; attr=N:int,min=2>
  2023-01-12 09:34:37.715939: I tensorflow/core/framework/op.cc:132] Op<name=NPolymorphicOut; signature= -> a:N*T; attr=T:type; attr=N:int,min=2>
  2023-01-12 09:34:37.715985: I tensorflow/core/framework/op.cc:132] Op<name=NPolymorphicOutDefault; signature= -> a:N*T; attr=T:type,default=DT_BOOL; attr=N:int,default=2,min=2>
  2023-01-12 09:34:37.716049: I tensorflow/core/framework/op.cc:132] Op<name=NPolymorphicRestrictIn; signature=a:N*T -> ; attr=T:type,allowed=[DT_STRING, DT_BOOL]; attr=N:int,min=2>
  2023-01-12 09:34:37.716105: I tensorflow/core/framework/op.cc:132] Op<name=NPolymorphicRestrictOut; signature= -> a:N*T; attr=T:type,allowed=[DT_STRING, DT_BOOL]; attr=N:int,min=2>
  2023-01-12 09:34:37.716153: I tensorflow/core/framework/op.cc:132] Op<name=Namespace>TestStringOutput; signature=input:float -> output1:float, output2:string>
  2023-01-12 09:34:37.716225: I tensorflow/core/framework/op.cc:132] Op<name=NcclAllReduce; signature=input:T -> data:T; attr=reduction:string,allowed=["min", "max", "prod", "sum"]; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64]; attr=num_devices:int; attr=shared_name:string; is_stateful=true>
  2023-01-12 09:34:37.716283: I tensorflow/core/framework/op.cc:132] Op<name=NcclBroadcast; signature=input:T -> output:T; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64]; attr=shape:shape; is_stateful=true>
  2023-01-12 09:34:37.716443: I tensorflow/core/framework/op.cc:132] Op<name=NcclReduce; signature=input:num_devices*T -> data:T; attr=reduction:string,allowed=["min", "max", "prod", "sum"]; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64]; attr=num_devices:int,min=1; is_stateful=true>
  2023-01-12 09:34:37.716621: I tensorflow/core/framework/op.cc:132] Op<name=Ndtri; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.717305: I tensorflow/core/framework/op.cc:132] Op<name=NearestNeighbors; signature=points:float, centers:float, k:int64 -> nearest_center_indices:int64, nearest_center_distances:float>
  2023-01-12 09:34:37.717376: I tensorflow/core/framework/op.cc:132] Op<name=Neg; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT8, DT_INT16, DT_INT32, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.717467: I tensorflow/core/framework/op.cc:132] Op<name=NegTrain; signature=w_in:Ref(float), w_out:Ref(float), examples:int32, labels:int32, lr:float -> ; attr=vocab_count:list(int); attr=num_negative_samples:int; is_stateful=true>
  2023-01-12 09:34:37.717519: I tensorflow/core/framework/op.cc:132] Op<name=NextAfter; signature=x1:T, x2:T -> output:T; attr=T:type,default=DT_FLOAT,allowed=[DT_DOUBLE, DT_FLOAT]>
  2023-01-12 09:34:37.717638: I tensorflow/core/framework/op.cc:132] Op<name=NextIteration; signature=data:T -> output:T; attr=T:type>
  2023-01-12 09:34:37.717675: I tensorflow/core/framework/op.cc:132] Op<name=NoOp; signature= -> >
  2023-01-12 09:34:37.718006: I tensorflow/core/framework/op.cc:132] Op<name=NonDeterministicInts; signature=shape:shape_dtype -> output:dtype; attr=dtype:type,default=DT_INT64; attr=shape_dtype:type,default=DT_INT64; is_stateful=true>
  2023-01-12 09:34:37.718169: I tensorflow/core/framework/op.cc:132] Op<name=NonMaxSuppression; signature=boxes:float, scores:float, max_output_size:int32 -> selected_indices:int32; attr=iou_threshold:float,default=0.5>
  2023-01-12 09:34:37.718322: I tensorflow/core/framework/op.cc:132] Op<name=NonMaxSuppressionV2; signature=boxes:T, scores:T, max_output_size:int32, iou_threshold:T_threshold -> selected_indices:int32; attr=T:type,default=DT_FLOAT,allowed=[DT_HALF, DT_FLOAT]; attr=T_threshold:type,default=DT_FLOAT,allowed=[DT_HALF, DT_FLOAT]>
  2023-01-12 09:34:37.718561: I tensorflow/core/framework/op.cc:132] Op<name=NonMaxSuppressionV3; signature=boxes:T, scores:T, max_output_size:int32, iou_threshold:T_threshold, score_threshold:T_threshold -> selected_indices:int32; attr=T:type,default=DT_FLOAT,allowed=[DT_HALF, DT_FLOAT]; attr=T_threshold:type,default=DT_FLOAT,allowed=[DT_HALF, DT_FLOAT]>
  2023-01-12 09:34:37.718677: I tensorflow/core/framework/op.cc:132] Op<name=NonMaxSuppressionV4; signature=boxes:T, scores:T, max_output_size:int32, iou_threshold:T_threshold, score_threshold:T_threshold -> selected_indices:int32, valid_outputs:int32; attr=T:type,default=DT_FLOAT,allowed=[DT_HALF, DT_FLOAT]; attr=T_threshold:type,default=DT_FLOAT,allowed=[DT_HALF, DT_FLOAT]; attr=pad_to_max_output_size:bool,default=false>
  2023-01-12 09:34:37.718738: I tensorflow/core/framework/op.cc:132] Op<name=NonMaxSuppressionV5; signature=boxes:T, scores:T, max_output_size:int32, iou_threshold:T, score_threshold:T, soft_nms_sigma:T -> selected_indices:int32, selected_scores:T, valid_outputs:int32; attr=T:type,default=DT_FLOAT,allowed=[DT_HALF, DT_FLOAT]; attr=pad_to_max_output_size:bool,default=false>
  2023-01-12 09:34:37.718773: I tensorflow/core/framework/op.cc:132] Op<name=NonMaxSuppressionWithOverlaps; signature=overlaps:float, scores:float, max_output_size:int32, overlap_threshold:float, score_threshold:float -> selected_indices:int32>
  2023-01-12 09:34:37.718798: I tensorflow/core/framework/op.cc:132] Op<name=NonSerializableDataset; signature=input_dataset:variant -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1>
  2023-01-12 09:34:37.718816: I tensorflow/core/framework/op.cc:132] Op<name=None; signature= -> >
  2023-01-12 09:34:37.718840: I tensorflow/core/framework/op.cc:132] Op<name=NotEqual; signature=x:T, y:T -> z:bool; attr=T:type; attr=incompatible_shape_error:bool,default=true; is_commutative=true>
  2023-01-12 09:34:37.718872: I tensorflow/core/framework/op.cc:132] Op<name=NthElement; signature=input:T, n:int32 -> values:T; attr=reverse:bool,default=false; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:37.718899: I tensorflow/core/framework/op.cc:132] Op<name=Old; signature= -> >
  2023-01-12 09:34:37.718970: I tensorflow/core/framework/op.cc:132] Op<name=OneHot; signature=indices:TI, depth:int32, on_value:T, off_value:T -> output:T; attr=axis:int,default=-1; attr=T:type; attr=TI:type,default=DT_INT64,allowed=[DT_UINT8, DT_INT8, DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.719011: I tensorflow/core/framework/op.cc:132] Op<name=OneShotIterator; signature= -> handle:resource; attr=dataset_factory:func; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.719057: I tensorflow/core/framework/op.cc:132] Op<name=OnesLike; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT8, 4053465685252612840, DT_INT64, DT_UINT64, DT_COMPLEX64, DT_COMPLEX128, DT_BOOL]>
  2023-01-12 09:34:37.719098: I tensorflow/core/framework/op.cc:132] Op<name=OpWithDefaultAttr; signature= -> a:int32; attr=default_float:float,default=123>
  2023-01-12 09:34:37.719119: I tensorflow/core/framework/op.cc:132] Op<name=OpWithFutureDefaultAttr; signature= -> >
  2023-01-12 09:34:37.719143: I tensorflow/core/framework/op.cc:132] Op<name=OptimizeDataset; signature=input_dataset:variant, optimizations:string -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=optimization_configs:list(string),default=[]>
  2023-01-12 09:34:37.719172: I tensorflow/core/framework/op.cc:132] Op<name=OptimizeDatasetV2; signature=input_dataset:variant, optimizations_enabled:string, optimizations_disabled:string, optimizations_default:string -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=optimization_configs:list(string),default=[]>
  2023-01-12 09:34:37.719195: I tensorflow/core/framework/op.cc:132] Op<name=OptionalFromValue; signature=components: -> optional:variant; attr=Toutput_types:list(type),min=1>
  2023-01-12 09:34:37.719218: I tensorflow/core/framework/op.cc:132] Op<name=OptionalGetValue; signature=optional:variant -> components:; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1>
  2023-01-12 09:34:37.719238: I tensorflow/core/framework/op.cc:132] Op<name=OptionalHasValue; signature=optional:variant -> has_value:bool>
  2023-01-12 09:34:37.719255: I tensorflow/core/framework/op.cc:132] Op<name=OptionalNone; signature= -> optional:variant>
  2023-01-12 09:34:37.719277: I tensorflow/core/framework/op.cc:132] Op<name=OptionsDataset; signature=input_dataset:variant -> handle:variant; attr=serialized_options:string; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=metadata:string,default="">
  2023-01-12 09:34:37.719301: I tensorflow/core/framework/op.cc:132] Op<name=OrderedMapClear; signature= -> ; attr=capacity:int,default=0,min=0; attr=memory_limit:int,default=0,min=0; attr=dtypes:list(type); attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.719327: I tensorflow/core/framework/op.cc:132] Op<name=OrderedMapIncompleteSize; signature= -> size:int32; attr=capacity:int,default=0,min=0; attr=memory_limit:int,default=0,min=0; attr=dtypes:list(type); attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.719353: I tensorflow/core/framework/op.cc:132] Op<name=OrderedMapPeek; signature=key:int64, indices:int32 -> values:; attr=capacity:int,default=0,min=0; attr=memory_limit:int,default=0,min=0; attr=dtypes:list(type),min=1; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.719379: I tensorflow/core/framework/op.cc:132] Op<name=OrderedMapSize; signature= -> size:int32; attr=capacity:int,default=0,min=0; attr=memory_limit:int,default=0,min=0; attr=dtypes:list(type); attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.719406: I tensorflow/core/framework/op.cc:132] Op<name=OrderedMapStage; signature=key:int64, indices:int32, values: -> ; attr=capacity:int,default=0,min=0; attr=memory_limit:int,default=0,min=0; attr=dtypes:list(type); attr=fake_dtypes:list(type),min=1; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.719433: I tensorflow/core/framework/op.cc:132] Op<name=OrderedMapUnstage; signature=key:int64, indices:int32 -> values:; attr=capacity:int,default=0,min=0; attr=memory_limit:int,default=0,min=0; attr=dtypes:list(type),min=1; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.719461: I tensorflow/core/framework/op.cc:132] Op<name=OrderedMapUnstageNoKey; signature=indices:int32 -> key:int64, values:; attr=capacity:int,default=0,min=0; attr=memory_limit:int,default=0,min=0; attr=dtypes:list(type),min=1; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.719480: I tensorflow/core/framework/op.cc:132] Op<name=OutT; signature= -> a:T; attr=T:type>
  2023-01-12 09:34:37.719500: I tensorflow/core/framework/op.cc:132] Op<name=OutTypeList; signature= -> out:; attr=T:list(type),min=0>
  2023-01-12 09:34:37.719522: I tensorflow/core/framework/op.cc:132] Op<name=OutTypeListRestrict; signature= -> out:; attr=t:list(type),min=1,allowed=[DT_STRING, DT_BOOL]>
  2023-01-12 09:34:37.719544: I tensorflow/core/framework/op.cc:132] Op<name=OutfeedDequeue; signature= -> output:dtype; attr=dtype:type; attr=shape:shape; attr=device_ordinal:int,default=-1; is_stateful=true>
  2023-01-12 09:34:37.719627: I tensorflow/core/framework/op.cc:132] Op<name=OutfeedDequeueTuple; signature= -> outputs:; attr=dtypes:list(type),min=1; attr=shapes:list(shape); attr=device_ordinal:int,default=-1; is_stateful=true>
  2023-01-12 09:34:37.719680: I tensorflow/core/framework/op.cc:132] Op<name=OutfeedDequeueTupleV2; signature=device_ordinal:int32 -> outputs:; attr=dtypes:list(type),min=1; attr=shapes:list(shape); is_stateful=true>
  2023-01-12 09:34:37.719702: I tensorflow/core/framework/op.cc:132] Op<name=OutfeedDequeueV2; signature=device_ordinal:int32 -> output:dtype; attr=dtype:type; attr=shape:shape; is_stateful=true>
  2023-01-12 09:34:37.719719: I tensorflow/core/framework/op.cc:132] Op<name=OutfeedEnqueue; signature=input:dtype -> ; attr=dtype:type; is_stateful=true>
  2023-01-12 09:34:37.719738: I tensorflow/core/framework/op.cc:132] Op<name=OutfeedEnqueueTuple; signature=inputs: -> ; attr=dtypes:list(type),min=1; is_stateful=true>
  2023-01-12 09:34:37.719793: I tensorflow/core/framework/op.cc:132] Op<name=Pack; signature=values:N*T -> output:T; attr=N:int,min=1; attr=T:type; attr=axis:int,default=0>
  2023-01-12 09:34:37.719840: I tensorflow/core/framework/op.cc:132] Op<name=Pad; signature=input:T, paddings:Tpaddings -> output:T; attr=T:type; attr=Tpaddings:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.719867: I tensorflow/core/framework/op.cc:132] Op<name=PadV2; signature=input:T, paddings:Tpaddings, constant_values:T -> output:T; attr=T:type; attr=Tpaddings:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.719903: I tensorflow/core/framework/op.cc:132] Op<name=PaddedBatchDataset; signature=input_dataset:variant, batch_size:int64, padded_shapes:N*int64, padding_values: -> handle:variant; attr=Toutput_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=N:int,min=1; attr=metadata:string,default="">
  2023-01-12 09:34:37.719969: I tensorflow/core/framework/op.cc:132] Op<name=PaddedBatchDatasetV2; signature=input_dataset:variant, batch_size:int64, padded_shapes:N*int64, padding_values:, drop_remainder:bool -> handle:variant; attr=parallel_copy:bool,default=false; attr=Toutput_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=N:int,min=1; attr=metadata:string,default="">
  2023-01-12 09:34:37.720074: I tensorflow/core/framework/op.cc:132] Op<name=PaddingFIFOQueue; signature= -> handle:Ref(string); attr=component_types:list(type),min=1; attr=shapes:list(shape),default=[],min=0; attr=capacity:int,default=-1; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.720759: I tensorflow/core/framework/op.cc:132] Op<name=PaddingFIFOQueueV2; signature= -> handle:resource; attr=component_types:list(type),min=1; attr=shapes:list(shape),default=[],min=0; attr=capacity:int,default=-1; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.720955: I tensorflow/core/framework/op.cc:132] Op<name=ParallelBatchDataset; signature=input_dataset:variant, batch_size:int64, num_parallel_calls:int64, drop_remainder:bool -> handle:variant; attr=parallel_copy:bool,default=false; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=deterministic:string,default="default"; attr=metadata:string,default="">
  2023-01-12 09:34:37.721117: I tensorflow/core/framework/op.cc:132] Op<name=ParallelConcat; signature=values:N*T -> output:T; attr=N:int,min=1; attr=T:type; attr=shape:shape>
  2023-01-12 09:34:37.721217: I tensorflow/core/framework/op.cc:132] Op<name=ParallelDynamicStitch; signature=indices:N*int32, data:N*T -> merged:T; attr=N:int,min=1; attr=T:type>
  2023-01-12 09:34:37.721296: I tensorflow/core/framework/op.cc:132] Op<name=ParallelFilterDataset; signature=input_dataset:variant, other_arguments:, num_parallel_calls:int64 -> handle:variant; attr=predicate:func; attr=deterministic:string,default="default"; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=metadata:string,default="">
  2023-01-12 09:34:37.721401: I tensorflow/core/framework/op.cc:132] Op<name=ParallelInterleaveDataset; signature=input_dataset:variant, other_arguments:, cycle_length:int64, block_length:int64, sloppy:bool, buffer_output_elements:int64, prefetch_input_elements:int64 -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=metadata:string,default="">
  2023-01-12 09:34:37.721679: I tensorflow/core/framework/op.cc:132] Op<name=ParallelInterleaveDatasetV2; signature=input_dataset:variant, other_arguments:, cycle_length:int64, block_length:int64, num_parallel_calls:int64 -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=sloppy:bool,default=false; attr=metadata:string,default="">
  2023-01-12 09:34:37.722063: I tensorflow/core/framework/op.cc:132] Op<name=ParallelInterleaveDatasetV3; signature=input_dataset:variant, other_arguments:, cycle_length:int64, block_length:int64, num_parallel_calls:int64 -> handle:variant; attr=f:func; attr=deterministic:string,default="default"; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=metadata:string,default="">
  2023-01-12 09:34:37.722206: I tensorflow/core/framework/op.cc:132] Op<name=ParallelInterleaveDatasetV4; signature=input_dataset:variant, other_arguments:, cycle_length:int64, block_length:int64, buffer_output_elements:int64, prefetch_input_elements:int64, num_parallel_calls:int64 -> handle:variant; attr=f:func; attr=deterministic:string,default="default"; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=metadata:string,default="">
  2023-01-12 09:34:37.722288: I tensorflow/core/framework/op.cc:132] Op<name=ParallelMapDataset; signature=input_dataset:variant, other_arguments:, num_parallel_calls:int32 -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=sloppy:bool,default=false; attr=preserve_cardinality:bool,default=false; attr=metadata:string,default="">
  2023-01-12 09:34:37.722383: I tensorflow/core/framework/op.cc:132] Op<name=ParallelMapDatasetV2; signature=input_dataset:variant, other_arguments:, num_parallel_calls:int64 -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=deterministic:string,default="default"; attr=preserve_cardinality:bool,default=false; attr=metadata:string,default="">
  2023-01-12 09:34:37.722559: I tensorflow/core/framework/op.cc:132] Op<name=ParameterizedTruncatedNormal; signature=shape:T, means:dtype, stdevs:dtype, minvals:dtype, maxvals:dtype -> output:dtype; attr=seed:int,default=0; attr=seed2:int,default=0; attr=dtype:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]; attr=T:type,allowed=[DT_INT32, DT_INT64]; is_stateful=true>
  2023-01-12 09:34:37.722658: I tensorflow/core/framework/op.cc:132] Op<name=ParseExample; signature=serialized:string, names:string, sparse_keys:Nsparse*string, dense_keys:Ndense*string, dense_defaults: -> sparse_indices:Nsparse*int64, sparse_values:, sparse_shapes:Nsparse*int64, dense_values:; attr=Nsparse:int,min=0; attr=Ndense:int,min=0; attr=sparse_types:list(type),min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=Tdense:list(type),min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=dense_shapes:list(shape),min=0>
  2023-01-12 09:34:37.722760: I tensorflow/core/framework/op.cc:132] Op<name=ParseExampleDataset; signature=input_dataset:variant, num_parallel_calls:int64, dense_defaults: -> handle:variant; attr=sparse_keys:list(string),min=0; attr=dense_keys:list(string),min=0; attr=sparse_types:list(type),min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=Tdense:list(type),min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=dense_shapes:list(shape),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=sloppy:bool,default=false; attr=ragged_keys:list(string),default=[],min=0; attr=ragged_value_types:list(type),default=[],min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=ragged_split_types:list(type),default=[],min=0,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.723019: I tensorflow/core/framework/op.cc:132] Op<name=ParseExampleDatasetV2; signature=input_dataset:variant, num_parallel_calls:int64, dense_defaults: -> handle:variant; attr=sparse_keys:list(string),min=0; attr=dense_keys:list(string),min=0; attr=sparse_types:list(type),min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=Tdense:list(type),min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=dense_shapes:list(shape),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=deterministic:string,default="default"; attr=ragged_keys:list(string),default=[],min=0; attr=ragged_value_types:list(type),default=[],min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=ragged_split_types:list(type),default=[],min=0,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.723137: I tensorflow/core/framework/op.cc:132] Op<name=ParseExampleV2; signature=serialized:string, names:string, sparse_keys:string, dense_keys:string, ragged_keys:string, dense_defaults: -> sparse_indices:num_sparse*int64, sparse_values:, sparse_shapes:num_sparse*int64, dense_values:, ragged_values:, ragged_row_splits:; attr=Tdense:list(type),min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=num_sparse:int,min=0; attr=sparse_types:list(type),min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=ragged_value_types:list(type),min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=ragged_split_types:list(type),min=0,allowed=[DT_INT32, DT_INT64]; attr=dense_shapes:list(shape),min=0>
  2023-01-12 09:34:37.723316: I tensorflow/core/framework/op.cc:132] Op<name=ParseSequenceExample; signature=serialized:string, debug_name:string, context_dense_defaults: -> context_sparse_indices:Ncontext_sparse*int64, context_sparse_values:, context_sparse_shapes:Ncontext_sparse*int64, context_dense_values:, feature_list_sparse_indices:Nfeature_list_sparse*int64, feature_list_sparse_values:, feature_list_sparse_shapes:Nfeature_list_sparse*int64, feature_list_dense_values:, feature_list_dense_lengths:Nfeature_list_dense*int64; attr=feature_list_dense_missing_assumed_empty:list(string),min=0; attr=context_sparse_keys:list(string),min=0; attr=context_dense_keys:list(string),min=0; attr=feature_list_sparse_keys:list(string),min=0; attr=feature_list_dense_keys:list(string),min=0; attr=Ncontext_sparse:int,default=0,min=0; attr=Ncontext_dense:int,default=0,min=0; attr=Nfeature_list_sparse:int,default=0,min=0; attr=Nfeature_list_dense:int,default=0,min=0; attr=context_sparse_types:list(type),default=[],min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=Tcontext_dense:list(type),default=[],min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=feature_list_dense_types:list(type),default=[],min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=context_dense_shapes:list(shape),default=[],min=0; attr=feature_list_sparse_types:list(type),default=[],min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=feature_list_dense_shapes:list(shape),default=[],min=0>
  2023-01-12 09:34:37.723634: I tensorflow/core/framework/op.cc:132] Op<name=ParseSequenceExampleV2; signature=serialized:string, debug_name:string, context_sparse_keys:string, context_dense_keys:string, context_ragged_keys:string, feature_list_sparse_keys:string, feature_list_dense_keys:string, feature_list_ragged_keys:string, feature_list_dense_missing_assumed_empty:bool, context_dense_defaults: -> context_sparse_indices:Ncontext_sparse*int64, context_sparse_values:, context_sparse_shapes:Ncontext_sparse*int64, context_dense_values:, context_ragged_values:, context_ragged_row_splits:, feature_list_sparse_indices:Nfeature_list_sparse*int64, feature_list_sparse_values:, feature_list_sparse_shapes:Nfeature_list_sparse*int64, feature_list_dense_values:, feature_list_dense_lengths:Nfeature_list_dense*int64, feature_list_ragged_values:, feature_list_ragged_outer_splits:, feature_list_ragged_inner_splits:; attr=Ncontext_sparse:int,default=0,min=0; attr=Tcontext_dense:list(type),default=[],min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=context_sparse_types:list(type),default=[],min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=context_ragged_value_types:list(type),default=[],min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=context_ragged_split_types:list(type),default=[],min=0,allowed=[DT_INT32, DT_INT64]; attr=context_dense_shapes:list(shape),default=[],min=0; attr=Nfeature_list_sparse:int,default=0,min=0; attr=Nfeature_list_dense:int,default=0,min=0; attr=feature_list_dense_types:list(type),default=[],min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=feature_list_sparse_types:list(type),default=[],min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=feature_list_ragged_value_types:list(type),default=[],min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=feature_list_ragged_split_types:list(type),default=[],min=0,allowed=[DT_INT32, DT_INT64]; attr=feature_list_dense_shapes:list(shape),default=[],min=0>
  2023-01-12 09:34:37.723861: I tensorflow/core/framework/op.cc:132] Op<name=ParseSingleExample; signature=serialized:string, dense_defaults: -> sparse_indices:num_sparse*int64, sparse_values:, sparse_shapes:num_sparse*int64, dense_values:; attr=num_sparse:int,min=0; attr=sparse_keys:list(string),min=0; attr=dense_keys:list(string),min=0; attr=sparse_types:list(type),min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=Tdense:list(type),min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=dense_shapes:list(shape),min=0>
  2023-01-12 09:34:37.723999: I tensorflow/core/framework/op.cc:132] Op<name=ParseSingleSequenceExample; signature=serialized:string, feature_list_dense_missing_assumed_empty:string, context_sparse_keys:Ncontext_sparse*string, context_dense_keys:Ncontext_dense*string, feature_list_sparse_keys:Nfeature_list_sparse*string, feature_list_dense_keys:Nfeature_list_dense*string, context_dense_defaults:, debug_name:string -> context_sparse_indices:Ncontext_sparse*int64, context_sparse_values:, context_sparse_shapes:Ncontext_sparse*int64, context_dense_values:, feature_list_sparse_indices:Nfeature_list_sparse*int64, feature_list_sparse_values:, feature_list_sparse_shapes:Nfeature_list_sparse*int64, feature_list_dense_values:; attr=Ncontext_sparse:int,default=0,min=0; attr=Ncontext_dense:int,default=0,min=0; attr=Nfeature_list_sparse:int,default=0,min=0; attr=Nfeature_list_dense:int,default=0,min=0; attr=context_sparse_types:list(type),default=[],min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=Tcontext_dense:list(type),default=[],min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=feature_list_dense_types:list(type),default=[],min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=context_dense_shapes:list(shape),default=[],min=0; attr=feature_list_sparse_types:list(type),default=[],min=0,allowed=[DT_FLOAT, DT_INT64, DT_STRING]; attr=feature_list_dense_shapes:list(shape),default=[],min=0>
  2023-01-12 09:34:37.724150: I tensorflow/core/framework/op.cc:132] Op<name=ParseTensor; signature=serialized:string -> output:out_type; attr=out_type:type>
  2023-01-12 09:34:37.724239: I tensorflow/core/framework/op.cc:132] Op<name=PartitionedCall; signature=args: -> output:; attr=Tin:list(type),min=0; attr=Tout:list(type),min=0; attr=f:func; attr=config:string,default=""; attr=config_proto:string,default=""; attr=executor_type:string,default="">
  2023-01-12 09:34:37.724282: I tensorflow/core/framework/op.cc:132] Op<name=Placeholder; signature= -> output:dtype; attr=dtype:type; attr=shape:shape,default=<unknown>>
  2023-01-12 09:34:37.724300: I tensorflow/core/framework/op.cc:132] Op<name=PlaceholderV2; signature= -> output:dtype; attr=dtype:type; attr=shape:shape>
  2023-01-12 09:34:37.724311: I tensorflow/core/framework/op.cc:132] Op<name=PlaceholderWithDefault; signature=input:dtype -> output:dtype; attr=dtype:type; attr=shape:shape>
  2023-01-12 09:34:37.724329: I tensorflow/core/framework/op.cc:132] Op<name=Polygamma; signature=a:T, x:T -> z:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.724342: I tensorflow/core/framework/op.cc:132] Op<name=Polymorphic; signature=a:T -> out:T; attr=T:type>
  2023-01-12 09:34:37.724352: I tensorflow/core/framework/op.cc:132] Op<name=PolymorphicDefaultOut; signature= -> out:T; attr=T:type,default=DT_STRING>
  2023-01-12 09:34:37.724361: I tensorflow/core/framework/op.cc:132] Op<name=PolymorphicOut; signature= -> out:T; attr=T:type>
  2023-01-12 09:34:37.724377: I tensorflow/core/framework/op.cc:132] Op<name=PopulationCount; signature=x:T -> y:uint8; attr=T:type,allowed=[DT_INT8, DT_INT16, DT_INT32, DT_INT64, DT_UINT8, DT_UINT16, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:37.724394: I tensorflow/core/framework/op.cc:132] Op<name=Pow; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT, DT_HALF, DT_DOUBLE, DT_INT8, DT_INT16, DT_INT32, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.724413: I tensorflow/core/framework/op.cc:132] Op<name=PrefetchDataset; signature=input_dataset:variant, buffer_size:int64 -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=slack_period:int,default=0; attr=legacy_autotune:bool,default=true; attr=buffer_size_min:int,default=0; attr=metadata:string,default="">
  2023-01-12 09:34:37.724431: I tensorflow/core/framework/op.cc:132] Op<name=Prelinearize; signature=input:dtype -> output:variant; attr=dtype:type; attr=shape:shape,default=[]; attr=layout:list(int),default=[]>
  2023-01-12 09:34:37.724444: I tensorflow/core/framework/op.cc:132] Op<name=PrelinearizeTuple; signature=inputs: -> output:variant; attr=dtypes:list(type),min=1; attr=shapes:list(shape); attr=layouts:list(int),default=[]>
  2023-01-12 09:34:37.724456: I tensorflow/core/framework/op.cc:132] Op<name=PreventGradient; signature=input:T -> output:T; attr=T:type; attr=message:string,default="">
  2023-01-12 09:34:37.724493: I tensorflow/core/framework/op.cc:132] Op<name=Print; signature=input:T, data: -> output:T; attr=T:type; attr=U:list(type),min=0; attr=message:string,default=""; attr=first_n:int,default=-1; attr=summarize:int,default=3; is_stateful=true>
  2023-01-12 09:34:37.724532: I tensorflow/core/framework/op.cc:132] Op<name=PrintV2; signature=input:string -> ; attr=output_stream:string,default="stderr"; attr=end:string,default="\n"; is_stateful=true>
  2023-01-12 09:34:37.724711: I tensorflow/core/framework/op.cc:132] Op<name=PriorityQueue; signature= -> handle:Ref(string); attr=component_types:list(type),default=[],min=0; attr=shapes:list(shape),min=0; attr=capacity:int,default=-1; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.724874: I tensorflow/core/framework/op.cc:132] Op<name=PriorityQueueV2; signature= -> handle:resource; attr=component_types:list(type),default=[],min=0; attr=shapes:list(shape),min=0; attr=capacity:int,default=-1; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.724911: I tensorflow/core/framework/op.cc:132] Op<name=PrivateThreadPoolDataset; signature=input_dataset:variant, num_threads:int64 -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1>
  2023-01-12 09:34:37.724978: I tensorflow/core/framework/op.cc:132] Op<name=Prod; signature=input:T, reduction_indices:Tidx -> output:T; attr=keep_dims:bool,default=false; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.725010: I tensorflow/core/framework/op.cc:132] Op<name=PyFunc; signature=input: -> output:; attr=token:string; attr=Tin:list(type),min=0; attr=Tout:list(type),min=0; is_stateful=true>
  2023-01-12 09:34:37.725032: I tensorflow/core/framework/op.cc:132] Op<name=PyFuncStateless; signature=input: -> output:; attr=token:string; attr=Tin:list(type),min=0; attr=Tout:list(type),min=0>
  2023-01-12 09:34:37.725062: I tensorflow/core/framework/op.cc:132] Op<name=Qr; signature=input:T -> q:T, r:T; attr=full_matrices:bool,default=false; attr=T:type,allowed=[DT_DOUBLE, DT_FLOAT, DT_HALF, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.725113: I tensorflow/core/framework/op.cc:132] Op<name=QuantizeAndDequantize; signature=input:T -> output:T; attr=signed_input:bool,default=true; attr=num_bits:int,default=8; attr=range_given:bool,default=false; attr=input_min:float,default=0; attr=input_max:float,default=0; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.725197: I tensorflow/core/framework/op.cc:132] Op<name=QuantizeAndDequantizeV2; signature=input:T, input_min:T, input_max:T -> output:T; attr=signed_input:bool,default=true; attr=num_bits:int,default=8; attr=range_given:bool,default=false; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=round_mode:string,default="HALF_TO_EVEN",allowed=["HALF_TO_EVEN", "HALF_UP"]; attr=narrow_range:bool,default=false; attr=axis:int,default=-1>
  2023-01-12 09:34:37.725230: I tensorflow/core/framework/op.cc:132] Op<name=QuantizeAndDequantizeV3; signature=input:T, input_min:T, input_max:T, num_bits:int32 -> output:T; attr=signed_input:bool,default=true; attr=range_given:bool,default=true; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=narrow_range:bool,default=false; attr=axis:int,default=-1>
  2023-01-12 09:34:37.725263: I tensorflow/core/framework/op.cc:132] Op<name=QuantizeAndDequantizeV4; signature=input:T, input_min:T, input_max:T -> output:T; attr=signed_input:bool,default=true; attr=num_bits:int,default=8; attr=range_given:bool,default=false; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=round_mode:string,default="HALF_TO_EVEN",allowed=["HALF_TO_EVEN", "HALF_UP"]; attr=narrow_range:bool,default=false; attr=axis:int,default=-1>
  2023-01-12 09:34:37.725334: I tensorflow/core/framework/op.cc:132] Op<name=QuantizeAndDequantizeV4Grad; signature=gradients:T, input:T, input_min:T, input_max:T -> input_backprop:T, input_min_backprop:T, input_max_backprop:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=axis:int,default=-1>
  2023-01-12 09:34:37.725402: I tensorflow/core/framework/op.cc:132] Op<name=QuantizeDownAndShrinkRange; signature=input:Tinput, input_min:float, input_max:float -> output:out_type, output_min:float, output_max:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=out_type:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]>
  2023-01-12 09:34:37.725518: I tensorflow/core/framework/op.cc:132] Op<name=QuantizeV2; signature=input:float, min_range:float, max_range:float -> output:T, output_min:float, output_max:float; attr=T:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=mode:string,default="MIN_COMBINED",allowed=["MIN_COMBINED", "MIN_FIRST", "SCALED"]; attr=round_mode:string,default="HALF_AWAY_FROM_ZERO",allowed=["HALF_AWAY_FROM_ZERO", "HALF_TO_EVEN"]; attr=narrow_range:bool,default=false; attr=axis:int,default=-1; attr=ensure_minimum_range:float,default=0.01>
  2023-01-12 09:34:37.725595: I tensorflow/core/framework/op.cc:132] Op<name=QuantizedAdd; signature=x:T1, y:T2, min_x:float, max_x:float, min_y:float, max_y:float -> z:Toutput, min_z:float, max_z:float; attr=T1:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=T2:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Toutput:type,default=DT_QINT32,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]>
  2023-01-12 09:34:37.725694: I tensorflow/core/framework/op.cc:132] Op<name=QuantizedAvgPool; signature=input:T, min_input:float, max_input:float -> output:T, min_output:float, max_output:float; attr=T:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=ksize:list(int); attr=strides:list(int); attr=padding:string,allowed=["SAME", "VALID"]>
  2023-01-12 09:34:37.725789: I tensorflow/core/framework/op.cc:132] Op<name=QuantizedBatchNormWithGlobalNormalization; signature=t:Tinput, t_min:float, t_max:float, m:Tinput, m_min:float, m_max:float, v:Tinput, v_min:float, v_max:float, beta:Tinput, beta_min:float, beta_max:float, gamma:Tinput, gamma_min:float, gamma_max:float -> result:out_type, result_min:float, result_max:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=out_type:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=variance_epsilon:float; attr=scale_after_normalization:bool>
  2023-01-12 09:34:37.725863: I tensorflow/core/framework/op.cc:132] Op<name=QuantizedBiasAdd; signature=input:T1, bias:T2, min_input:float, max_input:float, min_bias:float, max_bias:float -> output:out_type, min_out:float, max_out:float; attr=T1:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=T2:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=out_type:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]>
  2023-01-12 09:34:37.725918: I tensorflow/core/framework/op.cc:132] Op<name=QuantizedConcat; signature=concat_dim:int32, values:N*T, input_mins:N*float, input_maxes:N*float -> output:T, output_min:float, output_max:float; attr=N:int,min=2; attr=T:type>
  2023-01-12 09:34:37.726027: I tensorflow/core/framework/op.cc:132] Op<name=QuantizedConcatV2; signature=values:N*T, axis:Tidx, input_mins:N*float, input_maxes:N*float -> output:T, output_min:float, output_max:float; attr=N:int,min=2; attr=T:type; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.726113: I tensorflow/core/framework/op.cc:132] Op<name=QuantizedConv2D; signature=input:Tinput, filter:Tfilter, min_input:float, max_input:float, min_filter:float, max_filter:float -> output:out_type, min_output:float, max_output:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tfilter:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=out_type:type,default=DT_QINT32,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=strides:list(int); attr=padding:string,allowed=["SAME", "VALID"]; attr=dilations:list(int),default=[1, 1, 1, 1]>
  2023-01-12 09:34:37.726194: I tensorflow/core/framework/op.cc:132] Op<name=QuantizedConv2DAndRelu; signature=input:Tinput, filter:Tfilter, min_input:float, max_input:float, min_filter:float, max_filter:float -> output:out_type, min_output:float, max_output:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tfilter:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=out_type:type,default=DT_QINT32,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=strides:list(int); attr=padding:string,allowed=["SAME", "VALID"]; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=padding_list:list(int),default=[]>
  2023-01-12 09:34:37.726293: I tensorflow/core/framework/op.cc:132] Op<name=QuantizedConv2DAndReluAndRequantize; signature=input:Tinput, filter:Tfilter, min_input:float, max_input:float, min_filter:float, max_filter:float, min_freezed_output:float, max_freezed_output:float -> output:out_type, min_output:float, max_output:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tfilter:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=out_type:type,default=DT_QUINT8,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=strides:list(int); attr=padding:string,allowed=["SAME", "VALID"]; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=padding_list:list(int),default=[]>
  2023-01-12 09:34:37.726521: I tensorflow/core/framework/op.cc:132] Op<name=QuantizedConv2DAndRequantize; signature=input:Tinput, filter:Tfilter, min_input:float, max_input:float, min_filter:float, max_filter:float, min_freezed_output:float, max_freezed_output:float -> output:out_type, min_output:float, max_output:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tfilter:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=out_type:type,default=DT_QINT8,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=strides:list(int); attr=padding:string,allowed=["SAME", "VALID"]; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=padding_list:list(int),default=[]>
  2023-01-12 09:34:37.726673: I tensorflow/core/framework/op.cc:132] Op<name=QuantizedConv2DPerChannel; signature=input:Tinput, filter:Tfilter, min_input:float, max_input:float, min_filter:float, max_filter:float -> output:out_type, min_output:float, max_output:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tfilter:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=out_type:type,default=DT_QINT32,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=strides:list(int); attr=padding:string,allowed=["SAME", "VALID"]; attr=dilations:list(int),default=[1, 1, 1, 1]>
  2023-01-12 09:34:37.726751: I tensorflow/core/framework/op.cc:132] Op<name=QuantizedConv2DWithBias; signature=input:Tinput, filter:Tfilter, bias:float, min_input:float, max_input:float, min_filter:float, max_filter:float -> output:out_type, min_output:float, max_output:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tfilter:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=out_type:type,default=DT_QINT32,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=strides:list(int); attr=padding:string,allowed=["SAME", "VALID"]; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=padding_list:list(int),default=[]>
  2023-01-12 09:34:37.726886: I tensorflow/core/framework/op.cc:132] Op<name=QuantizedConv2DWithBiasAndRelu; signature=input:Tinput, filter:Tfilter, bias:float, min_input:float, max_input:float, min_filter:float, max_filter:float -> output:out_type, min_output:float, max_output:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tfilter:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=out_type:type,default=DT_QINT32,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=strides:list(int); attr=padding:string,allowed=["SAME", "VALID"]; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=padding_list:list(int),default=[]>
  2023-01-12 09:34:37.727056: I tensorflow/core/framework/op.cc:132] Op<name=QuantizedConv2DWithBiasAndReluAndRequantize; signature=input:Tinput, filter:Tfilter, bias:Tbias, min_input:float, max_input:float, min_filter:float, max_filter:float, min_freezed_output:float, max_freezed_output:float -> output:out_type, min_output:float, max_output:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tfilter:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tbias:type,allowed=[DT_FLOAT, DT_QINT32]; attr=out_type:type,default=DT_QUINT8,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=strides:list(int); attr=padding:string,allowed=["SAME", "VALID"]; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=padding_list:list(int),default=[]>
  2023-01-12 09:34:37.767436: I tensorflow/core/framework/op.cc:132] Op<name=QuantizedConv2DWithBiasAndRequantize; signature=input:Tinput, filter:Tfilter, bias:Tbias, min_input:float, max_input:float, min_filter:float, max_filter:float, min_freezed_output:float, max_freezed_output:float -> output:out_type, min_output:float, max_output:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tfilter:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tbias:type,allowed=[DT_FLOAT, DT_QINT32]; attr=out_type:type,default=DT_QINT8,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=strides:list(int); attr=padding:string,allowed=["SAME", "VALID"]; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=padding_list:list(int),default=[]>
  2023-01-12 09:34:37.767554: I tensorflow/core/framework/op.cc:132] Op<name=QuantizedConv2DWithBiasSignedSumAndReluAndRequantize; signature=input:Tinput, filter:Tfilter, bias:Tbias, min_input:float, max_input:float, min_filter:float, max_filter:float, min_freezed_output:float, max_freezed_output:float, summand:Tsummand, min_summand:float, max_summand:float -> output:out_type, min_output:float, max_output:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tfilter:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tbias:type,allowed=[DT_FLOAT, DT_QINT32]; attr=Tsummand:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=out_type:type,default=DT_QUINT8,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=strides:list(int); attr=padding:string,allowed=["SAME", "VALID"]; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=padding_list:list(int),default=[]>
  2023-01-12 09:34:37.767715: I tensorflow/core/framework/op.cc:132] Op<name=QuantizedConv2DWithBiasSumAndRelu; signature=input:Tinput, filter:Tfilter, bias:float, min_input:float, max_input:float, min_filter:float, max_filter:float, summand:float -> output:out_type, min_output:float, max_output:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tfilter:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=out_type:type,default=DT_QINT32,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=strides:list(int); attr=padding:string,allowed=["SAME", "VALID"]; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=padding_list:list(int),default=[]>
  2023-01-12 09:34:37.767823: I tensorflow/core/framework/op.cc:132] Op<name=QuantizedConv2DWithBiasSumAndReluAndRequantize; signature=input:Tinput, filter:Tfilter, bias:Tbias, min_input:float, max_input:float, min_filter:float, max_filter:float, min_freezed_output:float, max_freezed_output:float, summand:Tsummand, min_summand:float, max_summand:float -> output:out_type, min_output:float, max_output:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tfilter:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tbias:type,allowed=[DT_FLOAT, DT_QINT32]; attr=Tsummand:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=out_type:type,default=DT_QUINT8,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=strides:list(int); attr=padding:string,allowed=["SAME", "VALID"]; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=padding_list:list(int),default=[]>
  2023-01-12 09:34:37.768021: I tensorflow/core/framework/op.cc:132] Op<name=QuantizedDepthwiseConv2D; signature=input:Tinput, filter:Tfilter, min_input:float, max_input:float, min_filter:float, max_filter:float -> output:out_type, min_output:float, max_output:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tfilter:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=out_type:type,default=DT_QINT32,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=strides:list(int); attr=padding:string,allowed=["SAME", "VALID"]; attr=dilations:list(int),default=[1, 1, 1, 1]>
  2023-01-12 09:34:37.768075: I tensorflow/core/framework/op.cc:132] Op<name=QuantizedDepthwiseConv2DWithBias; signature=input:Tinput, filter:Tfilter, bias:float, min_input:float, max_input:float, min_filter:float, max_filter:float -> output:out_type, min_output:float, max_output:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tfilter:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=out_type:type,default=DT_QINT32,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=strides:list(int); attr=padding:string,allowed=["SAME", "VALID"]; attr=dilations:list(int),default=[1, 1, 1, 1]>
  2023-01-12 09:34:37.768114: I tensorflow/core/framework/op.cc:132] Op<name=QuantizedDepthwiseConv2DWithBiasAndRelu; signature=input:Tinput, filter:Tfilter, bias:float, min_input:float, max_input:float, min_filter:float, max_filter:float -> output:out_type, min_output:float, max_output:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tfilter:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=out_type:type,default=DT_QINT32,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=strides:list(int); attr=padding:string,allowed=["SAME", "VALID"]; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=padding_list:list(int),default=[]>
  2023-01-12 09:34:37.768157: I tensorflow/core/framework/op.cc:132] Op<name=QuantizedDepthwiseConv2DWithBiasAndReluAndRequantize; signature=input:Tinput, filter:Tfilter, bias:Tbias, min_input:float, max_input:float, min_filter:float, max_filter:float, min_freezed_output:float, max_freezed_output:float -> output:out_type, min_output:float, max_output:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tfilter:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tbias:type,allowed=[DT_FLOAT, DT_QINT32]; attr=out_type:type,default=DT_QUINT8,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=strides:list(int); attr=padding:string,allowed=["SAME", "VALID"]; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=padding_list:list(int),default=[]>
  2023-01-12 09:34:37.768210: I tensorflow/core/framework/op.cc:132] Op<name=QuantizedInstanceNorm; signature=x:T, x_min:float, x_max:float -> y:T, y_min:float, y_max:float; attr=T:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=output_range_given:bool,default=false; attr=given_y_min:float,default=0; attr=given_y_max:float,default=0; attr=variance_epsilon:float,default=1e-05; attr=min_separation:float,default=0.001>
  2023-01-12 09:34:37.768272: I tensorflow/core/framework/op.cc:132] Op<name=QuantizedMatMul; signature=a:T1, b:T2, min_a:float, max_a:float, min_b:float, max_b:float -> out:Toutput, min_out:float, max_out:float; attr=T1:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=T2:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Toutput:type,default=DT_QINT32,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=transpose_a:bool,default=false; attr=transpose_b:bool,default=false; attr=Tactivation:type,default=DT_QUINT8,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]>
  2023-01-12 09:34:37.768353: I tensorflow/core/framework/op.cc:132] Op<name=QuantizedMatMulWithBias; signature=a:T1, b:T2, bias:Tbias, min_a:float, max_a:float, min_b:float, max_b:float -> out:Toutput, min_out:float, max_out:float; attr=T1:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=T2:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tbias:type,allowed=[DT_FLOAT, DT_QINT32]; attr=Toutput:type,default=DT_QINT32,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=transpose_a:bool,default=false; attr=transpose_b:bool,default=false; attr=input_quant_mode:string,default="MIN_FIRST",allowed=["MIN_FIRST", "SCALED"]>
  2023-01-12 09:34:37.768521: I tensorflow/core/framework/op.cc:132] Op<name=QuantizedMatMulWithBiasAndDequantize; signature=a:T1, b:T2, bias:Tbias, min_a:float, max_a:float, min_b:float, max_b:float, min_freezed_output:float, max_freezed_output:float -> out:Toutput; attr=T1:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=T2:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tbias:type,allowed=[DT_FLOAT, DT_QINT32]; attr=Toutput:type,allowed=[DT_FLOAT]; attr=transpose_a:bool,default=false; attr=transpose_b:bool,default=false; attr=input_quant_mode:string,default="MIN_FIRST",allowed=["MIN_FIRST", "SCALED"]>
  2023-01-12 09:34:37.768653: I tensorflow/core/framework/op.cc:132] Op<name=QuantizedMatMulWithBiasAndRelu; signature=a:T1, b:T2, bias:float, min_a:float, max_a:float, min_b:float, max_b:float -> out:Toutput, min_out:float, max_out:float; attr=T1:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=T2:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Toutput:type,default=DT_QINT32,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=transpose_a:bool,default=false; attr=transpose_b:bool,default=false; attr=input_quant_mode:string,default="MIN_FIRST",allowed=["MIN_FIRST", "SCALED"]>
  2023-01-12 09:34:37.768844: I tensorflow/core/framework/op.cc:132] Op<name=QuantizedMatMulWithBiasAndReluAndRequantize; signature=a:T1, b:T2, bias:Tbias, min_a:float, max_a:float, min_b:float, max_b:float, min_freezed_output:float, max_freezed_output:float -> out:Toutput, min_out:float, max_out:float; attr=T1:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=T2:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tbias:type,allowed=[DT_FLOAT, DT_QINT32]; attr=Toutput:type,default=DT_QUINT8,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=transpose_a:bool,default=false; attr=transpose_b:bool,default=false; attr=input_quant_mode:string,default="MIN_FIRST",allowed=["MIN_FIRST", "SCALED"]>
  2023-01-12 09:34:37.768965: I tensorflow/core/framework/op.cc:132] Op<name=QuantizedMatMulWithBiasAndRequantize; signature=a:T1, b:T2, bias:Tbias, min_a:float, max_a:float, min_b:float, max_b:float, min_freezed_output:float, max_freezed_output:float -> out:Toutput, min_out:float, max_out:float; attr=T1:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=T2:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tbias:type,allowed=[DT_FLOAT, DT_QINT32]; attr=Toutput:type,default=DT_QUINT8,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=transpose_a:bool,default=false; attr=transpose_b:bool,default=false; attr=input_quant_mode:string,default="MIN_FIRST",allowed=["MIN_FIRST", "SCALED"]>
  2023-01-12 09:34:37.769124: I tensorflow/core/framework/op.cc:132] Op<name=QuantizedMaxPool; signature=input:T, min_input:float, max_input:float -> output:T, min_output:float, max_output:float; attr=T:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=ksize:list(int); attr=strides:list(int); attr=padding:string,allowed=["SAME", "VALID"]>
  2023-01-12 09:34:37.769221: I tensorflow/core/framework/op.cc:132] Op<name=QuantizedMul; signature=x:T1, y:T2, min_x:float, max_x:float, min_y:float, max_y:float -> z:Toutput, min_z:float, max_z:float; attr=T1:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=T2:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Toutput:type,default=DT_QINT32,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]>
  2023-01-12 09:34:37.769294: I tensorflow/core/framework/op.cc:132] Op<name=QuantizedRelu; signature=features:Tinput, min_features:float, max_features:float -> activations:out_type, min_activations:float, max_activations:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=out_type:type,default=DT_QUINT8,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]>
  2023-01-12 09:34:37.769402: I tensorflow/core/framework/op.cc:132] Op<name=QuantizedRelu6; signature=features:Tinput, min_features:float, max_features:float -> activations:out_type, min_activations:float, max_activations:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=out_type:type,default=DT_QUINT8,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]>
  2023-01-12 09:34:37.769524: I tensorflow/core/framework/op.cc:132] Op<name=QuantizedReluX; signature=features:Tinput, max_value:float, min_features:float, max_features:float -> activations:out_type, min_activations:float, max_activations:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=out_type:type,default=DT_QUINT8,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]>
  2023-01-12 09:34:37.769579: I tensorflow/core/framework/op.cc:132] Op<name=QuantizedReshape; signature=tensor:T, shape:Tshape, input_min:float, input_max:float -> output:T, output_min:float, output_max:float; attr=T:type; attr=Tshape:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.769684: I tensorflow/core/framework/op.cc:132] Op<name=QuantizedResizeBilinear; signature=images:T, size:int32, min:float, max:float -> resized_images:T, out_min:float, out_max:float; attr=T:type,allowed=[DT_QUINT8, DT_QINT32, DT_FLOAT]; attr=align_corners:bool,default=false; attr=half_pixel_centers:bool,default=false>
  2023-01-12 09:34:37.769705: I tensorflow/core/framework/op.cc:132] Op<name=QueueClose; signature=handle:Ref(string) -> ; attr=cancel_pending_enqueues:bool,default=false>
  2023-01-12 09:34:37.769716: I tensorflow/core/framework/op.cc:132] Op<name=QueueCloseV2; signature=handle:resource -> ; attr=cancel_pending_enqueues:bool,default=false; is_stateful=true>
  2023-01-12 09:34:37.769729: I tensorflow/core/framework/op.cc:132] Op<name=QueueDequeue; signature=handle:Ref(string) -> components:; attr=component_types:list(type),min=1; attr=timeout_ms:int,default=-1>
  2023-01-12 09:34:37.769764: I tensorflow/core/framework/op.cc:132] Op<name=QueueDequeueMany; signature=handle:Ref(string), n:int32 -> components:; attr=component_types:list(type),min=1; attr=timeout_ms:int,default=-1>
  2023-01-12 09:34:37.769818: I tensorflow/core/framework/op.cc:132] Op<name=QueueDequeueManyV2; signature=handle:resource, n:int32 -> components:; attr=component_types:list(type),min=1; attr=timeout_ms:int,default=-1; is_stateful=true>
  2023-01-12 09:34:37.769869: I tensorflow/core/framework/op.cc:132] Op<name=QueueDequeueUpTo; signature=handle:Ref(string), n:int32 -> components:; attr=component_types:list(type),min=1; attr=timeout_ms:int,default=-1>
  2023-01-12 09:34:37.770059: I tensorflow/core/framework/op.cc:132] Op<name=QueueDequeueUpToV2; signature=handle:resource, n:int32 -> components:; attr=component_types:list(type),min=1; attr=timeout_ms:int,default=-1; is_stateful=true>
  2023-01-12 09:34:37.770226: I tensorflow/core/framework/op.cc:132] Op<name=QueueDequeueV2; signature=handle:resource -> components:; attr=component_types:list(type),min=1; attr=timeout_ms:int,default=-1; is_stateful=true>
  2023-01-12 09:34:37.770301: I tensorflow/core/framework/op.cc:132] Op<name=QueueEnqueue; signature=handle:Ref(string), components: -> ; attr=Tcomponents:list(type),min=1; attr=timeout_ms:int,default=-1>
  2023-01-12 09:34:37.770399: I tensorflow/core/framework/op.cc:132] Op<name=QueueEnqueueMany; signature=handle:Ref(string), components: -> ; attr=Tcomponents:list(type),min=1; attr=timeout_ms:int,default=-1>
  2023-01-12 09:34:37.770690: I tensorflow/core/framework/op.cc:132] Op<name=QueueEnqueueManyV2; signature=handle:resource, components: -> ; attr=Tcomponents:list(type),min=1; attr=timeout_ms:int,default=-1; is_stateful=true>
  2023-01-12 09:34:37.770910: I tensorflow/core/framework/op.cc:132] Op<name=QueueEnqueueV2; signature=handle:resource, components: -> ; attr=Tcomponents:list(type),min=1; attr=timeout_ms:int,default=-1; is_stateful=true>
  2023-01-12 09:34:37.771110: I tensorflow/core/framework/op.cc:132] Op<name=QueueIsClosed; signature=handle:Ref(string) -> is_closed:bool>
  2023-01-12 09:34:37.771207: I tensorflow/core/framework/op.cc:132] Op<name=QueueIsClosedV2; signature=handle:resource -> is_closed:bool; is_stateful=true>
  2023-01-12 09:34:37.771254: I tensorflow/core/framework/op.cc:132] Op<name=QueueSize; signature=handle:Ref(string) -> size:int32>
  2023-01-12 09:34:37.771302: I tensorflow/core/framework/op.cc:132] Op<name=QueueSizeV2; signature=handle:resource -> size:int32; is_stateful=true>
  2023-01-12 09:34:37.771402: I tensorflow/core/framework/op.cc:132] Op<name=RFFT; signature=input:Treal, fft_length:int32 -> output:Tcomplex; attr=Treal:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_DOUBLE]; attr=Tcomplex:type,default=DT_COMPLEX64,allowed=[DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.771464: I tensorflow/core/framework/op.cc:132] Op<name=RFFT2D; signature=input:Treal, fft_length:int32 -> output:Tcomplex; attr=Treal:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_DOUBLE]; attr=Tcomplex:type,default=DT_COMPLEX64,allowed=[DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.771499: I tensorflow/core/framework/op.cc:132] Op<name=RFFT3D; signature=input:Treal, fft_length:int32 -> output:Tcomplex; attr=Treal:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_DOUBLE]; attr=Tcomplex:type,default=DT_COMPLEX64,allowed=[DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.771522: I tensorflow/core/framework/op.cc:132] Op<name=RGBToHSV; signature=images:T -> output:T; attr=T:type,default=DT_FLOAT,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.771545: I tensorflow/core/framework/op.cc:132] Op<name=RaggedBincount; signature=splits:int64, values:Tidx, size:Tidx, weights:T -> output:T; attr=Tidx:type,allowed=[DT_INT32, DT_INT64]; attr=T:type,allowed=[DT_INT32, DT_INT64, DT_FLOAT, DT_DOUBLE]; attr=binary_output:bool,default=false>
  2023-01-12 09:34:37.771577: I tensorflow/core/framework/op.cc:132] Op<name=RaggedCountSparseOutput; signature=splits:int64, values:T, weights:output_type -> output_indices:int64, output_values:output_type, output_dense_shape:int64; attr=T:type,allowed=[DT_INT32, DT_INT64]; attr=minlength:int,default=-1,min=-1; attr=maxlength:int,default=-1,min=-1; attr=binary_output:bool; attr=output_type:type,allowed=[DT_INT32, DT_INT64, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.771651: I tensorflow/core/framework/op.cc:132] Op<name=RaggedCross; signature=ragged_values:, ragged_row_splits:, sparse_indices:Nsparse*int64, sparse_values:, sparse_shape:Nsparse*int64, dense_inputs: -> output_values:out_values_type, output_row_splits:out_row_splits_type; attr=Nsparse:int,min=0; attr=input_order:string; attr=hashed_output:bool; attr=num_buckets:int,min=0; attr=hash_key:int; attr=ragged_values_types:list(type),min=0,allowed=[DT_INT64, DT_STRING]; attr=ragged_splits_types:list(type),min=0,allowed=[DT_INT32, DT_INT64]; attr=sparse_values_types:list(type),min=0,allowed=[DT_INT64, DT_STRING]; attr=dense_types:list(type),min=0,allowed=[DT_INT64, DT_STRING]; attr=out_values_type:type,allowed=[DT_INT64, DT_STRING]; attr=out_row_splits_type:type,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.771750: I tensorflow/core/framework/op.cc:132] Op<name=RaggedGather; signature=params_nested_splits:PARAMS_RAGGED_RANK*Tsplits, params_dense_values:Tvalues, indices:Tindices -> output_nested_splits:OUTPUT_RAGGED_RANK*Tsplits, output_dense_values:Tvalues; attr=Tvalues:type; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=Tsplits:type,default=DT_INT64,allowed=[DT_INT32, DT_INT64]; attr=PARAMS_RAGGED_RANK:int,min=1; attr=OUTPUT_RAGGED_RANK:int,min=0>
  2023-01-12 09:34:37.771846: I tensorflow/core/framework/op.cc:132] Op<name=RaggedRange; signature=starts:T, limits:T, deltas:T -> rt_nested_splits:Tsplits, rt_dense_values:T; attr=T:type,default=DT_INT32,allowed=[DT_BFLOAT16, DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64]; attr=Tsplits:type,default=DT_INT64,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.771875: I tensorflow/core/framework/op.cc:132] Op<name=RaggedTensorFromVariant; signature=encoded_ragged:variant -> output_nested_splits:output_ragged_rank*Tsplits, output_dense_values:Tvalues; attr=input_ragged_rank:int,min=-1; attr=output_ragged_rank:int,min=0; attr=Tvalues:type; attr=Tsplits:type,default=DT_INT64,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.771895: I tensorflow/core/framework/op.cc:132] Op<name=RaggedTensorToSparse; signature=rt_nested_splits:RAGGED_RANK*Tsplits, rt_dense_values:T -> sparse_indices:int64, sparse_values:T, sparse_dense_shape:int64; attr=RAGGED_RANK:int,min=1; attr=T:type; attr=Tsplits:type,default=DT_INT64,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.772047: I tensorflow/core/framework/op.cc:132] Op<name=RaggedTensorToTensor; signature=shape:Tshape, values:T, default_value:T, row_partition_tensors:num_row_partition_tensors*Tindex -> result:T; attr=T:type; attr=Tindex:type,allowed=[DT_INT64, DT_INT32]; attr=Tshape:type,allowed=[DT_INT64, DT_INT32]; attr=num_row_partition_tensors:int,min=1; attr=row_partition_types:list(string)>
  2023-01-12 09:34:37.772110: I tensorflow/core/framework/op.cc:132] Op<name=RaggedTensorToVariant; signature=rt_nested_splits:RAGGED_RANK*Tsplits, rt_dense_values:Tvalues -> encoded_ragged:variant; attr=RAGGED_RANK:int,min=0; attr=Tvalues:type; attr=Tsplits:type,default=DT_INT64,allowed=[DT_INT32, DT_INT64]; attr=batched_input:bool>
  2023-01-12 09:34:37.772149: I tensorflow/core/framework/op.cc:132] Op<name=RaggedTensorToVariantGradient; signature=encoded_ragged_grad:variant, row_splits:Tsplits, dense_values_shape:int32 -> dense_values_grad:Tvalues; attr=Tvalues:type; attr=Tsplits:type,default=DT_INT64,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.772188: I tensorflow/core/framework/op.cc:132] Op<name=RandomCrop; signature=image:T, size:int64 -> output:T; attr=T:type,allowed=[DT_UINT8, DT_INT8, DT_INT16, DT_INT32, DT_INT64, DT_FLOAT, DT_DOUBLE]; attr=seed:int,default=0; attr=seed2:int,default=0; is_stateful=true>
  2023-01-12 09:34:37.772220: I tensorflow/core/framework/op.cc:132] Op<name=RandomDataset; signature=seed:int64, seed2:int64 -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=metadata:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.772428: I tensorflow/core/framework/op.cc:132] Op<name=RandomGamma; signature=shape:S, alpha:T -> output:T; attr=seed:int,default=0; attr=seed2:int,default=0; attr=S:type,allowed=[DT_INT32, DT_INT64]; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE]; is_stateful=true>
  2023-01-12 09:34:37.772465: I tensorflow/core/framework/op.cc:132] Op<name=RandomGammaGrad; signature=alpha:T, sample:T -> output:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.772494: I tensorflow/core/framework/op.cc:132] Op<name=RandomIndexShuffle; signature=index:dtype, seed:Tseed, max_index:dtype -> output:dtype; attr=rounds:int,default=4; attr=dtype:type,allowed=[DT_INT32, DT_UINT32, DT_INT64, DT_UINT64]; attr=Tseed:type,allowed=[DT_INT32, DT_UINT32, DT_INT64, DT_UINT64]>
  2023-01-12 09:34:37.774424: I tensorflow/core/framework/op.cc:132] Op<name=RandomPoisson; signature=shape:S, rate:dtype -> output:dtype; attr=seed:int,default=0; attr=seed2:int,default=0; attr=S:type,allowed=[DT_INT32, DT_INT64]; attr=dtype:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE]; is_stateful=true>
  2023-01-12 09:34:37.774519: I tensorflow/core/framework/op.cc:132] Op<name=RandomPoissonV2; signature=shape:S, rate:R -> output:dtype; attr=seed:int,default=0; attr=seed2:int,default=0; attr=S:type,allowed=[DT_INT32, DT_INT64]; attr=R:type,default=DT_DOUBLE,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64]; attr=dtype:type,default=DT_INT64,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64]; is_stateful=true>
  2023-01-12 09:34:37.774604: I tensorflow/core/framework/op.cc:132] Op<name=RandomShuffle; signature=value:T -> output:T; attr=seed:int,default=0; attr=seed2:int,default=0; attr=T:type; is_stateful=true>
  2023-01-12 09:34:37.774766: I tensorflow/core/framework/op.cc:132] Op<name=RandomShuffleQueue; signature= -> handle:Ref(string); attr=component_types:list(type),min=1; attr=shapes:list(shape),default=[],min=0; attr=capacity:int,default=-1; attr=min_after_dequeue:int,default=0; attr=seed:int,default=0; attr=seed2:int,default=0; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.774850: I tensorflow/core/framework/op.cc:132] Op<name=RandomShuffleQueueV2; signature= -> handle:resource; attr=component_types:list(type),min=1; attr=shapes:list(shape),default=[],min=0; attr=capacity:int,default=-1; attr=min_after_dequeue:int,default=0; attr=seed:int,default=0; attr=seed2:int,default=0; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.774954: I tensorflow/core/framework/op.cc:132] Op<name=RandomStandardNormal; signature=shape:T -> output:dtype; attr=seed:int,default=0; attr=seed2:int,default=0; attr=dtype:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]; attr=T:type,allowed=[DT_INT32, DT_INT64]; is_stateful=true>
  2023-01-12 09:34:37.775046: I tensorflow/core/framework/op.cc:132] Op<name=RandomUniform; signature=shape:T -> output:dtype; attr=seed:int,default=0; attr=seed2:int,default=0; attr=dtype:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]; attr=T:type,allowed=[DT_INT32, DT_INT64]; is_stateful=true>
  2023-01-12 09:34:37.775106: I tensorflow/core/framework/op.cc:132] Op<name=RandomUniformInt; signature=shape:T, minval:Tout, maxval:Tout -> output:Tout; attr=seed:int,default=0; attr=seed2:int,default=0; attr=Tout:type,allowed=[DT_INT32, DT_INT64]; attr=T:type,allowed=[DT_INT32, DT_INT64]; is_stateful=true>
  2023-01-12 09:34:37.775449: I tensorflow/core/framework/op.cc:132] Op<name=Range; signature=start:Tidx, limit:Tidx, delta:Tidx -> output:Tidx; attr=Tidx:type,default=DT_INT32,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT8, DT_INT16, DT_INT32, DT_INT64, DT_UINT16, DT_UINT32]>
  2023-01-12 09:34:37.775530: I tensorflow/core/framework/op.cc:132] Op<name=RangeDataset; signature=start:int64, stop:int64, step:int64 -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=metadata:string,default=""; attr=replicate_on_split:bool,default=false; is_stateful=true>
  2023-01-12 09:34:37.775669: I tensorflow/core/framework/op.cc:132] Op<name=Rank; signature=input:T -> output:int32; attr=T:type>
  2023-01-12 09:34:37.775760: I tensorflow/core/framework/op.cc:132] Op<name=ReadFile; signature=filename:string -> contents:string>
  2023-01-12 09:34:37.775847: I tensorflow/core/framework/op.cc:132] Op<name=ReadVariableOp; signature=resource:resource -> value:dtype; attr=dtype:type; is_stateful=true>
  2023-01-12 09:34:37.775963: I tensorflow/core/framework/op.cc:132] Op<name=ReadVariableXlaSplitND; signature=resource:resource -> outputs:N*T; attr=T:type; attr=N:int,min=1; attr=num_splits:list(int); attr=paddings:list(int),default=[]; is_stateful=true>
  2023-01-12 09:34:37.776024: I tensorflow/core/framework/op.cc:132] Op<name=ReaderNumRecordsProduced; signature=reader_handle:Ref(string) -> records_produced:int64>
  2023-01-12 09:34:37.776083: I tensorflow/core/framework/op.cc:132] Op<name=ReaderNumRecordsProducedV2; signature=reader_handle:resource -> records_produced:int64; is_stateful=true>
  2023-01-12 09:34:37.776139: I tensorflow/core/framework/op.cc:132] Op<name=ReaderNumWorkUnitsCompleted; signature=reader_handle:Ref(string) -> units_completed:int64>
  2023-01-12 09:34:37.776194: I tensorflow/core/framework/op.cc:132] Op<name=ReaderNumWorkUnitsCompletedV2; signature=reader_handle:resource -> units_completed:int64; is_stateful=true>
  2023-01-12 09:34:37.776249: I tensorflow/core/framework/op.cc:132] Op<name=ReaderRead; signature=reader_handle:Ref(string), queue_handle:Ref(string) -> key:string, value:string>
  2023-01-12 09:34:37.776387: I tensorflow/core/framework/op.cc:132] Op<name=ReaderReadUpTo; signature=reader_handle:Ref(string), queue_handle:Ref(string), num_records:int64 -> keys:string, values:string>
  2023-01-12 09:34:37.776622: I tensorflow/core/framework/op.cc:132] Op<name=ReaderReadUpToV2; signature=reader_handle:resource, queue_handle:resource, num_records:int64 -> keys:string, values:string; is_stateful=true>
  2023-01-12 09:34:37.776893: I tensorflow/core/framework/op.cc:132] Op<name=ReaderReadV2; signature=reader_handle:resource, queue_handle:resource -> key:string, value:string; is_stateful=true>
  2023-01-12 09:34:37.776963: I tensorflow/core/framework/op.cc:132] Op<name=ReaderReset; signature=reader_handle:Ref(string) -> >
  2023-01-12 09:34:37.777026: I tensorflow/core/framework/op.cc:132] Op<name=ReaderResetV2; signature=reader_handle:resource -> ; is_stateful=true>
  2023-01-12 09:34:37.777093: I tensorflow/core/framework/op.cc:132] Op<name=ReaderRestoreState; signature=reader_handle:Ref(string), state:string -> >
  2023-01-12 09:34:37.777157: I tensorflow/core/framework/op.cc:132] Op<name=ReaderRestoreStateV2; signature=reader_handle:resource, state:string -> ; is_stateful=true>
  2023-01-12 09:34:37.777222: I tensorflow/core/framework/op.cc:132] Op<name=ReaderSerializeState; signature=reader_handle:Ref(string) -> state:string>
  2023-01-12 09:34:37.777301: I tensorflow/core/framework/op.cc:132] Op<name=ReaderSerializeStateV2; signature=reader_handle:resource -> state:string; is_stateful=true>
  2023-01-12 09:34:37.777406: I tensorflow/core/framework/op.cc:132] Op<name=Real; signature=input:T -> output:Tout; attr=T:type,default=DT_COMPLEX64,allowed=[DT_COMPLEX64, DT_COMPLEX128]; attr=Tout:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.777526: I tensorflow/core/framework/op.cc:132] Op<name=RealDiv; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_INT32, DT_UINT32, DT_UINT64, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.777861: I tensorflow/core/framework/op.cc:132] Op<name=RebatchDataset; signature=input_dataset:variant, num_replicas:int64 -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_fallback:bool,default=true>
  2023-01-12 09:34:37.778086: I tensorflow/core/framework/op.cc:132] Op<name=RebatchDatasetV2; signature=input_dataset:variant, batch_sizes:int64, drop_remainder:bool -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1>
  2023-01-12 09:34:37.778442: I tensorflow/core/framework/op.cc:132] Op<name=Reciprocal; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT8, DT_INT16, DT_INT32, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.778646: I tensorflow/core/framework/op.cc:132] Op<name=ReciprocalGrad; signature=y:T, dy:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.778829: I tensorflow/core/framework/op.cc:132] Op<name=RecordInput; signature= -> records:string; attr=file_pattern:string; attr=file_random_seed:int,default=301; attr=file_shuffle_shift_ratio:float,default=0; attr=file_buffer_size:int,default=10000; attr=file_parallelism:int,default=16; attr=batch_size:int,default=32; attr=compression_type:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.778996: I tensorflow/core/framework/op.cc:132] Op<name=Recv; signature= -> tensor:tensor_type; attr=tensor_type:type; attr=tensor_name:string; attr=send_device:string; attr=send_device_incarnation:int; attr=recv_device:string; attr=client_terminated:bool,default=false; is_stateful=true; is_distributed_communication=true>
  2023-01-12 09:34:37.779199: I tensorflow/core/framework/op.cc:132] Op<name=RecvTPUEmbeddingActivations; signature= -> outputs:num_outputs*float; attr=num_outputs:int,min=1; attr=config:string; is_stateful=true>
  2023-01-12 09:34:37.779337: I tensorflow/core/framework/op.cc:132] Op<name=ReduceDataset; signature=input_dataset:variant, initial_state:, other_arguments: -> components:; attr=f:func; attr=Tstate:list(type),min=1; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=metadata:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.779469: I tensorflow/core/framework/op.cc:132] Op<name=ReduceJoin; signature=inputs:string, reduction_indices:int32 -> output:string; attr=keep_dims:bool,default=false; attr=separator:string,default="">
  2023-01-12 09:34:37.779584: I tensorflow/core/framework/op.cc:132] Op<name=RefEnter; signature=data:Ref(T) -> output:Ref(T); attr=T:type; attr=frame_name:string; attr=is_constant:bool,default=false; attr=parallel_iterations:int,default=10>
  2023-01-12 09:34:37.779629: I tensorflow/core/framework/op.cc:132] Op<name=RefExit; signature=data:Ref(T) -> output:Ref(T); attr=T:type>
  2023-01-12 09:34:37.779703: I tensorflow/core/framework/op.cc:132] Op<name=RefIdentity; signature=input:Ref(T) -> output:Ref(T); attr=T:type; allows_uninitialized_input=true>
  2023-01-12 09:34:37.779770: I tensorflow/core/framework/op.cc:132] Op<name=RefIn; signature=a:Ref(T) -> ; attr=T:type>
  2023-01-12 09:34:37.779865: I tensorflow/core/framework/op.cc:132] Op<name=RefInputFloatInput; signature=a:Ref(float), b:float -> >
  2023-01-12 09:34:37.780048: I tensorflow/core/framework/op.cc:132] Op<name=RefInputFloatInputIntOutput; signature=a:Ref(float), b:float -> c:int32>
  2023-01-12 09:34:37.780166: I tensorflow/core/framework/op.cc:132] Op<name=RefInputIntInput; signature=a:Ref(int32), b:int32 -> >
  2023-01-12 09:34:37.780212: I tensorflow/core/framework/op.cc:132] Op<name=RefMerge; signature=inputs:Ref(N*T) -> output:Ref(T), value_index:int32; attr=T:type; attr=N:int,min=1>
  2023-01-12 09:34:37.780292: I tensorflow/core/framework/op.cc:132] Op<name=RefNextIteration; signature=data:Ref(T) -> output:Ref(T); attr=T:type>
  2023-01-12 09:34:37.780394: I tensorflow/core/framework/op.cc:132] Op<name=RefOut; signature= -> a:Ref(T); attr=T:type>
  2023-01-12 09:34:37.780478: I tensorflow/core/framework/op.cc:132] Op<name=RefOutput; signature= -> a:Ref(int32)>
  2023-01-12 09:34:37.780524: I tensorflow/core/framework/op.cc:132] Op<name=RefOutputFloatOutput; signature= -> a:Ref(float), b:float>
  2023-01-12 09:34:37.780559: I tensorflow/core/framework/op.cc:132] Op<name=RefSelect; signature=index:int32, inputs:Ref(N*T) -> output:Ref(T); attr=T:type; attr=N:int,min=1>
  2023-01-12 09:34:37.780595: I tensorflow/core/framework/op.cc:132] Op<name=RefSwitch; signature=data:Ref(T), pred:bool -> output_false:Ref(T), output_true:Ref(T); attr=T:type; allows_uninitialized_input=true>
  2023-01-12 09:34:37.780672: I tensorflow/core/framework/op.cc:132] Op<name=RegexFullMatch; signature=input:string, pattern:string -> output:bool>
  2023-01-12 09:34:37.780729: I tensorflow/core/framework/op.cc:132] Op<name=RegexReplace; signature=input:string, pattern:string, rewrite:string -> output:string; attr=replace_global:bool,default=true>
  2023-01-12 09:34:37.780851: I tensorflow/core/framework/op.cc:132] Op<name=RegisterDataset; signature=dataset:variant, address:string, protocol:string -> dataset_id:int64; attr=external_state_policy:int; attr=element_spec:string,default=""; attr=metadata:string,default="">
  2023-01-12 09:34:37.780997: I tensorflow/core/framework/op.cc:132] Op<name=RegisterDatasetV2; signature=dataset:variant, address:string, protocol:string -> dataset_id:string; attr=external_state_policy:int; attr=element_spec:string,default=""; attr=requested_dataset_id:string,default=""; attr=metadata:string,default="">
  2023-01-12 09:34:37.781033: I tensorflow/core/framework/op.cc:132] Op<name=Relayout; signature=input:T -> output:T; attr=layout:string; attr=T:type>
  2023-01-12 09:34:37.781329: I tensorflow/core/framework/op.cc:132] Op<name=Relu; signature=features:T -> activations:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64, DT_QINT8]>
  2023-01-12 09:34:37.781427: I tensorflow/core/framework/op.cc:132] Op<name=Relu6; signature=features:T -> activations:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:37.781475: I tensorflow/core/framework/op.cc:132] Op<name=Relu6Grad; signature=gradients:T, features:T -> backprops:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:37.781558: I tensorflow/core/framework/op.cc:132] Op<name=ReluGrad; signature=gradients:T, features:T -> backprops:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:37.781597: I tensorflow/core/framework/op.cc:132] Op<name=RemoteCall; signature=target:string, args: -> output:; attr=Tin:list(type),min=1; attr=Tout:list(type),min=1; attr=f:func; is_stateful=true>
  2023-01-12 09:34:37.781637: I tensorflow/core/framework/op.cc:132] Op<name=RepeatDataset; signature=input_dataset:variant, count:int64 -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=metadata:string,default="">
  2023-01-12 09:34:37.781793: I tensorflow/core/framework/op.cc:132] Op<name=RequantizationRange; signature=input:Tinput, input_min:float, input_max:float -> output_min:float, output_max:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]>
  2023-01-12 09:34:37.781842: I tensorflow/core/framework/op.cc:132] Op<name=RequantizationRangePerChannel; signature=input:T, input_min:float, input_max:float -> output_min:float, output_max:float; attr=T:type,default=DT_QINT32,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=clip_value_max:float>
  2023-01-12 09:34:37.781939: I tensorflow/core/framework/op.cc:132] Op<name=Requantize; signature=input:Tinput, input_min:float, input_max:float, requested_output_min:float, requested_output_max:float -> output:out_type, output_min:float, output_max:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=out_type:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]>
  2023-01-12 09:34:37.782016: I tensorflow/core/framework/op.cc:132] Op<name=RequantizePerChannel; signature=input:T, input_min:float, input_max:float, requested_output_min:float, requested_output_max:float -> output:out_type, output_min:float, output_max:float; attr=T:type,default=DT_QINT32,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=out_type:type,default=DT_QUINT8,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]>
  2023-01-12 09:34:37.782042: I tensorflow/core/framework/op.cc:132] Op<name=RequiresOlderGraphVersion; signature= -> version:int32; is_stateful=true>
  2023-01-12 09:34:37.782099: I tensorflow/core/framework/op.cc:132] Op<name=ReservedAttr; signature= -> ; attr=range:int>
  2023-01-12 09:34:37.782131: I tensorflow/core/framework/op.cc:132] Op<name=ReservedInput; signature=input:int32 -> >
  2023-01-12 09:34:37.782163: I tensorflow/core/framework/op.cc:132] Op<name=Reshape; signature=tensor:T, shape:Tshape -> output:T; attr=T:type; attr=Tshape:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.782204: I tensorflow/core/framework/op.cc:132] Op<name=ResizeArea; signature=images:T, size:int32 -> resized_images:float; attr=T:type,allowed=[DT_INT8, DT_UINT8, DT_INT16, DT_UINT16, DT_INT32, DT_INT64, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_BFLOAT16]; attr=align_corners:bool,default=false>
  2023-01-12 09:34:37.783490: I tensorflow/core/framework/op.cc:132] Op<name=ResizeBicubic; signature=images:T, size:int32 -> resized_images:float; attr=T:type,allowed=[DT_INT8, DT_UINT8, DT_INT16, DT_UINT16, DT_INT32, DT_INT64, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_BFLOAT16]; attr=align_corners:bool,default=false; attr=half_pixel_centers:bool,default=false>
  2023-01-12 09:34:37.783792: I tensorflow/core/framework/op.cc:132] Op<name=ResizeBicubicGrad; signature=grads:float, original_image:T -> output:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE]; attr=align_corners:bool,default=false; attr=half_pixel_centers:bool,default=false>
  2023-01-12 09:34:37.783884: I tensorflow/core/framework/op.cc:132] Op<name=ResizeBilinear; signature=images:T, size:int32 -> resized_images:float; attr=T:type,allowed=[DT_INT8, DT_UINT8, DT_INT16, DT_UINT16, DT_INT32, DT_INT64, DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_BFLOAT16]; attr=align_corners:bool,default=false; attr=half_pixel_centers:bool,default=false>
  2023-01-12 09:34:37.783965: I tensorflow/core/framework/op.cc:132] Op<name=ResizeBilinearGrad; signature=grads:float, original_image:T -> output:T; attr=T:type,allowed=[DT_FLOAT, DT_BFLOAT16, DT_HALF, DT_DOUBLE]; attr=align_corners:bool,default=false; attr=half_pixel_centers:bool,default=false>
  2023-01-12 09:34:37.784007: I tensorflow/core/framework/op.cc:132] Op<name=ResizeNearestNeighbor; signature=images:T, size:int32 -> resized_images:T; attr=T:type,allowed=[DT_INT8, DT_UINT8, DT_INT16, DT_UINT16, DT_INT32, DT_INT64, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_BFLOAT16]; attr=align_corners:bool,default=false; attr=half_pixel_centers:bool,default=false>
  2023-01-12 09:34:37.784042: I tensorflow/core/framework/op.cc:132] Op<name=ResizeNearestNeighborGrad; signature=grads:T, size:int32 -> output:T; attr=T:type,allowed=[DT_UINT8, DT_INT8, DT_INT32, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_BFLOAT16]; attr=align_corners:bool,default=false; attr=half_pixel_centers:bool,default=false>
  2023-01-12 09:34:37.784126: I tensorflow/core/framework/op.cc:132] Op<name=ResourceAccumulatorApplyGradient; signature=handle:resource, local_step:int64, gradient:dtype -> ; attr=dtype:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; is_stateful=true>
  2023-01-12 09:34:37.784155: I tensorflow/core/framework/op.cc:132] Op<name=ResourceAccumulatorNumAccumulated; signature=handle:resource -> num_accumulated:int32; is_stateful=true>
  2023-01-12 09:34:37.784171: I tensorflow/core/framework/op.cc:132] Op<name=ResourceAccumulatorSetGlobalStep; signature=handle:resource, new_global_step:int64 -> ; is_stateful=true>
  2023-01-12 09:34:37.784206: I tensorflow/core/framework/op.cc:132] Op<name=ResourceAccumulatorTakeGradient; signature=handle:resource, num_required:int32 -> average:dtype; attr=dtype:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; is_stateful=true>
  2023-01-12 09:34:37.784248: I tensorflow/core/framework/op.cc:132] Op<name=ResourceApplyAdaMax; signature=var:resource, m:resource, v:resource, beta1_power:T, lr:T, beta1:T, beta2:T, epsilon:T, grad:T -> ; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=use_locking:bool,default=false; is_stateful=true>
  2023-01-12 09:34:37.784347: I tensorflow/core/framework/op.cc:132] Op<name=ResourceApplyAdadelta; signature=var:resource, accum:resource, accum_update:resource, lr:T, rho:T, epsilon:T, grad:T -> ; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=use_locking:bool,default=false; is_stateful=true>
  2023-01-12 09:34:37.784392: I tensorflow/core/framework/op.cc:132] Op<name=ResourceApplyAdagrad; signature=var:resource, accum:resource, lr:T, grad:T -> ; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=use_locking:bool,default=false; attr=update_slots:bool,default=true; is_stateful=true>
  2023-01-12 09:34:37.784474: I tensorflow/core/framework/op.cc:132] Op<name=ResourceApplyAdagradDA; signature=var:resource, gradient_accumulator:resource, gradient_squared_accumulator:resource, grad:T, lr:T, l1:T, l2:T, global_step:int64 -> ; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=use_locking:bool,default=false; is_stateful=true>
  2023-01-12 09:34:37.784520: I tensorflow/core/framework/op.cc:132] Op<name=ResourceApplyAdagradV2; signature=var:resource, accum:resource, lr:T, epsilon:T, grad:T -> ; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=use_locking:bool,default=false; attr=update_slots:bool,default=true; is_stateful=true>
  2023-01-12 09:34:37.784602: I tensorflow/core/framework/op.cc:132] Op<name=ResourceApplyAdam; signature=var:resource, m:resource, v:resource, beta1_power:T, beta2_power:T, lr:T, beta1:T, beta2:T, epsilon:T, grad:T -> ; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=use_locking:bool,default=false; attr=use_nesterov:bool,default=false; is_stateful=true>
  2023-01-12 09:34:37.784655: I tensorflow/core/framework/op.cc:132] Op<name=ResourceApplyAdamWithAmsgrad; signature=var:resource, m:resource, v:resource, vhat:resource, beta1_power:T, beta2_power:T, lr:T, beta1:T, beta2:T, epsilon:T, grad:T -> ; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=use_locking:bool,default=false; is_stateful=true>
  2023-01-12 09:34:37.784703: I tensorflow/core/framework/op.cc:132] Op<name=ResourceApplyAddSign; signature=var:resource, m:resource, lr:T, alpha:T, sign_decay:T, beta:T, grad:T -> ; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=use_locking:bool,default=false; is_stateful=true>
  2023-01-12 09:34:37.784835: I tensorflow/core/framework/op.cc:132] Op<name=ResourceApplyCenteredRMSProp; signature=var:resource, mg:resource, ms:resource, mom:resource, lr:T, rho:T, momentum:T, epsilon:T, grad:T -> ; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=use_locking:bool,default=false; is_stateful=true>
  2023-01-12 09:34:37.785176: I tensorflow/core/framework/op.cc:132] Op<name=ResourceApplyFtrl; signature=var:resource, accum:resource, linear:resource, grad:T, lr:T, l1:T, l2:T, lr_power:T -> ; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=use_locking:bool,default=false; attr=multiply_linear_by_lr:bool,default=false; is_stateful=true>
  2023-01-12 09:34:37.785519: I tensorflow/core/framework/op.cc:132] Op<name=ResourceApplyFtrlV2; signature=var:resource, accum:resource, linear:resource, grad:T, lr:T, l1:T, l2:T, l2_shrinkage:T, lr_power:T -> ; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=use_locking:bool,default=false; attr=multiply_linear_by_lr:bool,default=false; is_stateful=true>
  2023-01-12 09:34:37.785603: I tensorflow/core/framework/op.cc:132] Op<name=ResourceApplyGradientDescent; signature=var:resource, alpha:T, delta:T -> ; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=use_locking:bool,default=false; is_stateful=true>
  2023-01-12 09:34:37.785678: I tensorflow/core/framework/op.cc:132] Op<name=ResourceApplyKerasMomentum; signature=var:resource, accum:resource, lr:T, grad:T, momentum:T -> ; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=use_locking:bool,default=false; attr=use_nesterov:bool,default=false; is_stateful=true>
  2023-01-12 09:34:37.785823: I tensorflow/core/framework/op.cc:132] Op<name=ResourceApplyMomentum; signature=var:resource, accum:resource, lr:T, grad:T, momentum:T -> ; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=use_locking:bool,default=false; attr=use_nesterov:bool,default=false; is_stateful=true>
  2023-01-12 09:34:37.785963: I tensorflow/core/framework/op.cc:132] Op<name=ResourceApplyPowerSign; signature=var:resource, m:resource, lr:T, logbase:T, sign_decay:T, beta:T, grad:T -> ; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=use_locking:bool,default=false; is_stateful=true>
  2023-01-12 09:34:37.786056: I tensorflow/core/framework/op.cc:132] Op<name=ResourceApplyProximalAdagrad; signature=var:resource, accum:resource, lr:T, l1:T, l2:T, grad:T -> ; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=use_locking:bool,default=false; is_stateful=true>
  2023-01-12 09:34:37.786137: I tensorflow/core/framework/op.cc:132] Op<name=ResourceApplyProximalGradientDescent; signature=var:resource, alpha:T, l1:T, l2:T, delta:T -> ; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=use_locking:bool,default=false; is_stateful=true>
  2023-01-12 09:34:37.786305: I tensorflow/core/framework/op.cc:132] Op<name=ResourceApplyRMSProp; signature=var:resource, ms:resource, mom:resource, lr:T, rho:T, momentum:T, epsilon:T, grad:T -> ; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=use_locking:bool,default=false; is_stateful=true>
  2023-01-12 09:34:37.786435: I tensorflow/core/framework/op.cc:132] Op<name=ResourceConditionalAccumulator; signature= -> handle:resource; attr=dtype:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=shape:shape; attr=container:string,default=""; attr=shared_name:string,default=""; attr=reduction_type:string,default="MEAN",allowed=["MEAN", "SUM"]; is_stateful=true>
  2023-01-12 09:34:37.786552: I tensorflow/core/framework/op.cc:132] Op<name=ResourceCountUpTo; signature=resource:resource -> output:T; attr=limit:int; attr=T:type,allowed=[DT_INT32, DT_INT64]; is_stateful=true>
  2023-01-12 09:34:37.786797: I tensorflow/core/framework/op.cc:132] Op<name=ResourceCreateOp; signature=resource:resource -> ; is_stateful=true>
  2023-01-12 09:34:37.786963: I tensorflow/core/framework/op.cc:132] Op<name=ResourceGather; signature=resource:resource, indices:Tindices -> output:dtype; attr=batch_dims:int,default=0; attr=validate_indices:bool,default=true; attr=dtype:type; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; is_stateful=true>
  2023-01-12 09:34:37.787071: I tensorflow/core/framework/op.cc:132] Op<name=ResourceGatherNd; signature=resource:resource, indices:Tindices -> output:dtype; attr=dtype:type; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; is_stateful=true>
  2023-01-12 09:34:37.787177: I tensorflow/core/framework/op.cc:132] Op<name=ResourceInitializedOp; signature=resource:resource -> initialized:bool; is_stateful=true>
  2023-01-12 09:34:37.787320: I tensorflow/core/framework/op.cc:132] Op<name=ResourceScatterAdd; signature=resource:resource, indices:Tindices, updates:dtype -> ; attr=dtype:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; is_stateful=true>
  2023-01-12 09:34:37.787485: I tensorflow/core/framework/op.cc:132] Op<name=ResourceScatterDiv; signature=resource:resource, indices:Tindices, updates:dtype -> ; attr=dtype:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; is_stateful=true>
  2023-01-12 09:34:37.787584: I tensorflow/core/framework/op.cc:132] Op<name=ResourceScatterMax; signature=resource:resource, indices:Tindices, updates:dtype -> ; attr=dtype:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; is_stateful=true>
  2023-01-12 09:34:37.787671: I tensorflow/core/framework/op.cc:132] Op<name=ResourceScatterMin; signature=resource:resource, indices:Tindices, updates:dtype -> ; attr=dtype:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; is_stateful=true>
  2023-01-12 09:34:37.787736: I tensorflow/core/framework/op.cc:132] Op<name=ResourceScatterMul; signature=resource:resource, indices:Tindices, updates:dtype -> ; attr=dtype:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; is_stateful=true>
  2023-01-12 09:34:37.787803: I tensorflow/core/framework/op.cc:132] Op<name=ResourceScatterNdAdd; signature=ref:resource, indices:Tindices, updates:T -> ; attr=T:type; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=true; is_stateful=true>
  2023-01-12 09:34:37.787855: I tensorflow/core/framework/op.cc:132] Op<name=ResourceScatterNdMax; signature=ref:resource, indices:Tindices, updates:T -> ; attr=T:type; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=true; is_stateful=true>
  2023-01-12 09:34:37.787964: I tensorflow/core/framework/op.cc:132] Op<name=ResourceScatterNdMin; signature=ref:resource, indices:Tindices, updates:T -> ; attr=T:type; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=true; is_stateful=true>
  2023-01-12 09:34:37.788066: I tensorflow/core/framework/op.cc:132] Op<name=ResourceScatterNdSub; signature=ref:resource, indices:Tindices, updates:T -> ; attr=T:type; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=true; is_stateful=true>
  2023-01-12 09:34:37.788205: I tensorflow/core/framework/op.cc:132] Op<name=ResourceScatterNdUpdate; signature=ref:resource, indices:Tindices, updates:T -> ; attr=T:type; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=true; is_stateful=true>
  2023-01-12 09:34:37.788355: I tensorflow/core/framework/op.cc:132] Op<name=ResourceScatterSub; signature=resource:resource, indices:Tindices, updates:dtype -> ; attr=dtype:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; is_stateful=true>
  2023-01-12 09:34:37.788388: I tensorflow/core/framework/op.cc:132] Op<name=ResourceScatterUpdate; signature=resource:resource, indices:Tindices, updates:dtype -> ; attr=dtype:type; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; is_stateful=true>
  2023-01-12 09:34:37.788422: I tensorflow/core/framework/op.cc:132] Op<name=ResourceSparseApplyAdadelta; signature=var:resource, accum:resource, accum_update:resource, lr:T, rho:T, epsilon:T, grad:T, indices:Tindices -> ; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=false; is_stateful=true>
  2023-01-12 09:34:37.788460: I tensorflow/core/framework/op.cc:132] Op<name=ResourceSparseApplyAdagrad; signature=var:resource, accum:resource, lr:T, grad:T, indices:Tindices -> ; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=false; attr=update_slots:bool,default=true; is_stateful=true>
  2023-01-12 09:34:37.788494: I tensorflow/core/framework/op.cc:132] Op<name=ResourceSparseApplyAdagradDA; signature=var:resource, gradient_accumulator:resource, gradient_squared_accumulator:resource, grad:T, indices:Tindices, lr:T, l1:T, l2:T, global_step:int64 -> ; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=false; is_stateful=true>
  2023-01-12 09:34:37.788527: I tensorflow/core/framework/op.cc:132] Op<name=ResourceSparseApplyAdagradV2; signature=var:resource, accum:resource, lr:T, epsilon:T, grad:T, indices:Tindices -> ; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=false; attr=update_slots:bool,default=true; is_stateful=true>
  2023-01-12 09:34:37.788579: I tensorflow/core/framework/op.cc:132] Op<name=ResourceSparseApplyCenteredRMSProp; signature=var:resource, mg:resource, ms:resource, mom:resource, lr:T, rho:T, momentum:T, epsilon:T, grad:T, indices:Tindices -> ; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=false; is_stateful=true>
  2023-01-12 09:34:37.788768: I tensorflow/core/framework/op.cc:132] Op<name=ResourceSparseApplyFtrl; signature=var:resource, accum:resource, linear:resource, grad:T, indices:Tindices, lr:T, l1:T, l2:T, lr_power:T -> ; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=false; attr=multiply_linear_by_lr:bool,default=false; is_stateful=true>
  2023-01-12 09:34:37.788849: I tensorflow/core/framework/op.cc:132] Op<name=ResourceSparseApplyFtrlV2; signature=var:resource, accum:resource, linear:resource, grad:T, indices:Tindices, lr:T, l1:T, l2:T, l2_shrinkage:T, lr_power:T -> ; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=false; attr=multiply_linear_by_lr:bool,default=false; is_stateful=true>
  2023-01-12 09:34:37.788956: I tensorflow/core/framework/op.cc:132] Op<name=ResourceSparseApplyKerasMomentum; signature=var:resource, accum:resource, lr:T, grad:T, indices:Tindices, momentum:T -> ; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=false; attr=use_nesterov:bool,default=false; is_stateful=true>
  2023-01-12 09:34:37.790344: I tensorflow/core/framework/op.cc:132] Op<name=ResourceSparseApplyMomentum; signature=var:resource, accum:resource, lr:T, grad:T, indices:Tindices, momentum:T -> ; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=false; attr=use_nesterov:bool,default=false; is_stateful=true>
  2023-01-12 09:34:37.790464: I tensorflow/core/framework/op.cc:132] Op<name=ResourceSparseApplyProximalAdagrad; signature=var:resource, accum:resource, lr:T, l1:T, l2:T, grad:T, indices:Tindices -> ; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=false; is_stateful=true>
  2023-01-12 09:34:37.790560: I tensorflow/core/framework/op.cc:132] Op<name=ResourceSparseApplyProximalGradientDescent; signature=var:resource, alpha:T, l1:T, l2:T, grad:T, indices:Tindices -> ; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=false; is_stateful=true>
  2023-01-12 09:34:37.790760: I tensorflow/core/framework/op.cc:132] Op<name=ResourceSparseApplyRMSProp; signature=var:resource, ms:resource, mom:resource, lr:T, rho:T, momentum:T, epsilon:T, grad:T, indices:Tindices -> ; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=false; is_stateful=true>
  2023-01-12 09:34:37.790891: I tensorflow/core/framework/op.cc:132] Op<name=ResourceStridedSliceAssign; signature=ref:resource, begin:Index, end:Index, strides:Index, value:T -> ; attr=T:type; attr=Index:type,allowed=[DT_INT32, DT_INT64]; attr=begin_mask:int,default=0; attr=end_mask:int,default=0; attr=ellipsis_mask:int,default=0; attr=new_axis_mask:int,default=0; attr=shrink_axis_mask:int,default=0; is_stateful=true>
  2023-01-12 09:34:37.791008: I tensorflow/core/framework/op.cc:132] Op<name=ResourceUsingOp; signature=resource:resource -> ; is_stateful=true>
  2023-01-12 09:34:37.791125: I tensorflow/core/framework/op.cc:132] Op<name=Restore; signature=file_pattern:string, tensor_name:string -> tensor:dt; attr=dt:type; attr=preferred_shard:int,default=-1; is_stateful=true>
  2023-01-12 09:34:37.791189: I tensorflow/core/framework/op.cc:132] Op<name=RestoreSlice; signature=file_pattern:string, tensor_name:string, shape_and_slice:string -> tensor:dt; attr=dt:type; attr=preferred_shard:int,default=-1; is_stateful=true>
  2023-01-12 09:34:37.791238: I tensorflow/core/framework/op.cc:132] Op<name=RestoreV2; signature=prefix:string, tensor_names:string, shape_and_slices:string -> tensors:; attr=dtypes:list(type),min=1; is_stateful=true>
  2023-01-12 09:34:37.791298: I tensorflow/core/framework/op.cc:132] Op<name=Restrict; signature=a:T -> out:T; attr=T:type,allowed=[DT_STRING, DT_BOOL]>
  2023-01-12 09:34:37.791376: I tensorflow/core/framework/op.cc:132] Op<name=RetrieveAllTPUEmbeddingParameters; signature= -> parameters:NumTables*float, auxiliary1:NumTables*float, auxiliary2:NumTables*float, auxiliary3:NumTables*float, auxiliary4:NumTables*float, auxiliary5:NumTables*float, auxiliary6:NumTables*float, auxiliary7:NumTables*float; attr=NumTables:int,min=1; attr=config:string; attr=num_shards:int; attr=shard_id:int; is_stateful=true>
  2023-01-12 09:34:37.791457: I tensorflow/core/framework/op.cc:132] Op<name=RetrieveTPUEmbeddingADAMParameters; signature= -> parameters:float, momenta:float, velocities:float; attr=table_id:int,default=-1; attr=table_name:string,default=""; attr=num_shards:int; attr=shard_id:int; attr=config:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.791503: I tensorflow/core/framework/op.cc:132] Op<name=RetrieveTPUEmbeddingAdadeltaParameters; signature= -> parameters:float, accumulators:float, updates:float; attr=table_id:int,default=-1; attr=table_name:string,default=""; attr=num_shards:int; attr=shard_id:int; attr=config:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.791663: I tensorflow/core/framework/op.cc:132] Op<name=RetrieveTPUEmbeddingAdagradMomentumParameters; signature= -> parameters:float, accumulators:float, momenta:float; attr=table_id:int,default=-1; attr=table_name:string,default=""; attr=num_shards:int; attr=shard_id:int; attr=config:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.791749: I tensorflow/core/framework/op.cc:132] Op<name=RetrieveTPUEmbeddingAdagradParameters; signature= -> parameters:float, accumulators:float; attr=table_id:int,default=-1; attr=table_name:string,default=""; attr=num_shards:int; attr=shard_id:int; attr=config:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.791809: I tensorflow/core/framework/op.cc:132] Op<name=RetrieveTPUEmbeddingCenteredRMSPropParameters; signature= -> parameters:float, ms:float, mom:float, mg:float; attr=table_id:int,default=-1; attr=table_name:string,default=""; attr=num_shards:int; attr=shard_id:int; attr=config:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.791895: I tensorflow/core/framework/op.cc:132] Op<name=RetrieveTPUEmbeddingFTRLParameters; signature= -> parameters:float, accumulators:float, linears:float; attr=table_id:int,default=-1; attr=table_name:string,default=""; attr=num_shards:int; attr=shard_id:int; attr=config:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.791997: I tensorflow/core/framework/op.cc:132] Op<name=RetrieveTPUEmbeddingFrequencyEstimatorParameters; signature= -> parameters:float, last_hit_step:float; attr=table_id:int,default=-1; attr=table_name:string,default=""; attr=num_shards:int; attr=shard_id:int; attr=config:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.792041: I tensorflow/core/framework/op.cc:132] Op<name=RetrieveTPUEmbeddingMDLAdagradLightParameters; signature= -> parameters:float, accumulators:float, weights:float, benefits:float; attr=table_id:int,default=-1; attr=table_name:string,default=""; attr=num_shards:int; attr=shard_id:int; attr=config:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.792075: I tensorflow/core/framework/op.cc:132] Op<name=RetrieveTPUEmbeddingMomentumParameters; signature= -> parameters:float, momenta:float; attr=table_id:int,default=-1; attr=table_name:string,default=""; attr=num_shards:int; attr=shard_id:int; attr=config:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.792103: I tensorflow/core/framework/op.cc:132] Op<name=RetrieveTPUEmbeddingProximalAdagradParameters; signature= -> parameters:float, accumulators:float; attr=table_id:int,default=-1; attr=table_name:string,default=""; attr=num_shards:int; attr=shard_id:int; attr=config:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.792144: I tensorflow/core/framework/op.cc:132] Op<name=RetrieveTPUEmbeddingProximalYogiParameters; signature= -> parameters:float, v:float, m:float; attr=table_id:int,default=-1; attr=table_name:string,default=""; attr=num_shards:int; attr=shard_id:int; attr=config:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.792195: I tensorflow/core/framework/op.cc:132] Op<name=RetrieveTPUEmbeddingRMSPropParameters; signature= -> parameters:float, ms:float, mom:float; attr=table_id:int,default=-1; attr=table_name:string,default=""; attr=num_shards:int; attr=shard_id:int; attr=config:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.792307: I tensorflow/core/framework/op.cc:132] Op<name=RetrieveTPUEmbeddingStochasticGradientDescentParameters; signature= -> parameters:float; attr=table_id:int,default=-1; attr=table_name:string,default=""; attr=num_shards:int; attr=shard_id:int; attr=config:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.792475: I tensorflow/core/framework/op.cc:132] Op<name=Reverse; signature=tensor:T, dims:bool -> output:T; attr=T:type,allowed=[DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_UINT32, 15741007897756916787, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128, DT_STRING]>
  2023-01-12 09:34:37.792540: I tensorflow/core/framework/op.cc:132] Op<name=ReverseSequence; signature=input:T, seq_lengths:Tlen -> output:T; attr=seq_dim:int; attr=batch_dim:int,default=0; attr=T:type; attr=Tlen:type,default=DT_INT64,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.792602: I tensorflow/core/framework/op.cc:132] Op<name=ReverseV2; signature=tensor:T, axis:Tidx -> output:T; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=T:type,allowed=[DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_INT32, 5951096766385938332, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128, DT_STRING]>
  2023-01-12 09:34:37.792836: I tensorflow/core/framework/op.cc:132] Op<name=RewriteDataset; signature=input_dataset:variant, rewrite_name:string -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1>
  2023-01-12 09:34:37.793031: I tensorflow/core/framework/op.cc:132] Op<name=RightShift; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_INT8, DT_INT16, DT_INT32, DT_INT64, DT_UINT8, DT_UINT16, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:37.793094: I tensorflow/core/framework/op.cc:132] Op<name=Rint; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.793131: I tensorflow/core/framework/op.cc:132] Op<name=RiscAbs; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.793161: I tensorflow/core/framework/op.cc:132] Op<name=RiscAdd; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]; is_commutative=true; is_aggregate=true>
  2023-01-12 09:34:37.793295: I tensorflow/core/framework/op.cc:132] Op<name=RiscBinaryArithmetic; signature=x:T, y:T -> z:T; attr=op_type:string,allowed=["ADD", "SUB", "MUL", "DIV", "REM", "MIN", "POW"]; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.793363: I tensorflow/core/framework/op.cc:132] Op<name=RiscBinaryComparison; signature=x:T, y:T -> z:bool; attr=op_type:string,allowed=["EQ", "NE", "GE", "GT", "LE", "LT"]; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.793405: I tensorflow/core/framework/op.cc:132] Op<name=RiscBitcast; signature=x:SrcT -> y:DstT; attr=SrcT:type; attr=DstT:type>
  2023-01-12 09:34:37.793538: I tensorflow/core/framework/op.cc:132] Op<name=RiscBroadcast; signature=input:T, shape:Tidx -> output:T; attr=T:type; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.793574: I tensorflow/core/framework/op.cc:132] Op<name=RiscCast; signature=x:SrcT -> y:DstT; attr=SrcT:type; attr=DstT:type>
  2023-01-12 09:34:37.793608: I tensorflow/core/framework/op.cc:132] Op<name=RiscCeil; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.793643: I tensorflow/core/framework/op.cc:132] Op<name=RiscCholesky; signature=input:T -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.793677: I tensorflow/core/framework/op.cc:132] Op<name=RiscConcat; signature=values:N*T, axis:Tidx -> output:T; attr=N:int,min=2; attr=T:type; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.793724: I tensorflow/core/framework/op.cc:132] Op<name=RiscCondition; signature=pred:bool, input_true:SrcT, input_false:SrcT -> output:DstT; attr=func_true:func; attr=func_false:func; attr=SrcT:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=DstT:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.793798: I tensorflow/core/framework/op.cc:132] Op<name=RiscConv; signature=input:T, filter:T -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=strides:list(int); attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=dilations:list(int),default=[1, 1, 1, 1]>
  2023-01-12 09:34:37.794343: I tensorflow/core/framework/op.cc:132] Op<name=RiscCos; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.794630: I tensorflow/core/framework/op.cc:132] Op<name=RiscDiv; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.794897: I tensorflow/core/framework/op.cc:132] Op<name=RiscDot; signature=a:T, b:T -> product:T; attr=transpose_a:bool,default=false; attr=transpose_b:bool,default=false; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.795012: I tensorflow/core/framework/op.cc:132] Op<name=RiscExp; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.795059: I tensorflow/core/framework/op.cc:132] Op<name=RiscFft; signature=input:Tcomplex -> output:Tcomplex; attr=Tcomplex:type,default=DT_COMPLEX64,allowed=[DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.795090: I tensorflow/core/framework/op.cc:132] Op<name=RiscFloor; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.795130: I tensorflow/core/framework/op.cc:132] Op<name=RiscGather; signature=params:Tparams, indices:Tindices, axis:Taxis -> output:Tparams; attr=batch_dims:int,default=0; attr=Tparams:type; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=Taxis:type,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.795166: I tensorflow/core/framework/op.cc:132] Op<name=RiscImag; signature=input:T -> output:Tout; attr=T:type,default=DT_COMPLEX64,allowed=[DT_COMPLEX64, DT_COMPLEX128]; attr=Tout:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.795193: I tensorflow/core/framework/op.cc:132] Op<name=RiscIsFinite; signature=x:T -> y:bool; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.795214: I tensorflow/core/framework/op.cc:132] Op<name=RiscLog; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.795232: I tensorflow/core/framework/op.cc:132] Op<name=RiscLogicalAnd; signature=x:bool, y:bool -> z:bool>
  2023-01-12 09:34:37.795241: I tensorflow/core/framework/op.cc:132] Op<name=RiscLogicalNot; signature=x:bool -> z:bool>
  2023-01-12 09:34:37.795255: I tensorflow/core/framework/op.cc:132] Op<name=RiscLogicalOr; signature=x:bool, y:bool -> z:bool>
  2023-01-12 09:34:37.795281: I tensorflow/core/framework/op.cc:132] Op<name=RiscMax; signature=x:T, y:T -> max:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.795417: I tensorflow/core/framework/op.cc:132] Op<name=RiscMin; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.795538: I tensorflow/core/framework/op.cc:132] Op<name=RiscMul; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.795603: I tensorflow/core/framework/op.cc:132] Op<name=RiscNeg; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.795668: I tensorflow/core/framework/op.cc:132] Op<name=RiscPad; signature=input:T, paddings:Tpaddings, constant_values:T -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=Tpaddings:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.795786: I tensorflow/core/framework/op.cc:132] Op<name=RiscPool; signature=value:T -> output:T; attr=ksize:list(int),min=4; attr=strides:list(int),min=4; attr=pooling_type:string,allowed=["AVG", "MAX"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.795877: I tensorflow/core/framework/op.cc:132] Op<name=RiscPow; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.795949: I tensorflow/core/framework/op.cc:132] Op<name=RiscRandomUniform; signature=shape:T -> output:float; attr=seed:int,default=0; attr=T:type,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.795976: I tensorflow/core/framework/op.cc:132] Op<name=RiscReal; signature=input:T -> output:Tout; attr=T:type,default=DT_COMPLEX64,allowed=[DT_COMPLEX64, DT_COMPLEX128]; attr=Tout:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.795999: I tensorflow/core/framework/op.cc:132] Op<name=RiscReduce; signature=tensor:T, axis:Index -> output:T; attr=reduce_type:string,allowed=["MEAN", "SUM"]; attr=Index:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.796017: I tensorflow/core/framework/op.cc:132] Op<name=RiscRem; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.796035: I tensorflow/core/framework/op.cc:132] Op<name=RiscReshape; signature=tensor:T, shape:Tshape -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=Tshape:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.796053: I tensorflow/core/framework/op.cc:132] Op<name=RiscReverse; signature=tensor:T, axis:Tidx -> output:T; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.796071: I tensorflow/core/framework/op.cc:132] Op<name=RiscScatter; signature=indices:Tindices, updates:T, shape:Tindices -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.796089: I tensorflow/core/framework/op.cc:132] Op<name=RiscShape; signature=input:T -> output:out_type; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=out_type:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.796182: I tensorflow/core/framework/op.cc:132] Op<name=RiscSign; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.796297: I tensorflow/core/framework/op.cc:132] Op<name=RiscSlice; signature=input:T, begin:Index, size:Index -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=Index:type,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.796459: I tensorflow/core/framework/op.cc:132] Op<name=RiscSort; signature=input:T, axis:Index -> output:T; attr=Index:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=direction:string,allowed=["ASCENDING", "DESCENDING"]>
  2023-01-12 09:34:37.796499: I tensorflow/core/framework/op.cc:132] Op<name=RiscSqueeze; signature=input:T -> output:T; attr=T:type; attr=squeeze_dims:list(int),default=[],min=0>
  2023-01-12 09:34:37.796605: I tensorflow/core/framework/op.cc:132] Op<name=RiscSub; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.796667: I tensorflow/core/framework/op.cc:132] Op<name=RiscTranspose; signature=x:T, perm:Tperm -> y:T; attr=T:type; attr=Tperm:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.796767: I tensorflow/core/framework/op.cc:132] Op<name=RiscTriangularSolve; signature=matrix:T, rhs:T -> output:T; attr=lower:bool,default=true; attr=adjoint:bool,default=false; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.797077: I tensorflow/core/framework/op.cc:132] Op<name=RiscUnary; signature=x:T -> y:T; attr=op_type:string,allowed=["ABL", "CEIL", "COS", "EXP", "FLOOR", "IMAG", "LOG", "NEG", "REAL", "SIGN"]; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.797139: I tensorflow/core/framework/op.cc:132] Op<name=RiscWhile; signature=input: -> output:; attr=T:list(type),min=0; attr=cond:func; attr=body:func; attr=output_shapes:list(shape),default=[]; attr=parallel_iterations:int,default=10; is_stateful=true>
  2023-01-12 09:34:37.797181: I tensorflow/core/framework/op.cc:132] Op<name=RngReadAndSkip; signature=resource:resource, alg:int32, delta:uint64 -> value:int64; is_stateful=true>
  2023-01-12 09:34:37.797219: I tensorflow/core/framework/op.cc:132] Op<name=RngSkip; signature=resource:resource, algorithm:int64, delta:int64 -> ; is_stateful=true>
  2023-01-12 09:34:37.797387: I tensorflow/core/framework/op.cc:132] Op<name=Roll; signature=input:T, shift:Tshift, axis:Taxis -> output:T; attr=T:type; attr=Tshift:type,allowed=[DT_INT32, DT_INT64]; attr=Taxis:type,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.797487: I tensorflow/core/framework/op.cc:132] Op<name=Round; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT8, DT_INT16, DT_INT32, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.797571: I tensorflow/core/framework/op.cc:132] Op<name=RpcCall; signature=client:resource, method_name:string, args:, timeout_in_ms:int64 -> future:resource, deleter:variant; attr=Tin:list(type),min=0; is_stateful=true>
  2023-01-12 09:34:37.797604: I tensorflow/core/framework/op.cc:132] Op<name=RpcCheckStatus; signature=status_or:resource -> error_code:int64, error:string; is_stateful=true>
  2023-01-12 09:34:37.797629: I tensorflow/core/framework/op.cc:132] Op<name=RpcClient; signature=server_address:string, timeout_in_ms:int64 -> client:resource, method_specs:string; attr=shared_name:string,default=""; attr=list_registered_methods:bool,default=false; is_stateful=true>
  2023-01-12 09:34:37.797665: I tensorflow/core/framework/op.cc:132] Op<name=RpcGetValue; signature=status_or:resource -> output:; attr=Tout:list(type),min=0; is_stateful=true>
  2023-01-12 09:34:37.797759: I tensorflow/core/framework/op.cc:132] Op<name=RpcServer; signature=server_address:string -> server:resource; is_stateful=true>
  2023-01-12 09:34:37.797798: I tensorflow/core/framework/op.cc:132] Op<name=RpcServerRegister; signature=server:resource, method_name:string, captured_inputs: -> ; attr=Tin:list(type),default=[],min=0; attr=f:func; attr=input_specs:string,default=""; attr=output_specs:string; is_stateful=true>
  2023-01-12 09:34:37.797814: I tensorflow/core/framework/op.cc:132] Op<name=RpcServerStart; signature=server:resource -> ; is_stateful=true>
  2023-01-12 09:34:37.797833: I tensorflow/core/framework/op.cc:132] Op<name=Rsqrt; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.797850: I tensorflow/core/framework/op.cc:132] Op<name=RsqrtGrad; signature=y:T, dy:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.797915: I tensorflow/core/framework/op.cc:132] Op<name=SampleDistortedBoundingBox; signature=image_size:T, bounding_boxes:float -> begin:T, size:T, bboxes:float; attr=T:type,allowed=[DT_UINT8, DT_INT8, DT_INT16, DT_INT32, DT_INT64]; attr=seed:int,default=0; attr=seed2:int,default=0; attr=min_object_covered:float,default=0.1; attr=aspect_ratio_range:list(float),default=[0.75, 1.33]; attr=area_range:list(float),default=[0.05, 1]; attr=max_attempts:int,default=100; attr=use_image_if_no_bounding_boxes:bool,default=false; is_stateful=true>
  2023-01-12 09:34:37.797987: I tensorflow/core/framework/op.cc:132] Op<name=SampleDistortedBoundingBoxV2; signature=image_size:T, bounding_boxes:float, min_object_covered:float -> begin:T, size:T, bboxes:float; attr=T:type,allowed=[DT_UINT8, DT_INT8, DT_INT16, DT_INT32, DT_INT64]; attr=seed:int,default=0; attr=seed2:int,default=0; attr=aspect_ratio_range:list(float),default=[0.75, 1.33]; attr=area_range:list(float),default=[0.05, 1]; attr=max_attempts:int,default=100; attr=use_image_if_no_bounding_boxes:bool,default=false; is_stateful=true>
  2023-01-12 09:34:37.798032: I tensorflow/core/framework/op.cc:132] Op<name=SamplingDataset; signature=input_dataset:variant, rate:float, seed:int64, seed2:int64 -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1>
  2023-01-12 09:34:37.798052: I tensorflow/core/framework/op.cc:132] Op<name=Save; signature=filename:string, tensor_names:string, data: -> ; attr=T:list(type),min=1; is_stateful=true>
  2023-01-12 09:34:37.798069: I tensorflow/core/framework/op.cc:132] Op<name=SaveDataset; signature=input_dataset:variant, path:string, shard_func_other_args: -> ; attr=compression:string,default=""; attr=shard_func:func; attr=use_shard_func:bool,default=true; attr=Tshard_func_args:list(type),min=0; is_stateful=true>
  2023-01-12 09:34:37.798086: I tensorflow/core/framework/op.cc:132] Op<name=SaveDatasetV2; signature=input_dataset:variant, path:string, shard_func_other_args: -> handle:variant; attr=compression:string,default=""; attr=shard_func:func; attr=use_shard_func:bool,default=true; attr=Tshard_func_args:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; is_stateful=true>
  2023-01-12 09:34:37.798148: I tensorflow/core/framework/op.cc:132] Op<name=SaveSlices; signature=filename:string, tensor_names:string, shapes_and_slices:string, data: -> ; attr=T:list(type),min=1; is_stateful=true>
  2023-01-12 09:34:37.798189: I tensorflow/core/framework/op.cc:132] Op<name=SaveV2; signature=prefix:string, tensor_names:string, shape_and_slices:string, tensors: -> ; attr=dtypes:list(type),min=1; is_stateful=true>
  2023-01-12 09:34:37.798403: I tensorflow/core/framework/op.cc:132] Op<name=ScalarSummary; signature=tags:string, values:T -> summary:string; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:37.798465: I tensorflow/core/framework/op.cc:132] Op<name=ScaleAndTranslate; signature=images:T, size:int32, scale:float, translation:float -> resized_images:float; attr=T:type,allowed=[DT_INT8, DT_UINT8, DT_INT16, DT_UINT16, DT_INT32, DT_INT64, DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=kernel_type:string,default="lanczos3"; attr=antialias:bool,default=true>
  2023-01-12 09:34:37.798539: I tensorflow/core/framework/op.cc:132] Op<name=ScaleAndTranslateGrad; signature=grads:T, original_image:T, scale:float, translation:float -> output:T; attr=T:type,allowed=[DT_FLOAT]; attr=kernel_type:string,default="lanczos3"; attr=antialias:bool,default=true>
  2023-01-12 09:34:37.798622: I tensorflow/core/framework/op.cc:132] Op<name=ScanDataset; signature=input_dataset:variant, initial_state:, other_arguments: -> handle:variant; attr=f:func; attr=Tstate:list(type),min=1; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=preserve_cardinality:bool,default=false; attr=use_default_device:bool,default=true; attr=metadata:string,default="">
  2023-01-12 09:34:37.798810: I tensorflow/core/framework/op.cc:132] Op<name=ScatterAdd; signature=ref:Ref(T), indices:Tindices, updates:T -> output_ref:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=false>
  2023-01-12 09:34:37.798893: I tensorflow/core/framework/op.cc:132] Op<name=ScatterDiv; signature=ref:Ref(T), indices:Tindices, updates:T -> output_ref:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=false>
  2023-01-12 09:34:37.798946: I tensorflow/core/framework/op.cc:132] Op<name=ScatterMax; signature=ref:Ref(T), indices:Tindices, updates:T -> output_ref:Ref(T); attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=false>
  2023-01-12 09:34:37.799025: I tensorflow/core/framework/op.cc:132] Op<name=ScatterMin; signature=ref:Ref(T), indices:Tindices, updates:T -> output_ref:Ref(T); attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=false>
  2023-01-12 09:34:37.799067: I tensorflow/core/framework/op.cc:132] Op<name=ScatterMul; signature=ref:Ref(T), indices:Tindices, updates:T -> output_ref:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=false>
  2023-01-12 09:34:37.799105: I tensorflow/core/framework/op.cc:132] Op<name=ScatterNd; signature=indices:Tindices, updates:T, shape:Tindices -> output:T; attr=T:type; attr=Tindices:type,allowed=[DT_INT16, DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.799156: I tensorflow/core/framework/op.cc:132] Op<name=ScatterNdAdd; signature=ref:Ref(T), indices:Tindices, updates:T -> output_ref:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=false>
  2023-01-12 09:34:37.799218: I tensorflow/core/framework/op.cc:132] Op<name=ScatterNdMax; signature=ref:Ref(T), indices:Tindices, updates:T -> output_ref:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=false>
  2023-01-12 09:34:37.799279: I tensorflow/core/framework/op.cc:132] Op<name=ScatterNdMin; signature=ref:Ref(T), indices:Tindices, updates:T -> output_ref:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=false>
  2023-01-12 09:34:37.799344: I tensorflow/core/framework/op.cc:132] Op<name=ScatterNdNonAliasingAdd; signature=input:T, indices:Tindices, updates:T -> output:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 16534343205130372495, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64, DT_BOOL]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.799467: I tensorflow/core/framework/op.cc:132] Op<name=ScatterNdSub; signature=ref:Ref(T), indices:Tindices, updates:T -> output_ref:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=false>
  2023-01-12 09:34:37.799506: I tensorflow/core/framework/op.cc:132] Op<name=ScatterNdUpdate; signature=ref:Ref(T), indices:Tindices, updates:T -> output_ref:Ref(T); attr=T:type; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=true>
  2023-01-12 09:34:37.799639: I tensorflow/core/framework/op.cc:132] Op<name=ScatterSub; signature=ref:Ref(T), indices:Tindices, updates:T -> output_ref:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=false>
  2023-01-12 09:34:37.799679: I tensorflow/core/framework/op.cc:132] Op<name=ScatterUpdate; signature=ref:Ref(T), indices:Tindices, updates:T -> output_ref:Ref(T); attr=T:type; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=true>
  2023-01-12 09:34:37.799695: I tensorflow/core/framework/op.cc:132] Op<name=SdcaFprint; signature=input:string -> output:int64>
  2023-01-12 09:34:37.799827: I tensorflow/core/framework/op.cc:132] Op<name=SdcaOptimizer; signature=sparse_example_indices:num_sparse_features*int64, sparse_feature_indices:num_sparse_features*int64, sparse_feature_values:num_sparse_features_with_values*float, dense_features:num_dense_features*float, example_weights:float, example_labels:float, sparse_indices:num_sparse_features*int64, sparse_weights:num_sparse_features*float, dense_weights:num_dense_features*float, example_state_data:float -> out_example_state_data:float, out_delta_sparse_weights:num_sparse_features*float, out_delta_dense_weights:num_dense_features*float; attr=loss_type:string,allowed=["logistic_loss", "squared_loss", "hinge_loss", "smooth_hinge_loss", "poisson_loss"]; attr=adaptative:bool,default=false; attr=num_sparse_features:int,min=0; attr=num_sparse_features_with_values:int,min=0; attr=num_dense_features:int,min=0; attr=l1:float; attr=l2:float; attr=num_loss_partitions:int,min=1; attr=num_inner_iterations:int,min=1>
  2023-01-12 09:34:37.800214: I tensorflow/core/framework/op.cc:132] Op<name=SdcaOptimizerV2; signature=sparse_example_indices:num_sparse_features*int64, sparse_feature_indices:num_sparse_features*int64, sparse_feature_values:num_sparse_features_with_values*float, dense_features:num_dense_features*float, example_weights:float, example_labels:float, sparse_indices:num_sparse_features*int64, sparse_weights:num_sparse_features*float, dense_weights:num_dense_features*float, example_state_data:float -> out_example_state_data:float, out_delta_sparse_weights:num_sparse_features*float, out_delta_dense_weights:num_dense_features*float; attr=loss_type:string,allowed=["logistic_loss", "squared_loss", "hinge_loss", "smooth_hinge_loss", "poisson_loss"]; attr=adaptive:bool,default=false; attr=num_sparse_features:int,min=0; attr=num_sparse_features_with_values:int,min=0; attr=num_dense_features:int,min=0; attr=l1:float; attr=l2:float; attr=num_loss_partitions:int,min=1; attr=num_inner_iterations:int,min=1>
  2023-01-12 09:34:37.800448: I tensorflow/core/framework/op.cc:132] Op<name=SdcaShrinkL1; signature=weights:Ref(num_features*float) -> ; attr=num_features:int,min=0; attr=l1:float; attr=l2:float>
  2023-01-12 09:34:37.801099: I tensorflow/core/framework/op.cc:132] Op<name=SegmentMax; signature=data:T, segment_ids:Tindices -> output:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.801515: I tensorflow/core/framework/op.cc:132] Op<name=SegmentMean; signature=data:T, segment_ids:Tindices -> output:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.801626: I tensorflow/core/framework/op.cc:132] Op<name=SegmentMin; signature=data:T, segment_ids:Tindices -> output:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.801697: I tensorflow/core/framework/op.cc:132] Op<name=SegmentProd; signature=data:T, segment_ids:Tindices -> output:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.801857: I tensorflow/core/framework/op.cc:132] Op<name=SegmentSum; signature=data:T, segment_ids:Tindices -> output:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.801926: I tensorflow/core/framework/op.cc:132] Op<name=Select; signature=condition:bool, t:T, e:T -> output:T; attr=T:type>
  2023-01-12 09:34:37.801946: I tensorflow/core/framework/op.cc:132] Op<name=SelectV2; signature=condition:bool, t:T, e:T -> output:T; attr=T:type>
  2023-01-12 09:34:37.801966: I tensorflow/core/framework/op.cc:132] Op<name=SelfAdjointEig; signature=input:T -> output:T; attr=T:type,allowed=[DT_DOUBLE, DT_FLOAT, DT_HALF]>
  2023-01-12 09:34:37.949552: I tensorflow/core/framework/op.cc:132] Op<name=SelfAdjointEigV2; signature=input:T -> e:T, v:T; attr=compute_v:bool,default=true; attr=T:type,allowed=[DT_DOUBLE, DT_FLOAT, DT_HALF, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.949686: I tensorflow/core/framework/op.cc:132] Op<name=Selu; signature=features:T -> activations:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.949752: I tensorflow/core/framework/op.cc:132] Op<name=SeluGrad; signature=gradients:T, outputs:T -> backprops:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.949807: I tensorflow/core/framework/op.cc:132] Op<name=Send; signature=tensor:T -> ; attr=T:type; attr=tensor_name:string; attr=send_device:string; attr=send_device_incarnation:int; attr=recv_device:string; attr=client_terminated:bool,default=false; is_stateful=true>
  2023-01-12 09:34:37.950015: I tensorflow/core/framework/op.cc:132] Op<name=SendTPUEmbeddingGradients; signature=inputs:N*float, learning_rates:NN*float -> ; attr=N:int,min=1; attr=NN:int,default=0,min=0; attr=config:string; is_stateful=true>
  2023-01-12 09:34:37.950840: I tensorflow/core/framework/op.cc:132] Op<name=SerializeIterator; signature=resource_handle:resource -> serialized:variant; attr=external_state_policy:int,default=0; is_stateful=true>
  2023-01-12 09:34:37.950903: I tensorflow/core/framework/op.cc:132] Op<name=SerializeManySparse; signature=sparse_indices:int64, sparse_values:T, sparse_shape:int64 -> serialized_sparse:out_type; attr=T:type; attr=out_type:type,default=DT_STRING,allowed=[DT_STRING, DT_VARIANT]>
  2023-01-12 09:34:37.950933: I tensorflow/core/framework/op.cc:132] Op<name=SerializeSparse; signature=sparse_indices:int64, sparse_values:T, sparse_shape:int64 -> serialized_sparse:out_type; attr=T:type; attr=out_type:type,default=DT_STRING,allowed=[DT_STRING, DT_VARIANT]>
  2023-01-12 09:34:37.950955: I tensorflow/core/framework/op.cc:132] Op<name=SerializeTensor; signature=tensor:T -> serialized:string; attr=T:type>
  2023-01-12 09:34:37.950983: I tensorflow/core/framework/op.cc:132] Op<name=SetSize; signature=set_indices:int64, set_values:T, set_shape:int64 -> size:int32; attr=validate_indices:bool,default=true; attr=T:type,allowed=[DT_INT8, DT_INT16, DT_INT32, DT_INT64, DT_UINT8, DT_UINT16, DT_STRING]>
  2023-01-12 09:34:37.951007: I tensorflow/core/framework/op.cc:132] Op<name=SetStatsAggregatorDataset; signature=input_dataset:variant, stats_aggregator:resource, tag:string, counter_prefix:string -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; is_stateful=true>
  2023-01-12 09:34:37.951034: I tensorflow/core/framework/op.cc:132] Op<name=Shape; signature=input:T -> output:out_type; attr=T:type; attr=out_type:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.951074: I tensorflow/core/framework/op.cc:132] Op<name=ShapeN; signature=input:N*T -> output:N*out_type; attr=N:int,min=1; attr=T:type; attr=out_type:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.951183: I tensorflow/core/framework/op.cc:132] Op<name=ShardDataset; signature=input_dataset:variant, num_shards:int64, index:int64 -> handle:variant; attr=require_non_empty:bool,default=false; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=metadata:string,default="">
  2023-01-12 09:34:37.951231: I tensorflow/core/framework/op.cc:132] Op<name=ShardedFilename; signature=basename:string, shard:int32, num_shards:int32 -> filename:string>
  2023-01-12 09:34:37.951254: I tensorflow/core/framework/op.cc:132] Op<name=ShardedFilespec; signature=basename:string, num_shards:int32 -> filename:string>
  2023-01-12 09:34:37.951282: I tensorflow/core/framework/op.cc:132] Op<name=ShuffleAndRepeatDataset; signature=input_dataset:variant, buffer_size:int64, seed:int64, seed2:int64, count:int64 -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=reshuffle_each_iteration:bool,default=true; attr=metadata:string,default="">
  2023-01-12 09:34:37.951322: I tensorflow/core/framework/op.cc:132] Op<name=ShuffleAndRepeatDatasetV2; signature=input_dataset:variant, buffer_size:int64, seed:int64, seed2:int64, count:int64, seed_generator:resource -> handle:variant; attr=reshuffle_each_iteration:bool,default=true; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=metadata:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.951347: I tensorflow/core/framework/op.cc:132] Op<name=ShuffleDataset; signature=input_dataset:variant, buffer_size:int64, seed:int64, seed2:int64 -> handle:variant; attr=reshuffle_each_iteration:bool,default=true; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=metadata:string,default="">
  2023-01-12 09:34:37.951370: I tensorflow/core/framework/op.cc:132] Op<name=ShuffleDatasetV2; signature=input_dataset:variant, buffer_size:int64, seed_generator:resource -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=metadata:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.951397: I tensorflow/core/framework/op.cc:132] Op<name=ShuffleDatasetV3; signature=input_dataset:variant, buffer_size:int64, seed:int64, seed2:int64, seed_generator:resource -> handle:variant; attr=reshuffle_each_iteration:bool,default=true; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=metadata:string,default=""; is_stateful=true>
  2023-01-12 09:34:37.951414: I tensorflow/core/framework/op.cc:132] Op<name=ShutdownDistributedTPU; signature= -> ; is_stateful=true>
  2023-01-12 09:34:37.951429: I tensorflow/core/framework/op.cc:132] Op<name=ShutdownTPUSystem; signature= -> success:bool; is_stateful=true>
  2023-01-12 09:34:37.951455: I tensorflow/core/framework/op.cc:132] Op<name=Sigmoid; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.951607: I tensorflow/core/framework/op.cc:132] Op<name=SigmoidGrad; signature=y:T, dy:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.951712: I tensorflow/core/framework/op.cc:132] Op<name=Sign; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT8, DT_INT16, DT_INT32, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.951777: I tensorflow/core/framework/op.cc:132] Op<name=Simple; signature=a:int32 -> out:float>
  2023-01-12 09:34:37.951816: I tensorflow/core/framework/op.cc:132] Op<name=SimpleStruct; signature= -> a:n_a*int32; attr=n_a:int,min=0>
  2023-01-12 09:34:37.952013: I tensorflow/core/framework/op.cc:132] Op<name=Sin; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.953153: I tensorflow/core/framework/op.cc:132] Op<name=Sinh; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:37.953254: I tensorflow/core/framework/op.cc:132] Op<name=Size; signature=input:T -> output:out_type; attr=T:type; attr=out_type:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.953316: I tensorflow/core/framework/op.cc:132] Op<name=SkipDataset; signature=input_dataset:variant, count:int64 -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=metadata:string,default="">
  2023-01-12 09:34:37.953445: I tensorflow/core/framework/op.cc:132] Op<name=Skipgram; signature= -> vocab_word:string, vocab_freq:int32, words_per_epoch:int64, current_epoch:int32, total_words_processed:int64, examples:int32, labels:int32; attr=filename:string; attr=batch_size:int; attr=window_size:int,default=5; attr=min_count:int,default=5; attr=subsample:float,default=0.001; is_stateful=true>
  2023-01-12 09:34:37.953759: I tensorflow/core/framework/op.cc:132] Op<name=SleepDataset; signature=input_dataset:variant, sleep_microseconds:int64 -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1>
  2023-01-12 09:34:37.953819: I tensorflow/core/framework/op.cc:132] Op<name=SleepIdentityOp; signature=sleep_seconds:int32, input:T -> output:T; attr=T:type>
  2023-01-12 09:34:37.953903: I tensorflow/core/framework/op.cc:132] Op<name=SleepOp; signature=sleep_seconds:int32 -> >
  2023-01-12 09:34:37.953961: I tensorflow/core/framework/op.cc:132] Op<name=Slice; signature=input:T, begin:Index, size:Index -> output:T; attr=T:type; attr=Index:type,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.954003: I tensorflow/core/framework/op.cc:132] Op<name=SlidingWindowDataset; signature=input_dataset:variant, window_size:int64, window_shift:int64, window_stride:int64 -> handle:variant; attr=drop_remainder:bool,default=true; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1>
  2023-01-12 09:34:37.970318: I tensorflow/core/framework/op.cc:132] Op<name=Snapshot; signature=input:T -> output:T; attr=T:type>
  2023-01-12 09:34:37.970737: I tensorflow/core/framework/op.cc:132] Op<name=SnapshotDataset; signature=input_dataset:variant, path:string -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=compression:string,default=""; attr=reader_path_prefix:string,default=""; attr=writer_path_prefix:string,default=""; attr=shard_size_bytes:int,default=10737418240; attr=pending_snapshot_expiry_seconds:int,default=86400; attr=num_reader_threads:int,default=1; attr=reader_buffer_size:int,default=1; attr=num_writer_threads:int,default=1; attr=writer_buffer_size:int,default=1; attr=shuffle_on_read:bool,default=false; attr=seed:int,default=0; attr=seed2:int,default=0; attr=mode:string,default="auto"; attr=snapshot_name:string,default="">
  2023-01-12 09:34:37.970841: I tensorflow/core/framework/op.cc:132] Op<name=SnapshotDatasetReader; signature=shard_dir:string, start_index:int64 -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=compression:string,default=""; attr=version:int>
  2023-01-12 09:34:37.971818: I tensorflow/core/framework/op.cc:132] Op<name=SnapshotDatasetV2; signature=input_dataset:variant, path:string, reader_func_other_args:, shard_func_other_args: -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=compression:string,default=""; attr=reader_prefix:string,default=""; attr=writer_prefix:string,default=""; attr=hash_valid:bool,default=false; attr=hash:int,default=0; attr=reader_func:func; attr=shard_func:func; attr=Treader_func_args:list(type),min=0; attr=Tshard_func_args:list(type),min=0; attr=metadata:string,default="">
  2023-01-12 09:34:37.971869: I tensorflow/core/framework/op.cc:132] Op<name=SnapshotNestedDatasetReader; signature=inputs:N*variant -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=N:int,min=1>
  2023-01-12 09:34:37.971908: I tensorflow/core/framework/op.cc:132] Op<name=SobolSample; signature=dim:int32, num_results:int32, skip:int32 -> samples:dtype; attr=dtype:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.971933: I tensorflow/core/framework/op.cc:132] Op<name=Softmax; signature=logits:T -> softmax:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.971967: I tensorflow/core/framework/op.cc:132] Op<name=SoftmaxCrossEntropyWithLogits; signature=features:T, labels:T -> loss:T, backprop:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.972061: I tensorflow/core/framework/op.cc:132] Op<name=Softplus; signature=features:T -> activations:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.972089: I tensorflow/core/framework/op.cc:132] Op<name=SoftplusGrad; signature=gradients:T, features:T -> backprops:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.972112: I tensorflow/core/framework/op.cc:132] Op<name=Softsign; signature=features:T -> activations:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.972238: I tensorflow/core/framework/op.cc:132] Op<name=SoftsignGrad; signature=gradients:T, features:T -> backprops:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:37.972297: I tensorflow/core/framework/op.cc:132] Op<name=SpaceToBatch; signature=input:T, paddings:Tpaddings -> output:T; attr=T:type; attr=Tpaddings:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=block_size:int,min=2>
  2023-01-12 09:34:37.972342: I tensorflow/core/framework/op.cc:132] Op<name=SpaceToBatchND; signature=input:T, block_shape:Tblock_shape, paddings:Tpaddings -> output:T; attr=T:type; attr=Tblock_shape:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=Tpaddings:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:37.983973: I tensorflow/core/framework/op.cc:132] Op<name=SpaceToDepth; signature=input:T -> output:T; attr=T:type; attr=block_size:int,min=2; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW", "NCHW_VECT_C"]>
  2023-01-12 09:34:37.984378: I tensorflow/core/framework/op.cc:132] Op<name=SparseAccumulatorApplyGradient; signature=handle:Ref(string), local_step:int64, gradient_indices:int64, gradient_values:dtype, gradient_shape:int64 -> ; attr=dtype:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=has_known_shape:bool>
  2023-01-12 09:34:37.984467: I tensorflow/core/framework/op.cc:132] Op<name=SparseAccumulatorTakeGradient; signature=handle:Ref(string), num_required:int32 -> indices:int64, values:dtype, shape:int64; attr=dtype:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:37.984542: I tensorflow/core/framework/op.cc:132] Op<name=SparseAdd; signature=a_indices:int64, a_values:T, a_shape:int64, b_indices:int64, b_values:T, b_shape:int64, thresh:Treal -> sum_indices:int64, sum_values:T, sum_shape:int64; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Treal:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:37.984682: I tensorflow/core/framework/op.cc:132] Op<name=SparseAddGrad; signature=backprop_val_grad:T, a_indices:int64, b_indices:int64, sum_indices:int64 -> a_val_grad:T, b_val_grad:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:37.984732: I tensorflow/core/framework/op.cc:132] Op<name=SparseApplyAdadelta; signature=var:Ref(T), accum:Ref(T), accum_update:Ref(T), lr:T, rho:T, epsilon:T, grad:T, indices:Tindices -> out:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=false>
  2023-01-12 09:34:37.984776: I tensorflow/core/framework/op.cc:132] Op<name=SparseApplyAdagrad; signature=var:Ref(T), accum:Ref(T), lr:T, grad:T, indices:Tindices -> out:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=false; attr=update_slots:bool,default=true>
  2023-01-12 09:34:37.984831: I tensorflow/core/framework/op.cc:132] Op<name=SparseApplyAdagradDA; signature=var:Ref(T), gradient_accumulator:Ref(T), gradient_squared_accumulator:Ref(T), grad:T, indices:Tindices, lr:T, l1:T, l2:T, global_step:int64 -> out:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=false>
  2023-01-12 09:34:37.984885: I tensorflow/core/framework/op.cc:132] Op<name=SparseApplyAdagradV2; signature=var:Ref(T), accum:Ref(T), lr:T, epsilon:T, grad:T, indices:Tindices -> out:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=false; attr=update_slots:bool,default=true>
  2023-01-12 09:34:37.999042: I tensorflow/core/framework/op.cc:132] Op<name=SparseApplyCenteredRMSProp; signature=var:Ref(T), mg:Ref(T), ms:Ref(T), mom:Ref(T), lr:T, rho:T, momentum:T, epsilon:T, grad:T, indices:Tindices -> out:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=false>
  2023-01-12 09:34:38.002014: I tensorflow/core/framework/op.cc:132] Op<name=SparseApplyFtrl; signature=var:Ref(T), accum:Ref(T), linear:Ref(T), grad:T, indices:Tindices, lr:T, l1:T, l2:T, lr_power:T -> out:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=false; attr=multiply_linear_by_lr:bool,default=false>
  2023-01-12 09:34:38.002430: I tensorflow/core/framework/op.cc:132] Op<name=SparseApplyFtrlV2; signature=var:Ref(T), accum:Ref(T), linear:Ref(T), grad:T, indices:Tindices, lr:T, l1:T, l2:T, l2_shrinkage:T, lr_power:T -> out:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=false; attr=multiply_linear_by_lr:bool,default=false>
  2023-01-12 09:34:38.002939: I tensorflow/core/framework/op.cc:132] Op<name=SparseApplyMomentum; signature=var:Ref(T), accum:Ref(T), lr:T, grad:T, indices:Tindices, momentum:T -> out:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=false; attr=use_nesterov:bool,default=false>
  2023-01-12 09:34:38.003080: I tensorflow/core/framework/op.cc:132] Op<name=SparseApplyProximalAdagrad; signature=var:Ref(T), accum:Ref(T), lr:T, l1:T, l2:T, grad:T, indices:Tindices -> out:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=false>
  2023-01-12 09:34:38.003198: I tensorflow/core/framework/op.cc:132] Op<name=SparseApplyProximalGradientDescent; signature=var:Ref(T), alpha:T, l1:T, l2:T, grad:T, indices:Tindices -> out:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=false>
  2023-01-12 09:34:38.003605: I tensorflow/core/framework/op.cc:132] Op<name=SparseApplyRMSProp; signature=var:Ref(T), ms:Ref(T), mom:Ref(T), lr:T, rho:T, momentum:T, epsilon:T, grad:T, indices:Tindices -> out:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=use_locking:bool,default=false>
  2023-01-12 09:34:38.003680: I tensorflow/core/framework/op.cc:132] Op<name=SparseBincount; signature=indices:int64, values:Tidx, dense_shape:int64, size:Tidx, weights:T -> output:T; attr=Tidx:type,allowed=[DT_INT32, DT_INT64]; attr=T:type,allowed=[DT_INT32, DT_INT64, DT_FLOAT, DT_DOUBLE]; attr=binary_output:bool,default=false>
  2023-01-12 09:34:38.019774: I tensorflow/core/framework/op.cc:132] Op<name=SparseConcat; signature=indices:N*int64, values:N*T, shapes:N*int64 -> output_indices:int64, output_values:T, output_shape:int64; attr=concat_dim:int; attr=N:int,min=2; attr=T:type>
  2023-01-12 09:34:38.019987: I tensorflow/core/framework/op.cc:132] Op<name=SparseConditionalAccumulator; signature= -> handle:Ref(string); attr=dtype:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=shape:shape; attr=container:string,default=""; attr=shared_name:string,default=""; attr=reduction_type:string,default="MEAN",allowed=["MEAN", "SUM"]; is_stateful=true>
  2023-01-12 09:34:38.020045: I tensorflow/core/framework/op.cc:132] Op<name=SparseCountSparseOutput; signature=indices:int64, values:T, dense_shape:int64, weights:output_type -> output_indices:int64, output_values:output_type, output_dense_shape:int64; attr=T:type,allowed=[DT_INT32, DT_INT64]; attr=minlength:int,default=-1,min=-1; attr=maxlength:int,default=-1,min=-1; attr=binary_output:bool; attr=output_type:type,allowed=[DT_INT32, DT_INT64, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:38.020090: I tensorflow/core/framework/op.cc:132] Op<name=SparseCross; signature=indices:N*int64, values:, shapes:N*int64, dense_inputs: -> output_indices:int64, output_values:out_type, output_shape:int64; attr=N:int,min=0; attr=hashed_output:bool; attr=num_buckets:int,min=0; attr=hash_key:int; attr=sparse_types:list(type),min=0,allowed=[DT_INT64, DT_STRING]; attr=dense_types:list(type),min=0,allowed=[DT_INT64, DT_STRING]; attr=out_type:type,allowed=[DT_INT64, DT_STRING]; attr=internal_type:type,allowed=[DT_INT64, DT_STRING]>
  2023-01-12 09:34:38.020196: I tensorflow/core/framework/op.cc:132] Op<name=SparseCrossHashed; signature=indices:N*int64, values:, shapes:N*int64, dense_inputs:, num_buckets:int64, strong_hash:bool, salt:int64 -> output_indices:int64, output_values:int64, output_shape:int64; attr=N:int,min=0; attr=sparse_types:list(type),min=0,allowed=[DT_INT64, DT_STRING]; attr=dense_types:list(type),min=0,allowed=[DT_INT64, DT_STRING]>
  2023-01-12 09:34:38.020286: I tensorflow/core/framework/op.cc:132] Op<name=SparseCrossV2; signature=indices:N*int64, values:, shapes:N*int64, dense_inputs:, sep:string -> output_indices:int64, output_values:string, output_shape:int64; attr=N:int,min=0; attr=sparse_types:list(type),min=0,allowed=[DT_INT64, DT_STRING]; attr=dense_types:list(type),min=0,allowed=[DT_INT64, DT_STRING]>
  2023-01-12 09:34:38.020713: I tensorflow/core/framework/op.cc:132] Op<name=SparseDenseCwiseAdd; signature=sp_indices:int64, sp_values:T, sp_shape:int64, dense:T -> output:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:38.020827: I tensorflow/core/framework/op.cc:132] Op<name=SparseDenseCwiseDiv; signature=sp_indices:int64, sp_values:T, sp_shape:int64, dense:T -> output:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:38.020870: I tensorflow/core/framework/op.cc:132] Op<name=SparseDenseCwiseMul; signature=sp_indices:int64, sp_values:T, sp_shape:int64, dense:T -> output:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:38.020910: I tensorflow/core/framework/op.cc:132] Op<name=SparseFillEmptyRows; signature=indices:int64, values:T, dense_shape:int64, default_value:T -> output_indices:int64, output_values:T, empty_row_indicator:bool, reverse_index_map:int64; attr=T:type>
  2023-01-12 09:34:38.020947: I tensorflow/core/framework/op.cc:132] Op<name=SparseFillEmptyRowsGrad; signature=reverse_index_map:int64, grad_values:T -> d_values:T, d_default_value:T; attr=T:type>
  2023-01-12 09:34:38.020992: I tensorflow/core/framework/op.cc:132] Op<name=SparseMatMul; signature=a:Ta, b:Tb -> product:float; attr=transpose_a:bool,default=false; attr=transpose_b:bool,default=false; attr=a_is_sparse:bool,default=false; attr=b_is_sparse:bool,default=false; attr=Ta:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_BFLOAT16]; attr=Tb:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_BFLOAT16]>
  2023-01-12 09:34:38.024058: I tensorflow/core/framework/op.cc:132] Op<name=SparseMatrixAdd; signature=a:variant, b:variant, alpha:T, beta:T -> c:variant; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:38.025337: I tensorflow/core/framework/op.cc:132] Op<name=SparseMatrixMatMul; signature=a:variant, b:T -> output:T; attr=T:type; attr=transpose_a:bool,default=false; attr=transpose_b:bool,default=false; attr=adjoint_a:bool,default=false; attr=adjoint_b:bool,default=false; attr=transpose_output:bool,default=false; attr=conjugate_output:bool,default=false>
  2023-01-12 09:34:38.025661: I tensorflow/core/framework/op.cc:132] Op<name=SparseMatrixMul; signature=a:variant, b:T -> output:variant; attr=T:type>
  2023-01-12 09:34:38.025818: I tensorflow/core/framework/op.cc:132] Op<name=SparseMatrixNNZ; signature=sparse_matrix:variant -> nnz:int32>
  2023-01-12 09:34:38.025879: I tensorflow/core/framework/op.cc:132] Op<name=SparseMatrixOrderingAMD; signature=input:variant -> output:int32>
  2023-01-12 09:34:38.025942: I tensorflow/core/framework/op.cc:132] Op<name=SparseMatrixSoftmax; signature=logits:variant -> softmax:variant; attr=type:type,allowed=[DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:38.026047: I tensorflow/core/framework/op.cc:132] Op<name=SparseMatrixSoftmaxGrad; signature=softmax:variant, grad_softmax:variant -> gradient:variant; attr=type:type,allowed=[DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:38.026240: I tensorflow/core/framework/op.cc:132] Op<name=SparseMatrixSparseCholesky; signature=input:variant, permutation:int32 -> output:variant; attr=type:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:38.026494: I tensorflow/core/framework/op.cc:132] Op<name=SparseMatrixSparseMatMul; signature=a:variant, b:variant -> c:variant; attr=type:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]; attr=transpose_a:bool,default=false; attr=transpose_b:bool,default=false; attr=adjoint_a:bool,default=false; attr=adjoint_b:bool,default=false>
  2023-01-12 09:34:38.026672: I tensorflow/core/framework/op.cc:132] Op<name=SparseMatrixTranspose; signature=input:variant -> output:variant; attr=conjugate:bool,default=false; attr=type:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:38.026823: I tensorflow/core/framework/op.cc:132] Op<name=SparseMatrixZeros; signature=dense_shape:int64 -> sparse_matrix:variant; attr=type:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:38.026968: I tensorflow/core/framework/op.cc:132] Op<name=SparseReduceMax; signature=input_indices:int64, input_values:T, input_shape:int64, reduction_axes:int32 -> output:T; attr=keep_dims:bool,default=false; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:38.027212: I tensorflow/core/framework/op.cc:132] Op<name=SparseReduceMaxSparse; signature=input_indices:int64, input_values:T, input_shape:int64, reduction_axes:int32 -> output_indices:int64, output_values:T, output_shape:int64; attr=keep_dims:bool,default=false; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:38.027440: I tensorflow/core/framework/op.cc:132] Op<name=SparseReduceSum; signature=input_indices:int64, input_values:T, input_shape:int64, reduction_axes:int32 -> output:T; attr=keep_dims:bool,default=false; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:38.027763: I tensorflow/core/framework/op.cc:132] Op<name=SparseReduceSumSparse; signature=input_indices:int64, input_values:T, input_shape:int64, reduction_axes:int32 -> output_indices:int64, output_values:T, output_shape:int64; attr=keep_dims:bool,default=false; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:38.027828: I tensorflow/core/framework/op.cc:132] Op<name=SparseReorder; signature=input_indices:int64, input_values:T, input_shape:int64 -> output_indices:int64, output_values:T; attr=T:type>
  2023-01-12 09:34:38.027922: I tensorflow/core/framework/op.cc:132] Op<name=SparseReshape; signature=input_indices:int64, input_shape:int64, new_shape:int64 -> output_indices:int64, output_shape:int64>
  2023-01-12 09:34:38.028035: I tensorflow/core/framework/op.cc:132] Op<name=SparseSegmentMean; signature=data:T, indices:Tidx, segment_ids:Tsegmentids -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=Tsegmentids:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.028120: I tensorflow/core/framework/op.cc:132] Op<name=SparseSegmentMeanGrad; signature=grad:T, indices:Tidx, segment_ids:Tsegmentids, output_dim0:int32 -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=Tsegmentids:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.028304: I tensorflow/core/framework/op.cc:132] Op<name=SparseSegmentMeanWithNumSegments; signature=data:T, indices:Tidx, segment_ids:Tsegmentids, num_segments:Tnumsegments -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=Tnumsegments:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=Tsegmentids:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.028432: I tensorflow/core/framework/op.cc:132] Op<name=SparseSegmentSqrtN; signature=data:T, indices:Tidx, segment_ids:Tsegmentids -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=Tsegmentids:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.028578: I tensorflow/core/framework/op.cc:132] Op<name=SparseSegmentSqrtNGrad; signature=grad:T, indices:Tidx, segment_ids:Tsegmentids, output_dim0:int32 -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=Tsegmentids:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.028821: I tensorflow/core/framework/op.cc:132] Op<name=SparseSegmentSqrtNWithNumSegments; signature=data:T, indices:Tidx, segment_ids:Tsegmentids, num_segments:Tnumsegments -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=Tnumsegments:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=Tsegmentids:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.029080: I tensorflow/core/framework/op.cc:132] Op<name=SparseSegmentSum; signature=data:T, indices:Tidx, segment_ids:Tsegmentids -> output:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=Tsegmentids:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.035544: I tensorflow/core/framework/op.cc:132] Op<name=SparseSegmentSumGrad; signature=grad:T, indices:Tidx, segment_ids:Tsegmentids, output_dim0:int32 -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=Tsegmentids:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.035854: I tensorflow/core/framework/op.cc:132] Op<name=SparseSegmentSumWithNumSegments; signature=data:T, indices:Tidx, segment_ids:Tsegmentids, num_segments:Tnumsegments -> output:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=Tnumsegments:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=Tsegmentids:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.036118: I tensorflow/core/framework/op.cc:132] Op<name=SparseSlice; signature=indices:int64, values:T, shape:int64, start:int64, size:int64 -> output_indices:int64, output_values:T, output_shape:int64; attr=T:type>
  2023-01-12 09:34:38.036299: I tensorflow/core/framework/op.cc:132] Op<name=SparseSliceGrad; signature=backprop_val_grad:T, input_indices:int64, input_start:int64, output_indices:int64 -> val_grad:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:38.036363: I tensorflow/core/framework/op.cc:132] Op<name=SparseSoftmax; signature=sp_indices:int64, sp_values:T, sp_shape:int64 -> output:T; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:38.036431: I tensorflow/core/framework/op.cc:132] Op<name=SparseSoftmaxCrossEntropyWithLogits; signature=features:T, labels:Tlabels -> loss:T, backprop:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]; attr=Tlabels:type,default=DT_INT64,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.036505: I tensorflow/core/framework/op.cc:132] Op<name=SparseSparseMaximum; signature=a_indices:int64, a_values:T, a_shape:int64, b_indices:int64, b_values:T, b_shape:int64 -> output_indices:int64, output_values:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:38.036706: I tensorflow/core/framework/op.cc:132] Op<name=SparseSparseMinimum; signature=a_indices:int64, a_values:T, a_shape:int64, b_indices:int64, b_values:T, b_shape:int64 -> output_indices:int64, output_values:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:38.036782: I tensorflow/core/framework/op.cc:132] Op<name=SparseSplit; signature=split_dim:int64, indices:int64, values:T, shape:int64 -> output_indices:num_split*int64, output_values:num_split*T, output_shape:num_split*int64; attr=num_split:int,min=1; attr=T:type>
  2023-01-12 09:34:38.036824: I tensorflow/core/framework/op.cc:132] Op<name=SparseTensorDenseAdd; signature=a_indices:Tindices, a_values:T, a_shape:Tindices, b:T -> output:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.036851: I tensorflow/core/framework/op.cc:132] Op<name=SparseTensorDenseMatMul; signature=a_indices:Tindices, a_values:T, a_shape:int64, b:T -> product:T; attr=T:type; attr=Tindices:type,default=DT_INT64,allowed=[DT_INT32, DT_INT64]; attr=adjoint_a:bool,default=false; attr=adjoint_b:bool,default=false>
  2023-01-12 09:34:38.036878: I tensorflow/core/framework/op.cc:132] Op<name=SparseTensorSliceDataset; signature=indices:int64, values:Tvalues, dense_shape:int64 -> handle:variant; attr=Tvalues:type; is_stateful=true>
  2023-01-12 09:34:38.036932: I tensorflow/core/framework/op.cc:132] Op<name=SparseTensorToCSRSparseMatrix; signature=indices:int64, values:T, dense_shape:int64 -> sparse_matrix:variant; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:38.036971: I tensorflow/core/framework/op.cc:132] Op<name=SparseToDense; signature=sparse_indices:Tindices, output_shape:Tindices, sparse_values:T, default_value:T -> dense:T; attr=validate_indices:bool,default=true; attr=T:type; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.037018: I tensorflow/core/framework/op.cc:132] Op<name=SparseToSparseSetOperation; signature=set1_indices:int64, set1_values:T, set1_shape:int64, set2_indices:int64, set2_values:T, set2_shape:int64 -> result_indices:int64, result_values:T, result_shape:int64; attr=set_operation:string; attr=validate_indices:bool,default=true; attr=T:type,allowed=[DT_INT8, DT_INT16, DT_INT32, DT_INT64, DT_UINT8, DT_UINT16, DT_STRING]>
  2023-01-12 09:34:38.037114: I tensorflow/core/framework/op.cc:132] Op<name=Spence; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:38.037264: I tensorflow/core/framework/op.cc:132] Op<name=Split; signature=split_dim:int32, value:T -> output:num_split*T; attr=num_split:int,min=1; attr=T:type>
  2023-01-12 09:34:38.037355: I tensorflow/core/framework/op.cc:132] Op<name=SplitV; signature=value:T, size_splits:Tlen, split_dim:int32 -> output:num_split*T; attr=num_split:int,min=1; attr=T:type; attr=Tlen:type,default=DT_INT64,allowed=[DT_INT8, DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.037531: I tensorflow/core/framework/op.cc:132] Op<name=SqlDataset; signature=driver_name:string, data_source_name:string, query:string -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; is_stateful=true>
  2023-01-12 09:34:38.037591: I tensorflow/core/framework/op.cc:132] Op<name=Sqrt; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:38.037733: I tensorflow/core/framework/op.cc:132] Op<name=SqrtGrad; signature=y:T, dy:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:38.037895: I tensorflow/core/framework/op.cc:132] Op<name=Square; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT8, DT_INT16, DT_INT32, DT_INT64, DT_UINT8, DT_UINT16, DT_UINT32, DT_UINT64, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:38.038008: I tensorflow/core/framework/op.cc:132] Op<name=SquaredDifference; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]; is_commutative=true>
  2023-01-12 09:34:38.038054: I tensorflow/core/framework/op.cc:132] Op<name=Squeeze; signature=input:T -> output:T; attr=T:type; attr=squeeze_dims:list(int),default=[],min=0>
  2023-01-12 09:34:38.038150: I tensorflow/core/framework/op.cc:132] Op<name=Stack; signature= -> handle:Ref(string); attr=elem_type:type; attr=stack_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:38.038184: I tensorflow/core/framework/op.cc:132] Op<name=StackClose; signature=handle:Ref(string) -> >
  2023-01-12 09:34:38.038203: I tensorflow/core/framework/op.cc:132] Op<name=StackCloseV2; signature=handle:resource -> ; is_stateful=true>
  2023-01-12 09:34:38.038225: I tensorflow/core/framework/op.cc:132] Op<name=StackPop; signature=handle:Ref(string) -> elem:elem_type; attr=elem_type:type>
  2023-01-12 09:34:38.038270: I tensorflow/core/framework/op.cc:132] Op<name=StackPopV2; signature=handle:resource -> elem:elem_type; attr=elem_type:type; is_stateful=true>
  2023-01-12 09:34:38.038320: I tensorflow/core/framework/op.cc:132] Op<name=StackPush; signature=handle:Ref(string), elem:T -> output:T; attr=T:type; attr=swap_memory:bool,default=false>
  2023-01-12 09:34:38.038352: I tensorflow/core/framework/op.cc:132] Op<name=StackPushV2; signature=handle:resource, elem:T -> output:T; attr=T:type; attr=swap_memory:bool,default=false; is_stateful=true>
  2023-01-12 09:34:38.043349: I tensorflow/core/framework/op.cc:132] Op<name=StackV2; signature=max_size:int32 -> handle:resource; attr=elem_type:type; attr=stack_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:38.044004: I tensorflow/core/framework/op.cc:132] Op<name=Stage; signature=values: -> ; attr=capacity:int,default=0,min=0; attr=memory_limit:int,default=0,min=0; attr=dtypes:list(type),min=1; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:38.044117: I tensorflow/core/framework/op.cc:132] Op<name=StageClear; signature= -> ; attr=capacity:int,default=0,min=0; attr=memory_limit:int,default=0,min=0; attr=dtypes:list(type); attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:38.044172: I tensorflow/core/framework/op.cc:132] Op<name=StagePeek; signature=index:int32 -> values:; attr=capacity:int,default=0,min=0; attr=memory_limit:int,default=0,min=0; attr=dtypes:list(type),min=1; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:38.044209: I tensorflow/core/framework/op.cc:132] Op<name=StageSize; signature= -> size:int32; attr=capacity:int,default=0,min=0; attr=memory_limit:int,default=0,min=0; attr=dtypes:list(type); attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:38.044252: I tensorflow/core/framework/op.cc:132] Op<name=StatefulPartitionedCall; signature=args: -> output:; attr=Tin:list(type),min=0; attr=Tout:list(type),min=0; attr=f:func; attr=config:string,default=""; attr=config_proto:string,default=""; attr=executor_type:string,default=""; is_stateful=true; is_distributed_communication=true>
  2023-01-12 09:34:38.044331: I tensorflow/core/framework/op.cc:132] Op<name=StatefulRandomBinomial; signature=resource:resource, algorithm:int64, shape:S, counts:T, probs:T -> output:dtype; attr=S:type,allowed=[DT_INT32, DT_INT64]; attr=T:type,default=DT_DOUBLE,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64]; attr=dtype:type,default=DT_INT64,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64]; is_stateful=true>
  2023-01-12 09:34:38.044413: I tensorflow/core/framework/op.cc:132] Op<name=StatefulStandardNormal; signature=resource:resource, shape:shape_dtype -> output:dtype; attr=dtype:type,default=DT_FLOAT; attr=shape_dtype:type,default=DT_INT64; is_stateful=true>
  2023-01-12 09:34:38.044485: I tensorflow/core/framework/op.cc:132] Op<name=StatefulStandardNormalV2; signature=resource:resource, algorithm:int64, shape:shape_dtype -> output:dtype; attr=dtype:type,default=DT_FLOAT; attr=shape_dtype:type,default=DT_INT64; is_stateful=true>
  2023-01-12 09:34:38.044632: I tensorflow/core/framework/op.cc:132] Op<name=StatefulTruncatedNormal; signature=resource:resource, algorithm:int64, shape:shape_dtype -> output:dtype; attr=dtype:type,default=DT_FLOAT; attr=shape_dtype:type,default=DT_INT64; is_stateful=true>
  2023-01-12 09:34:38.044690: I tensorflow/core/framework/op.cc:132] Op<name=StatefulUniform; signature=resource:resource, algorithm:int64, shape:shape_dtype -> output:dtype; attr=dtype:type,default=DT_FLOAT; attr=shape_dtype:type,default=DT_INT64; is_stateful=true>
  2023-01-12 09:34:38.044737: I tensorflow/core/framework/op.cc:132] Op<name=StatefulUniformFullInt; signature=resource:resource, algorithm:int64, shape:shape_dtype -> output:dtype; attr=dtype:type,default=DT_UINT64; attr=shape_dtype:type,default=DT_INT64; is_stateful=true>
  2023-01-12 09:34:38.044796: I tensorflow/core/framework/op.cc:132] Op<name=StatefulUniformInt; signature=resource:resource, algorithm:int64, shape:shape_dtype, minval:dtype, maxval:dtype -> output:dtype; attr=dtype:type,default=DT_INT64; attr=shape_dtype:type,default=DT_INT64; is_stateful=true>
  2023-01-12 09:34:38.044893: I tensorflow/core/framework/op.cc:132] Op<name=StatelessCase; signature=branch_index:int32, input: -> output:; attr=Tin:list(type),min=0; attr=Tout:list(type),min=0; attr=branches:list(func),min=1; attr=output_shapes:list(shape),default=[]>
  2023-01-12 09:34:38.045073: I tensorflow/core/framework/op.cc:132] Op<name=StatelessIf; signature=cond:Tcond, input: -> output:; attr=Tcond:type; attr=Tin:list(type),min=0; attr=Tout:list(type),min=0; attr=then_branch:func; attr=else_branch:func; attr=output_shapes:list(shape),default=[]>
  2023-01-12 09:34:38.045506: I tensorflow/core/framework/op.cc:132] Op<name=StatelessMultinomial; signature=logits:T, num_samples:int32, seed:Tseed -> output:output_dtype; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tseed:type,default=DT_INT64,allowed=[DT_INT32, DT_INT64]; attr=output_dtype:type,default=DT_INT64,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.169974: I tensorflow/core/framework/op.cc:132] Op<name=StatelessParameterizedTruncatedNormal; signature=shape:S, seed:Tseed, means:dtype, stddevs:dtype, minvals:dtype, maxvals:dtype -> output:dtype; attr=S:type,allowed=[DT_INT32, DT_INT64]; attr=Tseed:type,default=DT_INT64,allowed=[DT_INT32, DT_INT64]; attr=dtype:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:38.170126: I tensorflow/core/framework/op.cc:132] Op<name=StatelessRandomBinomial; signature=shape:S, seed:Tseed, counts:T, probs:T -> output:dtype; attr=S:type,allowed=[DT_INT32, DT_INT64]; attr=Tseed:type,default=DT_INT64,allowed=[DT_INT32, DT_INT64]; attr=T:type,default=DT_DOUBLE,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64]; attr=dtype:type,default=DT_INT64,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.170233: I tensorflow/core/framework/op.cc:132] Op<name=StatelessRandomGammaV2; signature=shape:T, seed:Tseed, alpha:dtype -> output:dtype; attr=dtype:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=T:type,allowed=[DT_INT32, DT_INT64]; attr=Tseed:type,default=DT_INT64,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.170318: I tensorflow/core/framework/op.cc:132] Op<name=StatelessRandomGetAlg; signature= -> alg:int32; is_stateful=true>
  2023-01-12 09:34:38.170385: I tensorflow/core/framework/op.cc:132] Op<name=StatelessRandomGetKeyCounter; signature=seed:Tseed -> key:uint64, counter:uint64; attr=Tseed:type,default=DT_INT64,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.170578: I tensorflow/core/framework/op.cc:132] Op<name=StatelessRandomGetKeyCounterAlg; signature=seed:Tseed -> key:uint64, counter:uint64, alg:int32; attr=Tseed:type,default=DT_INT64,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.170708: I tensorflow/core/framework/op.cc:132] Op<name=StatelessRandomNormal; signature=shape:T, seed:Tseed -> output:dtype; attr=dtype:type,default=DT_FLOAT,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]; attr=T:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=Tseed:type,default=DT_INT64,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.170865: I tensorflow/core/framework/op.cc:132] Op<name=StatelessRandomNormalV2; signature=shape:Tshape, key:uint64, counter:uint64, alg:int32 -> output:dtype; attr=dtype:type,default=DT_FLOAT,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]; attr=Tshape:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.171016: I tensorflow/core/framework/op.cc:132] Op<name=StatelessRandomPoisson; signature=shape:T, seed:Tseed, lam:Rtype -> output:dtype; attr=Rtype:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64]; attr=dtype:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64]; attr=T:type,allowed=[DT_INT32, DT_INT64]; attr=Tseed:type,default=DT_INT64,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.171164: I tensorflow/core/framework/op.cc:132] Op<name=StatelessRandomUniform; signature=shape:T, seed:Tseed -> output:dtype; attr=dtype:type,default=DT_FLOAT,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]; attr=T:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=Tseed:type,default=DT_INT64,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.171291: I tensorflow/core/framework/op.cc:132] Op<name=StatelessRandomUniformFullInt; signature=shape:T, seed:Tseed -> output:dtype; attr=dtype:type,default=DT_UINT64,allowed=[DT_INT32, DT_INT64, DT_UINT32, DT_UINT64]; attr=T:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=Tseed:type,default=DT_INT64,allowed=[DT_INT32, DT_INT64, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:38.189754: I tensorflow/core/framework/op.cc:132] Op<name=StatelessRandomUniformFullIntV2; signature=shape:Tshape, key:uint64, counter:uint64, alg:int32 -> output:dtype; attr=dtype:type,default=DT_UINT64,allowed=[DT_INT32, DT_INT64, DT_UINT32, DT_UINT64]; attr=Tshape:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.189840: I tensorflow/core/framework/op.cc:132] Op<name=StatelessRandomUniformInt; signature=shape:T, seed:Tseed, minval:dtype, maxval:dtype -> output:dtype; attr=dtype:type,allowed=[DT_INT32, DT_INT64]; attr=T:type,allowed=[DT_INT32, DT_INT64]; attr=Tseed:type,default=DT_INT64,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.189867: I tensorflow/core/framework/op.cc:132] Op<name=StatelessRandomUniformIntV2; signature=shape:Tshape, key:uint64, counter:uint64, alg:int32, minval:dtype, maxval:dtype -> output:dtype; attr=dtype:type,allowed=[DT_INT32, DT_INT64, DT_UINT32, DT_UINT64]; attr=Tshape:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.189939: I tensorflow/core/framework/op.cc:132] Op<name=StatelessRandomUniformV2; signature=shape:Tshape, key:uint64, counter:uint64, alg:int32 -> output:dtype; attr=dtype:type,default=DT_FLOAT,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]; attr=Tshape:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.190004: I tensorflow/core/framework/op.cc:132] Op<name=StatelessSampleDistortedBoundingBox; signature=image_size:T, bounding_boxes:float, min_object_covered:float, seed:Tseed -> begin:T, size:T, bboxes:float; attr=T:type,allowed=[DT_UINT8, DT_INT8, DT_INT16, DT_INT32, DT_INT64]; attr=Tseed:type,allowed=[DT_INT32, DT_INT64]; attr=aspect_ratio_range:list(float),default=[0.75, 1.33]; attr=area_range:list(float),default=[0.05, 1]; attr=max_attempts:int,default=100; attr=use_image_if_no_bounding_boxes:bool,default=false>
  2023-01-12 09:34:38.190059: I tensorflow/core/framework/op.cc:132] Op<name=StatelessShuffle; signature=value:T, key:uint64, counter:uint64, alg:int32 -> output:T; attr=T:type>
  2023-01-12 09:34:38.190124: I tensorflow/core/framework/op.cc:132] Op<name=StatelessTruncatedNormal; signature=shape:T, seed:Tseed -> output:dtype; attr=dtype:type,default=DT_FLOAT,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]; attr=T:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=Tseed:type,default=DT_INT64,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.190198: I tensorflow/core/framework/op.cc:132] Op<name=StatelessTruncatedNormalV2; signature=shape:Tshape, key:uint64, counter:uint64, alg:int32 -> output:dtype; attr=dtype:type,default=DT_FLOAT,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]; attr=Tshape:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.190222: I tensorflow/core/framework/op.cc:132] Op<name=StatelessWhile; signature=input: -> output:; attr=T:list(type),min=0; attr=cond:func; attr=body:func; attr=output_shapes:list(shape),default=[]; attr=parallel_iterations:int,default=10>
  2023-01-12 09:34:38.190235: I tensorflow/core/framework/op.cc:132] Op<name=StaticRegexFullMatch; signature=input:string -> output:bool; attr=pattern:string>
  2023-01-12 09:34:38.190246: I tensorflow/core/framework/op.cc:132] Op<name=StaticRegexReplace; signature=input:string -> output:string; attr=pattern:string; attr=rewrite:string; attr=replace_global:bool,default=true>
  2023-01-12 09:34:38.190288: I tensorflow/core/framework/op.cc:132] Op<name=StatsAggregatorHandle; signature= -> handle:resource; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:38.190306: I tensorflow/core/framework/op.cc:132] Op<name=StatsAggregatorHandleV2; signature= -> handle:resource; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:38.190317: I tensorflow/core/framework/op.cc:132] Op<name=StatsAggregatorSetSummaryWriter; signature=stats_aggregator:resource, summary:resource -> ; is_stateful=true>
  2023-01-12 09:34:38.190326: I tensorflow/core/framework/op.cc:132] Op<name=StatsAggregatorSummary; signature=iterator:resource -> summary:string; is_stateful=true>
  2023-01-12 09:34:38.190335: I tensorflow/core/framework/op.cc:132] Op<name=StopGradient; signature=input:T -> output:T; attr=T:type>
  2023-01-12 09:34:38.190358: I tensorflow/core/framework/op.cc:132] Op<name=StridedSlice; signature=input:T, begin:Index, end:Index, strides:Index -> output:T; attr=T:type; attr=Index:type,allowed=[DT_INT16, DT_INT32, DT_INT64]; attr=begin_mask:int,default=0; attr=end_mask:int,default=0; attr=ellipsis_mask:int,default=0; attr=new_axis_mask:int,default=0; attr=shrink_axis_mask:int,default=0>
  2023-01-12 09:34:38.200068: I tensorflow/core/framework/op.cc:132] Op<name=StridedSliceAssign; signature=ref:Ref(T), begin:Index, end:Index, strides:Index, value:T -> output_ref:Ref(T); attr=T:type; attr=Index:type,allowed=[DT_INT32, DT_INT64]; attr=begin_mask:int,default=0; attr=end_mask:int,default=0; attr=ellipsis_mask:int,default=0; attr=new_axis_mask:int,default=0; attr=shrink_axis_mask:int,default=0>
  2023-01-12 09:34:38.200167: I tensorflow/core/framework/op.cc:132] Op<name=StridedSliceGrad; signature=shape:Index, begin:Index, end:Index, strides:Index, dy:T -> output:T; attr=T:type; attr=Index:type,allowed=[DT_INT32, DT_INT64]; attr=begin_mask:int,default=0; attr=end_mask:int,default=0; attr=ellipsis_mask:int,default=0; attr=new_axis_mask:int,default=0; attr=shrink_axis_mask:int,default=0>
  2023-01-12 09:34:38.200217: I tensorflow/core/framework/op.cc:132] Op<name=StringFormat; signature=inputs: -> output:string; attr=T:list(type),min=0; attr=template:string,default="%s"; attr=placeholder:string,default="%s"; attr=summarize:int,default=3>
  2023-01-12 09:34:38.200250: I tensorflow/core/framework/op.cc:132] Op<name=StringJoin; signature=inputs:N*string -> output:string; attr=N:int,min=1; attr=separator:string,default="">
  2023-01-12 09:34:38.200292: I tensorflow/core/framework/op.cc:132] Op<name=StringLength; signature=input:string -> output:int32; attr=unit:string,default="BYTE",allowed=["BYTE", "UTF8_CHAR"]>
  2023-01-12 09:34:38.200325: I tensorflow/core/framework/op.cc:132] Op<name=StringListAttr; signature= -> ; attr=a:list(string); attr=b:string>
  2023-01-12 09:34:38.200361: I tensorflow/core/framework/op.cc:132] Op<name=StringLower; signature=input:string -> output:string; attr=encoding:string,default="">
  2023-01-12 09:34:38.200457: I tensorflow/core/framework/op.cc:132] Op<name=StringNGrams; signature=data:string, data_splits:Tsplits -> ngrams:string, ngrams_splits:Tsplits; attr=separator:string; attr=ngram_widths:list(int),min=0; attr=left_pad:string; attr=right_pad:string; attr=pad_width:int; attr=preserve_short_sequences:bool; attr=Tsplits:type,default=DT_INT64,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.200640: I tensorflow/core/framework/op.cc:132] Op<name=StringSplit; signature=input:string, delimiter:string -> indices:int64, values:string, shape:int64; attr=skip_empty:bool,default=true>
  2023-01-12 09:34:38.200709: I tensorflow/core/framework/op.cc:132] Op<name=StringSplitV2; signature=input:string, sep:string -> indices:int64, values:string, shape:int64; attr=maxsplit:int,default=-1>
  2023-01-12 09:34:38.200842: I tensorflow/core/framework/op.cc:132] Op<name=StringStrip; signature=input:string -> output:string>
  2023-01-12 09:34:38.200896: I tensorflow/core/framework/op.cc:132] Op<name=StringToHashBucket; signature=string_tensor:string -> output:int64; attr=num_buckets:int,min=1>
  2023-01-12 09:34:38.200943: I tensorflow/core/framework/op.cc:132] Op<name=StringToHashBucketFast; signature=input:string -> output:int64; attr=num_buckets:int,min=1>
  2023-01-12 09:34:38.201012: I tensorflow/core/framework/op.cc:132] Op<name=StringToHashBucketStrong; signature=input:string -> output:int64; attr=num_buckets:int,min=1; attr=key:list(int)>
  2023-01-12 09:34:38.201105: I tensorflow/core/framework/op.cc:132] Op<name=StringToNumber; signature=string_tensor:string -> output:out_type; attr=out_type:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.201183: I tensorflow/core/framework/op.cc:132] Op<name=StringUpper; signature=input:string -> output:string; attr=encoding:string,default="">
  2023-01-12 09:34:38.219184: I tensorflow/core/framework/op.cc:132] Op<name=StubResourceHandleOp; signature= -> resource:resource; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:38.219368: I tensorflow/core/framework/op.cc:132] Op<name=Sub; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_INT32, DT_INT64, DT_COMPLEX64, DT_COMPLEX128, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:38.219425: I tensorflow/core/framework/op.cc:132] Op<name=Substr; signature=input:string, pos:T, len:T -> output:string; attr=T:type,allowed=[DT_INT32, DT_INT64]; attr=unit:string,default="BYTE",allowed=["BYTE", "UTF8_CHAR"]>
  2023-01-12 09:34:38.219594: I tensorflow/core/framework/op.cc:132] Op<name=Sum; signature=input:T, reduction_indices:Tidx -> output:T; attr=keep_dims:bool,default=false; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.219635: I tensorflow/core/framework/op.cc:132] Op<name=SummaryWriter; signature= -> writer:resource; attr=shared_name:string,default=""; attr=container:string,default=""; is_stateful=true>
  2023-01-12 09:34:38.219668: I tensorflow/core/framework/op.cc:132] Op<name=Svd; signature=input:T -> s:T, u:T, v:T; attr=compute_uv:bool,default=true; attr=full_matrices:bool,default=false; attr=T:type,allowed=[DT_DOUBLE, DT_FLOAT, DT_HALF, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:38.219693: I tensorflow/core/framework/op.cc:132] Op<name=Switch; signature=data:T, pred:bool -> output_false:T, output_true:T; attr=T:type>
  2023-01-12 09:34:38.219715: I tensorflow/core/framework/op.cc:132] Op<name=SymbolicGradient; signature=input: -> output:; attr=Tin:list(type),min=1; attr=Tout:list(type),min=1; attr=f:func>
  2023-01-12 09:34:38.219738: I tensorflow/core/framework/op.cc:132] Op<name=TFRecordDataset; signature=filenames:string, compression_type:string, buffer_size:int64 -> handle:variant; attr=metadata:string,default=""; is_stateful=true>
  2023-01-12 09:34:38.219762: I tensorflow/core/framework/op.cc:132] Op<name=TFRecordReader; signature= -> reader_handle:Ref(string); attr=container:string,default=""; attr=shared_name:string,default=""; attr=compression_type:string,default=""; is_stateful=true>
  2023-01-12 09:34:38.219784: I tensorflow/core/framework/op.cc:132] Op<name=TFRecordReaderV2; signature= -> reader_handle:resource; attr=container:string,default=""; attr=shared_name:string,default=""; attr=compression_type:string,default=""; is_stateful=true>
  2023-01-12 09:34:38.219803: I tensorflow/core/framework/op.cc:132] Op<name=TPUCompilationResult; signature= -> output:string>
  2023-01-12 09:34:38.219830: I tensorflow/core/framework/op.cc:132] Op<name=TPUCompile; signature=dynamic_shapes:NumDynamicShapes*int64, guaranteed_constants: -> compilation_status:string, program:num_computations*string, may_modify_variables:num_computations*bool; attr=num_computations:int,min=0; attr=function:func; attr=metadata:string; attr=NumDynamicShapes:int,min=0; attr=Tguaranteed_constants:list(type),min=0; is_stateful=true>
  2023-01-12 09:34:38.219849: I tensorflow/core/framework/op.cc:132] Op<name=TPUCompileSucceededAssert; signature=compilation_status:string -> ; is_stateful=true>
  2023-01-12 09:34:38.219870: I tensorflow/core/framework/op.cc:132] Op<name=TPUEmbeddingActivations; signature=embedding_variable:float, sliced_activations:float -> output:float; attr=table_id:int,min=0; attr=lookup_id:int,min=0>
  2023-01-12 09:34:38.219891: I tensorflow/core/framework/op.cc:132] Op<name=TPUExecute; signature=args:, key:string -> results:; attr=Targs:list(type),min=0; attr=Tresults:list(type),min=0; is_stateful=true; is_distributed_communication=true>
  2023-01-12 09:34:38.219913: I tensorflow/core/framework/op.cc:132] Op<name=TPUExecuteAndUpdateVariables; signature=args:, key:string -> results:; attr=Targs:list(type),min=0; attr=Tresults:list(type),min=0; attr=device_var_reads_indices:list(int),min=0; attr=device_var_updates_indices:list(int),min=0; is_stateful=true; is_distributed_communication=true>
  2023-01-12 09:34:38.219932: I tensorflow/core/framework/op.cc:132] Op<name=TPUOrdinalSelector; signature= -> device_ordinals:int32; is_stateful=true>
  2023-01-12 09:34:38.219955: I tensorflow/core/framework/op.cc:132] Op<name=TPUPartitionedCall; signature=args:, device_ordinal:int32 -> output:; attr=Tin:list(type),min=0; attr=Tout:list(type),min=0; attr=f:func; attr=autotuner_thresh:int,default=0>
  2023-01-12 09:34:38.219976: I tensorflow/core/framework/op.cc:132] Op<name=TPUPartitionedInput; signature=inputs:N*T -> output:T; attr=N:int,min=1; attr=T:type; attr=partition_dim:int,default=0>
  2023-01-12 09:34:38.219995: I tensorflow/core/framework/op.cc:132] Op<name=TPUPartitionedOutput; signature=inputs:T -> output:num_splits*T; attr=T:type; attr=num_splits:int,min=1; attr=partition_dim:int,default=0>
  2023-01-12 09:34:38.224232: I tensorflow/core/framework/op.cc:132] Op<name=TPUReplicateMetadata; signature= -> ; attr=num_replicas:int,min=0; attr=num_cores_per_replica:int,default=1; attr=topology:string,default=""; attr=use_tpu:bool,default=true; attr=device_assignment:list(int),default=[]; attr=computation_shape:list(int),default=[]; attr=host_compute_core:list(string),default=[]; attr=padding_map:list(string),default=[]; attr=step_marker_location:string,default="STEP_MARK_AT_ENTRY"; attr=allow_soft_placement:bool,default=false; attr=use_spmd_for_xla_partitioning:bool,default=false; attr=tpu_compile_options_proto:string,default="">
  2023-01-12 09:34:38.224680: I tensorflow/core/framework/op.cc:132] Op<name=TPUReplicatedInput; signature=inputs:N*T -> output:T; attr=N:int,min=1; attr=T:type; attr=is_mirrored_variable:bool,default=false; attr=index:int,default=-1; attr=is_packed:bool,default=false>
  2023-01-12 09:34:38.224822: I tensorflow/core/framework/op.cc:132] Op<name=TPUReplicatedOutput; signature=input:T -> outputs:num_replicas*T; attr=num_replicas:int,min=1; attr=T:type>
  2023-01-12 09:34:38.225043: I tensorflow/core/framework/op.cc:132] Op<name=TPUReshardVariables; signature=vars:N*resource, new_format_key:string, format_state_var:resource -> ; attr=N:int,min=0; is_stateful=true>
  2023-01-12 09:34:38.225110: I tensorflow/core/framework/op.cc:132] Op<name=TPURoundRobin; signature= -> device_ordinal:int32; is_stateful=true>
  2023-01-12 09:34:38.225174: I tensorflow/core/framework/op.cc:132] Op<name=TakeDataset; signature=input_dataset:variant, count:int64 -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=metadata:string,default="">
  2023-01-12 09:34:38.225236: I tensorflow/core/framework/op.cc:132] Op<name=TakeManySparseFromTensorsMap; signature=sparse_handles:int64 -> sparse_indices:int64, sparse_values:dtype, sparse_shape:int64; attr=dtype:type; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:38.225302: I tensorflow/core/framework/op.cc:132] Op<name=TakeWhileDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=predicate:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=metadata:string,default="">
  2023-01-12 09:34:38.225374: I tensorflow/core/framework/op.cc:132] Op<name=Tan; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT8, DT_INT16, DT_INT32, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:38.225591: I tensorflow/core/framework/op.cc:132] Op<name=Tanh; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:38.225666: I tensorflow/core/framework/op.cc:132] Op<name=TanhGrad; signature=y:T, dy:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:38.225841: I tensorflow/core/framework/op.cc:132] Op<name=TemporaryVariable; signature= -> ref:Ref(dtype); attr=shape:shape; attr=dtype:type; attr=var_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:38.226063: I tensorflow/core/framework/op.cc:132] Op<name=TensorArray; signature=size:int32 -> handle:Ref(string); attr=dtype:type; attr=dynamic_size:bool,default=false; attr=clear_after_read:bool,default=true; attr=tensor_array_name:string,default=""; attr=element_shape:shape,default=<unknown>; is_stateful=true>
  2023-01-12 09:34:38.231975: I tensorflow/core/framework/op.cc:132] Op<name=TensorArrayClose; signature=handle:Ref(string) -> >
  2023-01-12 09:34:38.232034: I tensorflow/core/framework/op.cc:132] Op<name=TensorArrayCloseV2; signature=handle:string -> >
  2023-01-12 09:34:38.232055: I tensorflow/core/framework/op.cc:132] Op<name=TensorArrayCloseV3; signature=handle:resource -> ; is_stateful=true>
  2023-01-12 09:34:38.232089: I tensorflow/core/framework/op.cc:132] Op<name=TensorArrayConcat; signature=handle:Ref(string), flow_in:float -> value:dtype, lengths:int64; attr=dtype:type; attr=element_shape_except0:shape,default=<unknown>>
  2023-01-12 09:34:38.232114: I tensorflow/core/framework/op.cc:132] Op<name=TensorArrayConcatV2; signature=handle:string, flow_in:float -> value:dtype, lengths:int64; attr=dtype:type; attr=element_shape_except0:shape,default=<unknown>>
  2023-01-12 09:34:38.232137: I tensorflow/core/framework/op.cc:132] Op<name=TensorArrayConcatV3; signature=handle:resource, flow_in:float -> value:dtype, lengths:int64; attr=dtype:type; attr=element_shape_except0:shape,default=<unknown>; is_stateful=true>
  2023-01-12 09:34:38.232160: I tensorflow/core/framework/op.cc:132] Op<name=TensorArrayGather; signature=handle:Ref(string), indices:int32, flow_in:float -> value:dtype; attr=dtype:type; attr=element_shape:shape,default=<unknown>>
  2023-01-12 09:34:38.232181: I tensorflow/core/framework/op.cc:132] Op<name=TensorArrayGatherV2; signature=handle:string, indices:int32, flow_in:float -> value:dtype; attr=dtype:type; attr=element_shape:shape,default=<unknown>>
  2023-01-12 09:34:38.232204: I tensorflow/core/framework/op.cc:132] Op<name=TensorArrayGatherV3; signature=handle:resource, indices:int32, flow_in:float -> value:dtype; attr=dtype:type; attr=element_shape:shape,default=<unknown>; is_stateful=true>
  2023-01-12 09:34:38.232225: I tensorflow/core/framework/op.cc:132] Op<name=TensorArrayGrad; signature=handle:string, flow_in:float -> grad_handle:Ref(string); attr=source:string; is_stateful=true>
  2023-01-12 09:34:38.232246: I tensorflow/core/framework/op.cc:132] Op<name=TensorArrayGradV2; signature=handle:string, flow_in:float -> grad_handle:string; attr=source:string; is_stateful=true>
  2023-01-12 09:34:38.232293: I tensorflow/core/framework/op.cc:132] Op<name=TensorArrayGradV3; signature=handle:resource, flow_in:float -> grad_handle:resource, flow_out:float; attr=source:string; is_stateful=true>
  2023-01-12 09:34:38.232325: I tensorflow/core/framework/op.cc:132] Op<name=TensorArrayGradWithShape; signature=handle:resource, flow_in:float, shape_to_prepend:int32 -> grad_handle:resource, flow_out:float; attr=source:string; is_stateful=true>
  2023-01-12 09:34:38.232349: I tensorflow/core/framework/op.cc:132] Op<name=TensorArrayPack; signature=handle:Ref(string), flow_in:float -> value:dtype; attr=dtype:type; attr=element_shape:shape,default=<unknown>>
  2023-01-12 09:34:38.232434: I tensorflow/core/framework/op.cc:132] Op<name=TensorArrayRead; signature=handle:Ref(string), index:int32, flow_in:float -> value:dtype; attr=dtype:type>
  2023-01-12 09:34:38.232545: I tensorflow/core/framework/op.cc:132] Op<name=TensorArrayReadV2; signature=handle:string, index:int32, flow_in:float -> value:dtype; attr=dtype:type>
  2023-01-12 09:34:38.232703: I tensorflow/core/framework/op.cc:132] Op<name=TensorArrayReadV3; signature=handle:resource, index:int32, flow_in:float -> value:dtype; attr=dtype:type; is_stateful=true>
  2023-01-12 09:34:38.232793: I tensorflow/core/framework/op.cc:132] Op<name=TensorArrayScatter; signature=handle:Ref(string), indices:int32, value:T, flow_in:float -> flow_out:float; attr=T:type>
  2023-01-12 09:34:38.232844: I tensorflow/core/framework/op.cc:132] Op<name=TensorArrayScatterV2; signature=handle:string, indices:int32, value:T, flow_in:float -> flow_out:float; attr=T:type>
  2023-01-12 09:34:38.232898: I tensorflow/core/framework/op.cc:132] Op<name=TensorArrayScatterV3; signature=handle:resource, indices:int32, value:T, flow_in:float -> flow_out:float; attr=T:type; is_stateful=true>
  2023-01-12 09:34:38.232989: I tensorflow/core/framework/op.cc:132] Op<name=TensorArraySize; signature=handle:Ref(string), flow_in:float -> size:int32>
  2023-01-12 09:34:38.233057: I tensorflow/core/framework/op.cc:132] Op<name=TensorArraySizeV2; signature=handle:string, flow_in:float -> size:int32>
  2023-01-12 09:34:38.233125: I tensorflow/core/framework/op.cc:132] Op<name=TensorArraySizeV3; signature=handle:resource, flow_in:float -> size:int32; is_stateful=true>
  2023-01-12 09:34:38.233181: I tensorflow/core/framework/op.cc:132] Op<name=TensorArraySplit; signature=handle:Ref(string), value:T, lengths:int64, flow_in:float -> flow_out:float; attr=T:type>
  2023-01-12 09:34:38.239863: I tensorflow/core/framework/op.cc:132] Op<name=TensorArraySplitV2; signature=handle:string, value:T, lengths:int64, flow_in:float -> flow_out:float; attr=T:type>
  2023-01-12 09:34:38.239984: I tensorflow/core/framework/op.cc:132] Op<name=TensorArraySplitV3; signature=handle:resource, value:T, lengths:int64, flow_in:float -> flow_out:float; attr=T:type; is_stateful=true>
  2023-01-12 09:34:38.240196: I tensorflow/core/framework/op.cc:132] Op<name=TensorArrayUnpack; signature=handle:Ref(string), value:T, flow_in:float -> flow_out:float; attr=T:type>
  2023-01-12 09:34:38.240377: I tensorflow/core/framework/op.cc:132] Op<name=TensorArrayV2; signature=size:int32 -> handle:string; attr=dtype:type; attr=element_shape:shape,default=<unknown>; attr=dynamic_size:bool,default=false; attr=clear_after_read:bool,default=true; attr=tensor_array_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:38.240544: I tensorflow/core/framework/op.cc:132] Op<name=TensorArrayV3; signature=size:int32 -> handle:resource, flow:float; attr=dtype:type; attr=element_shape:shape,default=<unknown>; attr=dynamic_size:bool,default=false; attr=clear_after_read:bool,default=true; attr=identical_element_shapes:bool,default=false; attr=tensor_array_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:38.240634: I tensorflow/core/framework/op.cc:132] Op<name=TensorArrayWrite; signature=handle:Ref(string), index:int32, value:T, flow_in:float -> flow_out:float; attr=T:type>
  2023-01-12 09:34:38.240675: I tensorflow/core/framework/op.cc:132] Op<name=TensorArrayWriteV2; signature=handle:string, index:int32, value:T, flow_in:float -> flow_out:float; attr=T:type>
  2023-01-12 09:34:38.240727: I tensorflow/core/framework/op.cc:132] Op<name=TensorArrayWriteV3; signature=handle:resource, index:int32, value:T, flow_in:float -> flow_out:float; attr=T:type; is_stateful=true>
  2023-01-12 09:34:38.240835: I tensorflow/core/framework/op.cc:132] Op<name=TensorDataset; signature=components: -> handle:variant; attr=Toutput_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=metadata:string,default=""; is_stateful=true>
  2023-01-12 09:34:38.240899: I tensorflow/core/framework/op.cc:132] Op<name=TensorListConcat; signature=input_handle:variant -> tensor:element_dtype, lengths:int64; attr=element_dtype:type; attr=element_shape:shape,default=<unknown>>
  2023-01-12 09:34:38.240980: I tensorflow/core/framework/op.cc:132] Op<name=TensorListConcatLists; signature=input_a:variant, input_b:variant -> output:variant; attr=element_dtype:type>
  2023-01-12 09:34:38.241037: I tensorflow/core/framework/op.cc:132] Op<name=TensorListConcatV2; signature=input_handle:variant, element_shape:shape_type, leading_dims:int64 -> tensor:element_dtype, lengths:int64; attr=element_dtype:type; attr=shape_type:type,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.241065: I tensorflow/core/framework/op.cc:132] Op<name=TensorListElementShape; signature=input_handle:variant -> element_shape:shape_type; attr=shape_type:type,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.241091: I tensorflow/core/framework/op.cc:132] Op<name=TensorListFromTensor; signature=tensor:element_dtype, element_shape:shape_type -> output_handle:variant; attr=element_dtype:type; attr=shape_type:type,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.241114: I tensorflow/core/framework/op.cc:132] Op<name=TensorListGather; signature=input_handle:variant, indices:int32, element_shape:int32 -> values:element_dtype; attr=element_dtype:type>
  2023-01-12 09:34:38.241133: I tensorflow/core/framework/op.cc:132] Op<name=TensorListGetItem; signature=input_handle:variant, index:int32, element_shape:int32 -> item:element_dtype; attr=element_dtype:type>
  2023-01-12 09:34:38.241151: I tensorflow/core/framework/op.cc:132] Op<name=TensorListLength; signature=input_handle:variant -> length:int32>
  2023-01-12 09:34:38.335359: I tensorflow/core/framework/op.cc:132] Op<name=TensorListPopBack; signature=input_handle:variant, element_shape:int32 -> output_handle:variant, tensor:element_dtype; attr=element_dtype:type>
  2023-01-12 09:34:38.335522: I tensorflow/core/framework/op.cc:132] Op<name=TensorListPushBack; signature=input_handle:variant, tensor:element_dtype -> output_handle:variant; attr=element_dtype:type>
  2023-01-12 09:34:38.335569: I tensorflow/core/framework/op.cc:132] Op<name=TensorListPushBackBatch; signature=input_handles:variant, tensor:element_dtype -> output_handles:variant; attr=element_dtype:type>
  2023-01-12 09:34:38.335618: I tensorflow/core/framework/op.cc:132] Op<name=TensorListReserve; signature=element_shape:shape_type, num_elements:int32 -> handle:variant; attr=element_dtype:type; attr=shape_type:type,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.335640: I tensorflow/core/framework/op.cc:132] Op<name=TensorListResize; signature=input_handle:variant, size:int32 -> output_handle:variant>
  2023-01-12 09:34:38.335667: I tensorflow/core/framework/op.cc:132] Op<name=TensorListScatter; signature=tensor:element_dtype, indices:int32, element_shape:shape_type -> output_handle:variant; attr=element_dtype:type; attr=shape_type:type,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.335690: I tensorflow/core/framework/op.cc:132] Op<name=TensorListScatterIntoExistingList; signature=input_handle:variant, tensor:element_dtype, indices:int32 -> output_handle:variant; attr=element_dtype:type>
  2023-01-12 09:34:38.335719: I tensorflow/core/framework/op.cc:132] Op<name=TensorListScatterV2; signature=tensor:element_dtype, indices:int32, element_shape:shape_type, num_elements:int32 -> output_handle:variant; attr=element_dtype:type; attr=shape_type:type,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.335743: I tensorflow/core/framework/op.cc:132] Op<name=TensorListSetItem; signature=input_handle:variant, index:int32, item:element_dtype -> output_handle:variant; attr=element_dtype:type>
  2023-01-12 09:34:38.335791: I tensorflow/core/framework/op.cc:132] Op<name=TensorListSplit; signature=tensor:element_dtype, element_shape:shape_type, lengths:int64 -> output_handle:variant; attr=element_dtype:type; attr=shape_type:type,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.335831: I tensorflow/core/framework/op.cc:132] Op<name=TensorListStack; signature=input_handle:variant, element_shape:int32 -> tensor:element_dtype; attr=element_dtype:type; attr=num_elements:int,default=-1>
  2023-01-12 09:34:38.335854: I tensorflow/core/framework/op.cc:132] Op<name=TensorMapErase; signature=input_handle:variant, key:key_dtype -> output_handle:variant; attr=key_dtype:type; attr=value_dtype:type>
  2023-01-12 09:34:38.335874: I tensorflow/core/framework/op.cc:132] Op<name=TensorMapHasKey; signature=input_handle:variant, key:key_dtype -> has_key:bool; attr=key_dtype:type>
  2023-01-12 09:34:38.335896: I tensorflow/core/framework/op.cc:132] Op<name=TensorMapInsert; signature=input_handle:variant, key:key_dtype, value:value_dtype -> output_handle:variant; attr=key_dtype:type; attr=value_dtype:type>
  2023-01-12 09:34:38.335918: I tensorflow/core/framework/op.cc:132] Op<name=TensorMapLookup; signature=input_handle:variant, key:key_dtype -> value:value_dtype; attr=key_dtype:type; attr=value_dtype:type>
  2023-01-12 09:34:38.335935: I tensorflow/core/framework/op.cc:132] Op<name=TensorMapSize; signature=input_handle:variant -> size:int32>
  2023-01-12 09:34:38.335956: I tensorflow/core/framework/op.cc:132] Op<name=TensorMapStackKeys; signature=input_handle:variant -> keys:key_dtype; attr=key_dtype:type>
  2023-01-12 09:34:38.335996: I tensorflow/core/framework/op.cc:132] Op<name=TensorScatterAdd; signature=tensor:T, indices:Tindices, updates:T -> output:T; attr=T:type; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.336038: I tensorflow/core/framework/op.cc:132] Op<name=TensorScatterMax; signature=tensor:T, indices:Tindices, updates:T -> output:T; attr=T:type; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.336068: I tensorflow/core/framework/op.cc:132] Op<name=TensorScatterMin; signature=tensor:T, indices:Tindices, updates:T -> output:T; attr=T:type; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.336120: I tensorflow/core/framework/op.cc:132] Op<name=TensorScatterSub; signature=tensor:T, indices:Tindices, updates:T -> output:T; attr=T:type; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.336151: I tensorflow/core/framework/op.cc:132] Op<name=TensorScatterUpdate; signature=tensor:T, indices:Tindices, updates:T -> output:T; attr=T:type; attr=Tindices:type,allowed=[DT_INT16, DT_INT32, DT_INT64, DT_UINT16]>
  2023-01-12 09:34:38.336189: I tensorflow/core/framework/op.cc:132] Op<name=TensorSliceDataset; signature=components: -> handle:variant; attr=Toutput_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=is_files:bool,default=false; attr=metadata:string,default=""; attr=replicate_on_split:bool,default=false; is_stateful=true>
  2023-01-12 09:34:38.336236: I tensorflow/core/framework/op.cc:132] Op<name=TensorStridedSliceUpdate; signature=input:T, begin:Index, end:Index, strides:Index, value:T -> output:T; attr=T:type; attr=Index:type,allowed=[DT_INT32, DT_INT64]; attr=begin_mask:int,default=0; attr=end_mask:int,default=0; attr=ellipsis_mask:int,default=0; attr=new_axis_mask:int,default=0; attr=shrink_axis_mask:int,default=0>
  2023-01-12 09:34:38.336289: I tensorflow/core/framework/op.cc:132] Op<name=TensorSummary; signature=tensor:T -> summary:string; attr=T:type; attr=description:string,default=""; attr=labels:list(string),default=[]; attr=display_name:string,default="">
  2023-01-12 09:34:38.336331: I tensorflow/core/framework/op.cc:132] Op<name=TensorSummaryV2; signature=tag:string, tensor:T, serialized_summary_metadata:string -> summary:string; attr=T:type>
  2023-01-12 09:34:38.336363: I tensorflow/core/framework/op.cc:132] Op<name=TestAttr; signature= -> out:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE]; is_stateful=true>
  2023-01-12 09:34:38.336420: I tensorflow/core/framework/op.cc:132] Op<name=TestStringOutput; signature=input:float -> output1:float, output2:string>
  2023-01-12 09:34:38.336446: I tensorflow/core/framework/op.cc:132] Op<name=TextLineDataset; signature=filenames:string, compression_type:string, buffer_size:int64 -> handle:variant; attr=metadata:string,default=""; is_stateful=true>
  2023-01-12 09:34:38.336507: I tensorflow/core/framework/op.cc:132] Op<name=TextLineReader; signature= -> reader_handle:Ref(string); attr=skip_header_lines:int,default=0; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:38.336574: I tensorflow/core/framework/op.cc:132] Op<name=TextLineReaderV2; signature= -> reader_handle:resource; attr=skip_header_lines:int,default=0; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:38.336761: I tensorflow/core/framework/op.cc:132] Op<name=TfLiteSubgraphExecute; signature=subgraph_key:string, args: -> output:; attr=Tin:list(type),min=0; attr=Tout:list(type),min=0>
  2023-01-12 09:34:38.336793: I tensorflow/core/framework/op.cc:132] Op<name=ThreadPoolDataset; signature=input_dataset:variant, thread_pool:resource -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; is_stateful=true>
  2023-01-12 09:34:38.336819: I tensorflow/core/framework/op.cc:132] Op<name=ThreadPoolHandle; signature= -> handle:resource; attr=num_threads:int; attr=max_intra_op_parallelism:int,default=1; attr=display_name:string; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:38.336863: I tensorflow/core/framework/op.cc:132] Op<name=ThreadUnsafeUnigramCandidateSampler; signature=true_classes:int64 -> sampled_candidates:int64, true_expected_count:float, sampled_expected_count:float; attr=num_true:int,min=1; attr=num_sampled:int,min=1; attr=unique:bool; attr=range_max:int,min=1; attr=seed:int,default=0; attr=seed2:int,default=0; is_stateful=true>
  2023-01-12 09:34:38.336916: I tensorflow/core/framework/op.cc:132] Op<name=Tile; signature=input:T, multiples:Tmultiples -> output:T; attr=T:type; attr=Tmultiples:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.336955: I tensorflow/core/framework/op.cc:132] Op<name=TileGrad; signature=input:T, multiples:int32 -> output:T; attr=T:type>
  2023-01-12 09:34:38.336973: I tensorflow/core/framework/op.cc:132] Op<name=Timestamp; signature= -> ts:double; is_stateful=true>
  2023-01-12 09:34:38.336994: I tensorflow/core/framework/op.cc:132] Op<name=ToBool; signature=input:T -> output:bool; attr=T:type>
  2023-01-12 09:34:38.337033: I tensorflow/core/framework/op.cc:132] Op<name=TopK; signature=input:T -> values:T, indices:int32; attr=k:int,min=0; attr=sorted:bool,default=true; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:38.337061: I tensorflow/core/framework/op.cc:132] Op<name=TopKUnique; signature=input:float -> topk:float, topk_indices:int32; attr=k:int>
  2023-01-12 09:34:38.337109: I tensorflow/core/framework/op.cc:132] Op<name=TopKV2; signature=input:T, k:int32 -> values:T, indices:int32; attr=sorted:bool,default=true; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:38.337161: I tensorflow/core/framework/op.cc:132] Op<name=TopKWithUnique; signature=input:float -> topk:float, topk_indices:int32; attr=k:int>
  2023-01-12 09:34:38.337180: I tensorflow/core/framework/op.cc:132] Op<name=TpuHandleToProtoKey; signature=uid:int64 -> proto_keys:string>
  2023-01-12 09:34:38.337203: I tensorflow/core/framework/op.cc:132] Op<name=Transpose; signature=x:T, perm:Tperm -> y:T; attr=T:type; attr=Tperm:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.337242: I tensorflow/core/framework/op.cc:132] Op<name=TridiagonalMatMul; signature=superdiag:T, maindiag:T, subdiag:T, rhs:T -> output:T; attr=T:type,allowed=[DT_DOUBLE, DT_FLOAT, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:38.337316: I tensorflow/core/framework/op.cc:132] Op<name=TridiagonalSolve; signature=diagonals:T, rhs:T -> output:T; attr=partial_pivoting:bool,default=true; attr=perturb_singular:bool,default=false; attr=T:type,allowed=[DT_DOUBLE, DT_FLOAT, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:38.337401: I tensorflow/core/framework/op.cc:132] Op<name=TruncateDiv; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_INT32, DT_UINT32, DT_UINT64, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:38.337429: I tensorflow/core/framework/op.cc:132] Op<name=TruncateMod; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_INT32, DT_INT64, DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:38.337497: I tensorflow/core/framework/op.cc:132] Op<name=TruncatedNormal; signature=shape:T -> output:dtype; attr=seed:int,default=0; attr=seed2:int,default=0; attr=dtype:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]; attr=T:type,allowed=[DT_INT32, DT_INT64]; is_stateful=true>
  2023-01-12 09:34:38.337518: I tensorflow/core/framework/op.cc:132] Op<name=TwoFloatInputs; signature=a:float, b:float -> >
  2023-01-12 09:34:38.337533: I tensorflow/core/framework/op.cc:132] Op<name=TwoFloatInputsFloatOutput; signature=a:float, b:float -> c:float>
  2023-01-12 09:34:38.337547: I tensorflow/core/framework/op.cc:132] Op<name=TwoFloatInputsIntOutput; signature=a:float, b:float -> c:int32>
  2023-01-12 09:34:38.337561: I tensorflow/core/framework/op.cc:132] Op<name=TwoFloatOutputs; signature= -> a:float, b:float>
  2023-01-12 09:34:38.337574: I tensorflow/core/framework/op.cc:132] Op<name=TwoIntInputs; signature=a:int32, b:int32 -> >
  2023-01-12 09:34:38.337588: I tensorflow/core/framework/op.cc:132] Op<name=TwoIntOutputs; signature= -> a:int32, b:int32>
  2023-01-12 09:34:38.337725: I tensorflow/core/framework/op.cc:132] Op<name=TwoRefsIn; signature=a:Ref(T), b:Ref(T) -> ; attr=T:type>
  2023-01-12 09:34:38.337749: I tensorflow/core/framework/op.cc:132] Op<name=TypeList; signature=a: -> ; attr=T:list(type),min=0>
  2023-01-12 09:34:38.337824: I tensorflow/core/framework/op.cc:132] Op<name=TypeListRestrict; signature=a: -> ; attr=T:list(type),min=1,allowed=[DT_STRING, DT_BOOL]>
  2023-01-12 09:34:38.337846: I tensorflow/core/framework/op.cc:132] Op<name=TypeListTwice; signature=a:, b: -> ; attr=T:list(type),min=0>
  2023-01-12 09:34:38.337861: I tensorflow/core/framework/op.cc:132] Op<name=Unary; signature=a:T -> b:T; attr=T:type>
  2023-01-12 09:34:38.337881: I tensorflow/core/framework/op.cc:132] Op<name=Unbatch; signature=batched_tensor:T, batch_index:int64, id:int64 -> unbatched_tensor:T; attr=timeout_micros:int; attr=container:string,default=""; attr=shared_name:string,default=""; attr=T:type>
  2023-01-12 09:34:38.337938: I tensorflow/core/framework/op.cc:132] Op<name=UnbatchDataset; signature=input_dataset:variant -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=metadata:string,default="">
  2023-01-12 09:34:38.337964: I tensorflow/core/framework/op.cc:132] Op<name=UnbatchGrad; signature=original_input:T, batch_index:int64, grad:T, id:int64 -> batched_grad:T; attr=container:string,default=""; attr=shared_name:string,default=""; attr=T:type>
  2023-01-12 09:34:38.337981: I tensorflow/core/framework/op.cc:132] Op<name=UncompressElement; signature=compressed:variant -> components:; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1>
  2023-01-12 09:34:38.338014: I tensorflow/core/framework/op.cc:132] Op<name=UnicodeDecode; signature=input:string -> row_splits:Tsplits, char_values:int32; attr=input_encoding:string; attr=errors:string,default="replace",allowed=["strict", "replace", "ignore"]; attr=replacement_char:int,default=65533; attr=replace_control_characters:bool,default=false; attr=Tsplits:type,default=DT_INT64,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.338047: I tensorflow/core/framework/op.cc:132] Op<name=UnicodeDecodeWithOffsets; signature=input:string -> row_splits:Tsplits, char_values:int32, char_to_byte_starts:int64; attr=input_encoding:string; attr=errors:string,default="replace",allowed=["strict", "replace", "ignore"]; attr=replacement_char:int,default=65533; attr=replace_control_characters:bool,default=false; attr=Tsplits:type,default=DT_INT64,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.338113: I tensorflow/core/framework/op.cc:132] Op<name=UnicodeEncode; signature=input_values:int32, input_splits:Tsplits -> output:string; attr=errors:string,default="replace",allowed=["ignore", "replace", "strict"]; attr=output_encoding:string,allowed=["UTF-8", "UTF-16-BE", "UTF-32-BE"]; attr=replacement_char:int,default=65533; attr=Tsplits:type,default=DT_INT64,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.338138: I tensorflow/core/framework/op.cc:132] Op<name=UnicodeScript; signature=input:int32 -> output:int32>
  2023-01-12 09:34:38.338165: I tensorflow/core/framework/op.cc:132] Op<name=UnicodeTranscode; signature=input:string -> output:string; attr=input_encoding:string; attr=output_encoding:string,allowed=["UTF-8", "UTF-16-BE", "UTF-32-BE"]; attr=errors:string,default="replace",allowed=["strict", "replace", "ignore"]; attr=replacement_char:int,default=65533; attr=replace_control_characters:bool,default=false>
  2023-01-12 09:34:38.338189: I tensorflow/core/framework/op.cc:132] Op<name=UniformCandidateSampler; signature=true_classes:int64 -> sampled_candidates:int64, true_expected_count:float, sampled_expected_count:float; attr=num_true:int,min=1; attr=num_sampled:int,min=1; attr=unique:bool; attr=range_max:int,min=1; attr=seed:int,default=0; attr=seed2:int,default=0; is_stateful=true>
  2023-01-12 09:34:38.338228: I tensorflow/core/framework/op.cc:132] Op<name=UniformDequantize; signature=input:Tin, scales:float, zero_points:int32 -> output:Tout; attr=Tin:type,allowed=[DT_QINT8, DT_QINT32]; attr=Tout:type,allowed=[DT_FLOAT]; attr=quantization_axis:int,default=-1; attr=quantization_min_val:int; attr=quantization_max_val:int>
  2023-01-12 09:34:38.338266: I tensorflow/core/framework/op.cc:132] Op<name=UniformQuantize; signature=input:Tin, scales:float, zero_points:int32 -> output:Tout; attr=Tin:type,allowed=[DT_FLOAT]; attr=Tout:type,allowed=[DT_QINT8, DT_QINT32]; attr=quantization_axis:int,default=-1; attr=quantization_min_val:int; attr=quantization_max_val:int>
  2023-01-12 09:34:38.338293: I tensorflow/core/framework/op.cc:132] Op<name=UniformQuantizedClipByValue; signature=operand:T, min:T, max:T, scales:float, zero_points:int32 -> output:T; attr=T:type,allowed=[DT_QINT32]; attr=quantization_axis:int,default=-1; attr=quantization_min_val:int; attr=quantization_max_val:int>
  2023-01-12 09:34:38.338323: I tensorflow/core/framework/op.cc:132] Op<name=UniformQuantizedDot; signature=lhs:Tin, rhs:Tin, lhs_scales:float, lhs_zero_points:int32, rhs_scales:float, rhs_zero_points:int32, output_scales:float, output_zero_points:int32 -> output:Tout; attr=Tin:type,allowed=[DT_QINT8]; attr=Tout:type,allowed=[DT_QINT32]; attr=lhs_quantization_axis:int,default=-1; attr=lhs_quantization_min_val:int; attr=lhs_quantization_max_val:int; attr=rhs_quantization_axis:int,default=-1; attr=rhs_quantization_min_val:int; attr=rhs_quantization_max_val:int; attr=output_quantization_axis:int,default=-1; attr=output_quantization_min_val:int; attr=output_quantization_max_val:int>
  2023-01-12 09:34:38.338351: I tensorflow/core/framework/op.cc:132] Op<name=UniformQuantizedDotHybrid; signature=lhs:Tlhs, rhs:Trhs, rhs_scales:float, rhs_zero_points:int32 -> output:Tout; attr=Tlhs:type,allowed=[DT_FLOAT]; attr=Trhs:type,allowed=[DT_QINT8]; attr=Tout:type,allowed=[DT_FLOAT]; attr=rhs_quantization_axis:int,default=-1; attr=rhs_quantization_min_val:int; attr=rhs_quantization_max_val:int>
  2023-01-12 09:34:38.338384: I tensorflow/core/framework/op.cc:132] Op<name=UniformRequantize; signature=input:Tin, input_scales:float, input_zero_points:int32, output_scales:float, output_zero_points:int32 -> output:Tout; attr=Tin:type,allowed=[DT_QINT8, DT_QINT32]; attr=Tout:type,allowed=[DT_QINT8, DT_QINT32]; attr=input_quantization_axis:int,default=-1; attr=input_quantization_min_val:int; attr=input_quantization_max_val:int; attr=output_quantization_axis:int,default=-1; attr=output_quantization_min_val:int; attr=output_quantization_max_val:int>
  2023-01-12 09:34:38.338510: I tensorflow/core/framework/op.cc:132] Op<name=Unique; signature=x:T -> y:T, idx:out_idx; attr=T:type; attr=out_idx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.338561: I tensorflow/core/framework/op.cc:132] Op<name=UniqueDataset; signature=input_dataset:variant -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=metadata:string,default="">
  2023-01-12 09:34:38.338622: I tensorflow/core/framework/op.cc:132] Op<name=UniqueV2; signature=x:T, axis:Taxis -> y:T, idx:out_idx; attr=T:type; attr=Taxis:type,default=DT_INT64,allowed=[DT_INT32, DT_INT64]; attr=out_idx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.338713: I tensorflow/core/framework/op.cc:132] Op<name=UniqueWithCounts; signature=x:T -> y:T, idx:out_idx, count:out_idx; attr=T:type; attr=out_idx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.338835: I tensorflow/core/framework/op.cc:132] Op<name=UniqueWithCountsV2; signature=x:T, axis:Taxis -> y:T, idx:out_idx, count:out_idx; attr=T:type; attr=Taxis:type,default=DT_INT64,allowed=[DT_INT32, DT_INT64]; attr=out_idx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.338911: I tensorflow/core/framework/op.cc:132] Op<name=Unpack; signature=value:T -> output:num*T; attr=num:int,min=0; attr=T:type; attr=axis:int,default=0>
  2023-01-12 09:34:38.338977: I tensorflow/core/framework/op.cc:132] Op<name=UnravelIndex; signature=indices:Tidx, dims:Tidx -> output:Tidx; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.339242: I tensorflow/core/framework/op.cc:132] Op<name=UnsortedSegmentJoin; signature=inputs:string, segment_ids:Tindices, num_segments:Tnumsegments -> output:string; attr=separator:string,default=""; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=Tnumsegments:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.339374: I tensorflow/core/framework/op.cc:132] Op<name=UnsortedSegmentMax; signature=data:T, segment_ids:Tindices, num_segments:Tnumsegments -> output:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=Tnumsegments:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.339498: I tensorflow/core/framework/op.cc:132] Op<name=UnsortedSegmentMin; signature=data:T, segment_ids:Tindices, num_segments:Tnumsegments -> output:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=Tnumsegments:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.339613: I tensorflow/core/framework/op.cc:132] Op<name=UnsortedSegmentProd; signature=data:T, segment_ids:Tindices, num_segments:Tnumsegments -> output:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=Tnumsegments:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.339695: I tensorflow/core/framework/op.cc:132] Op<name=UnsortedSegmentSum; signature=data:T, segment_ids:Tindices, num_segments:Tnumsegments -> output:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=Tnumsegments:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.339748: I tensorflow/core/framework/op.cc:132] Op<name=Unstage; signature= -> values:; attr=capacity:int,default=0,min=0; attr=memory_limit:int,default=0,min=0; attr=dtypes:list(type),min=1; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:38.339784: I tensorflow/core/framework/op.cc:132] Op<name=UnwrapDatasetVariant; signature=input_handle:variant -> output_handle:variant>
  2023-01-12 09:34:38.339824: I tensorflow/core/framework/op.cc:132] Op<name=UpperBound; signature=sorted_inputs:T, values:T -> output:out_type; attr=T:type; attr=out_type:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.339868: I tensorflow/core/framework/op.cc:132] Op<name=VarHandleOp; signature= -> resource:resource; attr=container:string,default=""; attr=shared_name:string,default=""; attr=dtype:type; attr=shape:shape; attr=allowed_devices:list(string),default=[]; is_stateful=true>
  2023-01-12 09:34:38.339902: I tensorflow/core/framework/op.cc:132] Op<name=VarIsInitializedOp; signature=resource:resource -> is_initialized:bool; is_stateful=true>
  2023-01-12 09:34:38.339936: I tensorflow/core/framework/op.cc:132] Op<name=Variable; signature= -> ref:Ref(dtype); attr=shape:shape; attr=dtype:type; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:38.339961: I tensorflow/core/framework/op.cc:132] Op<name=VariableShape; signature=input:resource -> output:out_type; attr=out_type:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; is_stateful=true>
  2023-01-12 09:34:38.341853: I tensorflow/core/framework/op.cc:132] Op<name=VariableV2; signature= -> ref:Ref(dtype); attr=shape:shape; attr=dtype:type; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:38.342091: I tensorflow/core/framework/op.cc:132] Op<name=Where; signature=input:T -> index:int64; attr=T:type,default=DT_BOOL,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 16534343205130372495, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64, DT_BOOL]>
  2023-01-12 09:34:38.342202: I tensorflow/core/framework/op.cc:132] Op<name=While; signature=input: -> output:; attr=T:list(type),min=0; attr=cond:func; attr=body:func; attr=output_shapes:list(shape),default=[]; attr=parallel_iterations:int,default=10; is_stateful=true>
  2023-01-12 09:34:38.342680: I tensorflow/core/framework/op.cc:132] Op<name=WholeFileReader; signature= -> reader_handle:Ref(string); attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:38.342792: I tensorflow/core/framework/op.cc:132] Op<name=WholeFileReaderV2; signature= -> reader_handle:resource; attr=container:string,default=""; attr=shared_name:string,default=""; is_stateful=true>
  2023-01-12 09:34:38.342862: I tensorflow/core/framework/op.cc:132] Op<name=WindowDataset; signature=input_dataset:variant, size:int64, shift:int64, stride:int64, drop_remainder:bool -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=metadata:string,default="">
  2023-01-12 09:34:38.342945: I tensorflow/core/framework/op.cc:132] Op<name=WindowOp; signature=inputs: -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=Tinputs:list(type),min=1>
  2023-01-12 09:34:38.342993: I tensorflow/core/framework/op.cc:132] Op<name=WorkerHeartbeat; signature=request:string -> response:string; is_stateful=true>
  2023-01-12 09:34:38.343027: I tensorflow/core/framework/op.cc:132] Op<name=WrapDatasetVariant; signature=input_handle:variant -> output_handle:variant>
  2023-01-12 09:34:38.343202: I tensorflow/core/framework/op.cc:132] Op<name=WriteAudioSummary; signature=writer:resource, step:int64, tag:string, tensor:float, sample_rate:float -> ; attr=max_outputs:int,default=3,min=1; is_stateful=true>
  2023-01-12 09:34:38.343308: I tensorflow/core/framework/op.cc:132] Op<name=WriteFile; signature=filename:string, contents:string -> ; is_stateful=true>
  2023-01-12 09:34:38.343342: I tensorflow/core/framework/op.cc:132] Op<name=WriteGraphSummary; signature=writer:resource, step:int64, tensor:string -> ; is_stateful=true>
  2023-01-12 09:34:38.343449: I tensorflow/core/framework/op.cc:132] Op<name=WriteHistogramSummary; signature=writer:resource, step:int64, tag:string, values:T -> ; attr=T:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64, DT_BOOL]; is_stateful=true>
  2023-01-12 09:34:38.343599: I tensorflow/core/framework/op.cc:132] Op<name=WriteImageSummary; signature=writer:resource, step:int64, tag:string, tensor:T, bad_color:uint8 -> ; attr=max_images:int,default=3,min=1; attr=T:type,default=DT_FLOAT,allowed=[DT_UINT8, DT_DOUBLE, DT_FLOAT, DT_HALF]; is_stateful=true>
  2023-01-12 09:34:38.343692: I tensorflow/core/framework/op.cc:132] Op<name=WriteRawProtoSummary; signature=writer:resource, step:int64, tensor:string -> ; is_stateful=true>
  2023-01-12 09:34:38.343752: I tensorflow/core/framework/op.cc:132] Op<name=WriteScalarSummary; signature=writer:resource, step:int64, tag:string, value:T -> ; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]; is_stateful=true>
  2023-01-12 09:34:38.343794: I tensorflow/core/framework/op.cc:132] Op<name=WriteSummary; signature=writer:resource, step:int64, tensor:T, tag:string, summary_metadata:string -> ; attr=T:type; is_stateful=true>
  2023-01-12 09:34:38.343840: I tensorflow/core/framework/op.cc:132] Op<name=Xdivy; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:38.343971: I tensorflow/core/framework/op.cc:132] Op<name=XlaAllReduce; signature=input:T, group_assignment:int32 -> output:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_INT32, DT_UINT32]; attr=reduce_op:string,allowed=["Min", "Max", "Mul", "Add", "Mean"]; attr=mode:string,allowed=["CrossReplica", "CrossReplicaAndPartition"]>
  2023-01-12 09:34:38.344095: I tensorflow/core/framework/op.cc:132] Op<name=XlaBroadcastHelper; signature=lhs:T, rhs:T, broadcast_dims:Tindices -> lhs_output:T, rhs_output:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.344137: I tensorflow/core/framework/op.cc:132] Op<name=XlaCallModule; signature=args: -> output:; attr=module:string; attr=Sout:list(shape),min=0; attr=Tout:list(type),min=0; attr=Tin:list(type),min=0; attr=dim_args_spec:list(string),min=0>
  2023-01-12 09:34:38.344164: I tensorflow/core/framework/op.cc:132] Op<name=XlaClusterOutput; signature=input:T -> outputs:T; attr=T:type>
  2023-01-12 09:34:38.344195: I tensorflow/core/framework/op.cc:132] Op<name=XlaConcatND; signature=inputs:N*T -> output:T; attr=T:type; attr=N:int,min=1; attr=num_concats:list(int); attr=paddings:list(int),default=[]>
  2023-01-12 09:34:38.344302: I tensorflow/core/framework/op.cc:132] Op<name=XlaConv; signature=lhs:T, rhs:T, window_strides:Tindices, padding:Tindices, lhs_dilation:Tindices, rhs_dilation:Tindices, feature_group_count:Tindices -> output:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=dimension_numbers:string; attr=precision_config:string>
  2023-01-12 09:34:38.344583: I tensorflow/core/framework/op.cc:132] Op<name=XlaConvV2; signature=lhs:LhsT, rhs:RhsT, window_strides:Tindices, padding:Tindices, lhs_dilation:Tindices, rhs_dilation:Tindices, feature_group_count:Tindices -> output:preferred_element_type; attr=LhsT:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=RhsT:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=dimension_numbers:string; attr=precision_config:string; attr=preferred_element_type:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=batch_group_count:int,default=1>
  2023-01-12 09:34:38.344726: I tensorflow/core/framework/op.cc:132] Op<name=XlaCustomCall; signature=args: -> output:dtype; attr=target_name:string; attr=backend_config:string; attr=T:list(type),min=0; attr=dtype:type; attr=shape:shape>
  2023-01-12 09:34:38.344774: I tensorflow/core/framework/op.cc:132] Op<name=XlaCustomCallV2; signature=operands: -> results:; attr=call_target_name:string; attr=backend_config:string; attr=has_side_effect:bool; attr=operand_dtypes:list(type),min=0; attr=result_dtypes:list(type),min=0; attr=result_shapes:list(shape),min=0>
  2023-01-12 09:34:38.344806: I tensorflow/core/framework/op.cc:132] Op<name=XlaDequantize; signature=input:uint32 -> output:bfloat16; attr=min_range:float; attr=max_range:float; attr=mode:string; attr=transpose_output:bool; is_stateful=true>
  2023-01-12 09:34:38.344863: I tensorflow/core/framework/op.cc:132] Op<name=XlaDot; signature=lhs:T, rhs:T -> output:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=dimension_numbers:string; attr=precision_config:string>
  2023-01-12 09:34:38.344993: I tensorflow/core/framework/op.cc:132] Op<name=XlaDotV2; signature=lhs:LhsT, rhs:RhsT -> output:preferred_element_type; attr=LhsT:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=RhsT:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=dimension_numbers:string; attr=precision_config:string; attr=preferred_element_type:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:38.345051: I tensorflow/core/framework/op.cc:132] Op<name=XlaDynamicSlice; signature=input:T, start_indices:Tindices, size_indices:Tindices -> output:T; attr=T:type; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.345105: I tensorflow/core/framework/op.cc:132] Op<name=XlaDynamicUpdateSlice; signature=input:T, update:T, indices:Tindices -> output:T; attr=T:type; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.345226: I tensorflow/core/framework/op.cc:132] Op<name=XlaEinsum; signature=a:T, b:T -> product:T; attr=equation:string; attr=T:type,allowed=[DT_COMPLEX64, DT_BFLOAT16, DT_FLOAT]>
  2023-01-12 09:34:38.345300: I tensorflow/core/framework/op.cc:132] Op<name=XlaGather; signature=operand:T, start_indices:Tindices, slice_sizes:Tindices -> output:T; attr=dimension_numbers:string; attr=indices_are_sorted:bool; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 16534343205130372495, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64, DT_BOOL]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.345354: I tensorflow/core/framework/op.cc:132] Op<name=XlaHostCompute; signature=inputs: -> outputs:; attr=Tinputs:list(type),min=0; attr=Toutputs:list(type),min=0; attr=ancestors:list(string),min=0; attr=shapes:list(shape),min=0; attr=shape_inference_graph:func; attr=key:string; attr=send_key:string,default=""; attr=recv_key:string,default=""; attr=cost_estimate_ns:int,default=1000000; attr=tpu_core:int,default=0; is_stateful=true>
  2023-01-12 09:34:38.345397: I tensorflow/core/framework/op.cc:132] Op<name=XlaIf; signature=cond:Tcond, inputs: -> output:; attr=Tcond:type; attr=then_branch:func; attr=else_branch:func; attr=Tin:list(type),min=0; attr=Tout:list(type),min=0; is_stateful=true>
  2023-01-12 09:34:38.345449: I tensorflow/core/framework/op.cc:132] Op<name=XlaKeyValueSort; signature=keys:K, values:V -> sorted_keys:K, sorted_values:V; attr=K:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]; attr=V:type>
  2023-01-12 09:34:38.345486: I tensorflow/core/framework/op.cc:132] Op<name=XlaLaunch; signature=constants:, args:, resources:Nresources*resource -> results:; attr=Tconstants:list(type),min=0; attr=Targs:list(type),min=0; attr=Nresources:int,min=0; attr=Tresults:list(type),min=0; attr=function:func; is_stateful=true>
  2023-01-12 09:34:38.345512: I tensorflow/core/framework/op.cc:132] Op<name=XlaOptimizationBarrier; signature=input: -> output:; attr=T:list(type),min=0>
  2023-01-12 09:34:38.345556: I tensorflow/core/framework/op.cc:132] Op<name=XlaPad; signature=input:T, padding_value:T, padding_low:Tindices, padding_high:Tindices, padding_interior:Tindices -> output:T; attr=T:type; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.345665: I tensorflow/core/framework/op.cc:132] Op<name=XlaRecv; signature= -> tensor:dtype; attr=dtype:type; attr=tensor_name:string; attr=shape:shape; is_stateful=true>
  2023-01-12 09:34:38.349088: I tensorflow/core/framework/op.cc:132] Op<name=XlaRecvFromHost; signature= -> output:Toutput; attr=Toutput:type; attr=shape:shape; attr=key:string; is_stateful=true>
  2023-01-12 09:34:38.349429: I tensorflow/core/framework/op.cc:132] Op<name=XlaRecvTPUEmbeddingActivations; signature=deduplication_data:variant -> outputs:num_tables*float; attr=num_tables:int,min=1; attr=config:string; is_stateful=true>
  2023-01-12 09:34:38.349470: I tensorflow/core/framework/op.cc:132] Op<name=XlaRecvTPUEmbeddingDeduplicationData; signature= -> output:variant; attr=config:string; is_stateful=true>
  2023-01-12 09:34:38.349712: I tensorflow/core/framework/op.cc:132] Op<name=XlaReduce; signature=input:T, init_value:T -> output:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 16534343205130372495, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64, DT_BOOL]; attr=dimensions_to_reduce:list(int); attr=reducer:func>
  2023-01-12 09:34:38.349881: I tensorflow/core/framework/op.cc:132] Op<name=XlaReducePrecision; signature=operand:T -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=exponent_bits:int; attr=mantissa_bits:int>
  2023-01-12 09:34:38.349938: I tensorflow/core/framework/op.cc:132] Op<name=XlaReduceScatter; signature=input:T, group_assignment:int32, scatter_dimension:int32 -> output:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_INT32, DT_UINT32]; attr=reduce_op:string,allowed=["Min", "Max", "Mul", "Add", "Mean"]>
  2023-01-12 09:34:38.350005: I tensorflow/core/framework/op.cc:132] Op<name=XlaReduceWindow; signature=input:T, init_value:T, window_dimensions:Tindices, window_strides:Tindices, base_dilations:Tindices, window_dilations:Tindices, padding:Tindices -> output:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 16534343205130372495, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64, DT_BOOL]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=computation:func>
  2023-01-12 09:34:38.350077: I tensorflow/core/framework/op.cc:132] Op<name=XlaRemoveDynamicDimensionSize; signature=input:T, dim_index:int32 -> output:T; attr=T:type>
  2023-01-12 09:34:38.350112: I tensorflow/core/framework/op.cc:132] Op<name=XlaReplicaId; signature= -> id:int32>
  2023-01-12 09:34:38.350151: I tensorflow/core/framework/op.cc:132] Op<name=XlaRngBitGenerator; signature=algorithm:int32, initial_state:uint64, shape:Tshape -> output_key:uint64, output:dtype; attr=dtype:type,default=DT_UINT64,allowed=[DT_INT32, DT_INT64, DT_UINT32, DT_UINT64]; attr=Tshape:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.350220: I tensorflow/core/framework/op.cc:132] Op<name=XlaScatter; signature=operand:T, scatter_indices:Tindices, updates:T -> output:T; attr=update_computation:func; attr=dimension_numbers:string; attr=indices_are_sorted:bool; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 16534343205130372495, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64, DT_BOOL]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.350322: I tensorflow/core/framework/op.cc:132] Op<name=XlaSelectAndScatter; signature=operand:T, window_dimensions:Tindices, window_strides:Tindices, padding:Tindices, source:T, init_value:T -> output:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=select:func; attr=scatter:func>
  2023-01-12 09:34:38.350515: I tensorflow/core/framework/op.cc:132] Op<name=XlaSelfAdjointEig; signature=a:T -> w:T, v:T; attr=lower:bool; attr=max_iter:int; attr=epsilon:float; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:38.350580: I tensorflow/core/framework/op.cc:132] Op<name=XlaSend; signature=tensor:T -> ; attr=T:type; attr=tensor_name:string; is_stateful=true>
  2023-01-12 09:34:38.350639: I tensorflow/core/framework/op.cc:132] Op<name=XlaSendTPUEmbeddingGradients; signature=gradients:NumTables*float, learning_rates:NumLearningRateTags*float, deduplication_data:variant -> ; attr=NumTables:int,min=1; attr=NumLearningRateTags:int,default=0,min=0; attr=config:string; is_stateful=true>
  2023-01-12 09:34:38.350926: I tensorflow/core/framework/op.cc:132] Op<name=XlaSendToHost; signature=input:Tinput -> ; attr=Tinput:type; attr=key:string; is_stateful=true>
  2023-01-12 09:34:38.350965: I tensorflow/core/framework/op.cc:132] Op<name=XlaSetBound; signature=input:int32, bound:int32 -> output:int32>
  2023-01-12 09:34:38.350991: I tensorflow/core/framework/op.cc:132] Op<name=XlaSetDynamicDimensionSize; signature=input:T, dim_index:int32, size:int32 -> output:T; attr=T:type>
  2023-01-12 09:34:38.351017: I tensorflow/core/framework/op.cc:132] Op<name=XlaSharding; signature=input:T -> output:T; attr=T:type; attr=sharding:string,default=""; attr=unspecified_dims:list(int),default=[]>
  2023-01-12 09:34:38.351036: I tensorflow/core/framework/op.cc:132] Op<name=XlaSort; signature=input:T -> output:T; attr=T:type>
  2023-01-12 09:34:38.351055: I tensorflow/core/framework/op.cc:132] Op<name=XlaSplitND; signature=input:T -> outputs:N*T; attr=T:type; attr=N:int,min=1; attr=num_splits:list(int); attr=paddings:list(int),default=[]>
  2023-01-12 09:34:38.351075: I tensorflow/core/framework/op.cc:132] Op<name=XlaSpmdFullToShardShape; signature=input:T -> output:T; attr=T:type; attr=manual_sharding:string; attr=dim:int,default=-1; attr=unspecified_dims:list(int),default=[]>
  2023-01-12 09:34:38.351094: I tensorflow/core/framework/op.cc:132] Op<name=XlaSpmdShardToFullShape; signature=input:T -> output:T; attr=T:type; attr=manual_sharding:string; attr=full_shape:shape; attr=dim:int,default=-1; attr=unspecified_dims:list(int),default=[]>
  2023-01-12 09:34:38.351131: I tensorflow/core/framework/op.cc:132] Op<name=XlaSvd; signature=a:T -> s:T, u:T, v:T; attr=max_iter:int; attr=epsilon:float; attr=precision_config:string; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:38.351166: I tensorflow/core/framework/op.cc:132] Op<name=XlaVariadicReduce; signature=input:N*T, init_value:N*T -> output:N*T; attr=N:int,min=1; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 16534343205130372495, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64, DT_BOOL]; attr=dimensions_to_reduce:list(int); attr=reducer:func>
  2023-01-12 09:34:38.351212: I tensorflow/core/framework/op.cc:132] Op<name=XlaVariadicReduceV2; signature=inputs:, init_values: -> outputs:; attr=T:list(type),min=1; attr=dimensions_to_reduce:list(int); attr=reducer:func>
  2023-01-12 09:34:38.351234: I tensorflow/core/framework/op.cc:132] Op<name=XlaVariadicSort; signature=inputs:, dimension:int32 -> outputs:; attr=T:list(type),min=1; attr=comparator:func; attr=is_stable:bool>
  2023-01-12 09:34:38.351250: I tensorflow/core/framework/op.cc:132] Op<name=XlaWhile; signature=input: -> output:; attr=T:list(type),min=0; attr=cond:func; attr=body:func; is_stateful=true>
  2023-01-12 09:34:38.351273: I tensorflow/core/framework/op.cc:132] Op<name=Xlog1py; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:38.351304: I tensorflow/core/framework/op.cc:132] Op<name=Xlogy; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:38.351340: I tensorflow/core/framework/op.cc:132] Op<name=ZerosLike; signature=x:T -> y:T; attr=T:type>
  2023-01-12 09:34:38.351367: I tensorflow/core/framework/op.cc:132] Op<name=Zeta; signature=x:T, q:T -> z:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:38.351389: I tensorflow/core/framework/op.cc:132] Op<name=ZipDataset; signature=input_datasets:N*variant -> handle:variant; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=N:int,min=1; attr=metadata:string,default="">
  2023-01-12 09:34:38.351406: I tensorflow/core/framework/op.cc:132] Op<name=_Arg; signature= -> output:T; attr=T:type; attr=index:int,min=0; is_stateful=true>
  2023-01-12 09:34:38.351475: I tensorflow/core/framework/op.cc:132] Op<name=_ArrayToList; signature=input:N*T -> output:; attr=T:type; attr=N:int,min=1; attr=out_types:list(type),min=1>
  2023-01-12 09:34:38.351534: I tensorflow/core/framework/op.cc:132] Op<name=_ConfigureDistributedTPU; signature=inputs:N*int32 -> output:string; attr=N:int,min=1; attr=enable_whole_mesh_compilations:bool,default=false; is_stateful=true>
  2023-01-12 09:34:38.351576: I tensorflow/core/framework/op.cc:132] Op<name=_DeviceArg; signature= -> output:T; attr=T:type; attr=index:int,min=0; is_stateful=true>
  2023-01-12 09:34:38.351611: I tensorflow/core/framework/op.cc:132] Op<name=_DeviceRetval; signature=input:T -> ; attr=T:type; attr=index:int,min=0; is_stateful=true>
  2023-01-12 09:34:38.351643: I tensorflow/core/framework/op.cc:132] Op<name=_DisconnectHostFromDistributedTPUSystem; signature= -> number_of_tpu_chips:int32; is_stateful=true>
  2023-01-12 09:34:38.351675: I tensorflow/core/framework/op.cc:132] Op<name=_EagerConst; signature=input:T -> output:T; attr=T:type>
  2023-01-12 09:34:38.351766: I tensorflow/core/framework/op.cc:132] Op<name=_FusedBatchNormEx; signature=x:T, scale:U, offset:U, mean:U, variance:U, side_input:num_side_inputs*T -> y:T, batch_mean:U, batch_variance:U, reserve_space_1:U, reserve_space_2:U, reserve_space_3:U; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_BFLOAT16]; attr=U:type,allowed=[DT_FLOAT]; attr=epsilon:float,default=0.0001; attr=exponential_avg_factor:float,default=1; attr=num_side_inputs:int,default=0,min=0; attr=activation_mode:string,default="Identity"; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=is_training:bool,default=true>
  2023-01-12 09:34:38.351851: I tensorflow/core/framework/op.cc:132] Op<name=_FusedBatchNormGradEx; signature=y_backprop:T, x:T, scale:float, reserve_space_1:U, reserve_space_2:U, reserve_space_3:U, offset:float, y:T -> x_backprop:T, scale_backprop:U, offset_backprop:U, reserve_space_4:U, reserve_space_5:U, side_input_backprop:num_side_inputs*T; attr=T:type,allowed=[DT_HALF, DT_FLOAT]; attr=U:type,allowed=[DT_FLOAT]; attr=epsilon:float,default=0.0001; attr=num_side_inputs:int,default=0,min=0; attr=activation_mode:string,default="Identity"; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW", "NDHWC", "NCDHW"]; attr=is_training:bool,default=true>
  2023-01-12 09:34:38.351944: I tensorflow/core/framework/op.cc:132] Op<name=_FusedConv2D; signature=input:T, filter:T, args:, host_args:num_host_args*float -> output:T; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT8, DT_QINT8]; attr=TArgs:list(type),min=1; attr=num_args:int,min=0; attr=num_host_args:int,default=0,min=0; attr=strides:list(int); attr=padding:string,allowed=["SAME", "VALID", "EXPLICIT"]; attr=explicit_paddings:list(int),default=[]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW", "NCHW_VECT_C"]; attr=filter_format:string,default="HWIO",allowed=["HWIO", "OIHW", "OIHW_VECT_I"]; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=use_cudnn_on_gpu:bool,default=true; attr=fused_ops:list(string),default=[]; attr=epsilon:float,default=0.0001; attr=leakyrelu_alpha:float,default=0.2>
  2023-01-12 09:34:38.352001: I tensorflow/core/framework/op.cc:132] Op<name=_FusedConv3D; signature=input:T, filter:T, args:num_args*T -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=num_args:int,min=0; attr=strides:list(int),min=5; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NDHWC",allowed=["NDHWC", "NCDHW"]; attr=dilations:list(int),default=[1, 1, 1, 1, 1]; attr=padding_list:list(int),default=[]; attr=fused_ops:list(string),default=[]; attr=epsilon:float,default=0.0001; attr=leakyrelu_alpha:float,default=0.2>
  2023-01-12 09:34:38.352045: I tensorflow/core/framework/op.cc:132] Op<name=_FusedDepthwiseConv2dNative; signature=input:T, filter:T, args:num_args*T -> output:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]; attr=num_args:int,min=0; attr=strides:list(int); attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=fused_ops:list(string),default=[]; attr=epsilon:float,default=0.0001; attr=leakyrelu_alpha:float,default=0.2>
  2023-01-12 09:34:38.352080: I tensorflow/core/framework/op.cc:132] Op<name=_FusedMatMul; signature=a:T, b:T, args:num_args*T -> product:T; attr=transpose_a:bool,default=false; attr=transpose_b:bool,default=false; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT]; attr=num_args:int,min=0; attr=fused_ops:list(string),default=[]; attr=epsilon:float,default=0.0001; attr=leakyrelu_alpha:float,default=0.2>
  2023-01-12 09:34:38.352141: I tensorflow/core/framework/op.cc:132] Op<name=_FusedQuantizedConv2D; signature=device_inputs:, host_inputs: -> device_outputs:, host_outputs:; attr=Tinput:type,default=DT_QUINT8,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tfilter:type,default=DT_QINT8,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tbias:type,default=DT_QINT32,allowed=[DT_FLOAT, DT_QINT32]; attr=Tsummand:type,allowed=[DT_FLOAT, DT_QUINT8, DT_QINT8, DT_QINT32]; attr=out_type:type,default=DT_QINT32,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tdevice_inputs:list(type),default=[],min=0; attr=Thost_inputs:list(type),min=0; attr=Tdevice_outputs:list(type),default=[],min=0; attr=Thost_outputs:list(type),min=0; attr=data_format:string,default="NHWC"; attr=strides:list(int); attr=is_filter_const:bool,default=true; attr=is_bias_const:bool,default=true; attr=padding:string,allowed=["SAME", "VALID", "EXPLICIT"]; attr=explicit_paddings:list(int),default=[]; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=fused_ops:list(string),default=[]; attr=alpha:float,default=0>
  2023-01-12 09:34:38.352397: I tensorflow/core/framework/op.cc:132] Op<name=_FusedQuantizedDepthwiseConv2D; signature=device_inputs:, host_inputs: -> device_outputs:, host_outputs:; attr=Tinput:type,default=DT_QUINT8,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tfilter:type,default=DT_QINT8,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tbias:type,default=DT_QINT32,allowed=[DT_FLOAT, DT_QINT32]; attr=Tsummand:type,allowed=[DT_FLOAT, DT_QUINT8, DT_QINT8, DT_QINT32]; attr=out_type:type,default=DT_QINT32,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tdevice_inputs:list(type),default=[],min=0; attr=Thost_inputs:list(type),min=0; attr=Tdevice_outputs:list(type),default=[],min=0; attr=Thost_outputs:list(type),min=0; attr=data_format:string,default="NHWC"; attr=strides:list(int); attr=is_filter_const:bool,default=true; attr=is_bias_const:bool,default=true; attr=padding:string,allowed=["SAME", "VALID", "EXPLICIT"]; attr=explicit_paddings:list(int),default=[]; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=fused_ops:list(string),default=[]; attr=alpha:float,default=0>
  2023-01-12 09:34:38.352464: I tensorflow/core/framework/op.cc:132] Op<name=_HostCast; signature=x:SrcT -> y:DstT; attr=SrcT:type; attr=DstT:type; attr=Truncate:bool,default=false>
  2023-01-12 09:34:38.352668: I tensorflow/core/framework/op.cc:132] Op<name=_HostRecv; signature= -> tensor:tensor_type; attr=tensor_type:type; attr=tensor_name:string; attr=send_device:string; attr=send_device_incarnation:int; attr=recv_device:string; attr=client_terminated:bool,default=false; is_stateful=true; is_distributed_communication=true>
  2023-01-12 09:34:38.352751: I tensorflow/core/framework/op.cc:132] Op<name=_HostSend; signature=tensor:T -> ; attr=T:type; attr=tensor_name:string; attr=send_device:string; attr=send_device_incarnation:int; attr=recv_device:string; attr=client_terminated:bool,default=false; is_stateful=true>
  2023-01-12 09:34:38.352938: I tensorflow/core/framework/op.cc:132] Op<name=_If; signature=cond:Tcond, input: -> output:; attr=Tcond:type; attr=Tin:list(type),min=1; attr=Tout:list(type),min=1; attr=then_branch:func; attr=else_branch:func; is_stateful=true>
  2023-01-12 09:34:38.353296: I tensorflow/core/framework/op.cc:132] Op<name=_InitializeHostForDistributedTPU; signature=input:string -> tpu_ids:int32; attr=enable_whole_mesh_compilations:bool,default=false; attr=tpu_cancellation_closes_chips:int,default=0; is_stateful=true>
  2023-01-12 09:34:38.353403: I tensorflow/core/framework/op.cc:132] Op<name=_ListToArray; signature=input: -> output:N*T; attr=Tin:list(type),min=1; attr=T:type; attr=N:int,min=1>
  2023-01-12 09:34:38.353764: I tensorflow/core/framework/op.cc:132] Op<name=_MklAdd; signature=x:T, y:T, mkl_x:uint8, mkl_y:uint8 -> z:T, mkl_z:uint8; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_INT16, DT_INT32, DT_INT64, DT_COMPLEX64, DT_COMPLEX128, DT_STRING, DT_BFLOAT16]>
  2023-01-12 09:34:38.353895: I tensorflow/core/framework/op.cc:132] Op<name=_MklAddN; signature=inputs:N*T, mkl_input:N*uint8 -> sum:T, mkl_sum:uint8; attr=N:int,min=1; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:38.353974: I tensorflow/core/framework/op.cc:132] Op<name=_MklAddV2; signature=x:T, y:T, mkl_x:uint8, mkl_y:uint8 -> z:T, mkl_z:uint8; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_INT16, DT_INT32, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]; is_commutative=true; is_aggregate=true>
  2023-01-12 09:34:38.354054: I tensorflow/core/framework/op.cc:132] Op<name=_MklAvgPool; signature=value:T, mkl_input:uint8 -> output:T, mkl_output:uint8; attr=ksize:list(int),min=4; attr=strides:list(int),min=4; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=T:type,allowed=[DT_FLOAT, DT_HALF, DT_DOUBLE, DT_BFLOAT16]>
  2023-01-12 09:34:38.354166: I tensorflow/core/framework/op.cc:132] Op<name=_MklAvgPool3D; signature=value:T, mkl_input:uint8 -> output:T, mkl_output:uint8; attr=ksize:list(int),min=5; attr=strides:list(int),min=5; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NDHWC",allowed=["NDHWC", "NCDHW"]; attr=T:type,allowed=[DT_FLOAT, DT_HALF, DT_DOUBLE, DT_BFLOAT16]>
  2023-01-12 09:34:38.354230: I tensorflow/core/framework/op.cc:132] Op<name=_MklAvgPool3DGrad; signature=orig_input_shape:int32, grad:T, mkl_orig_input:uint8, mkl_grad:uint8 -> output:T, mkl_output:uint8; attr=ksize:list(int),min=5; attr=strides:list(int),min=5; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NDHWC",allowed=["NDHWC", "NCDHW"]; attr=T:type,allowed=[DT_FLOAT, DT_HALF, DT_DOUBLE, DT_BFLOAT16]>
  2023-01-12 09:34:38.354319: I tensorflow/core/framework/op.cc:132] Op<name=_MklAvgPoolGrad; signature=orig_input_shape:int32, grad:T, mkl_orig_input:uint8, mkl_grad:uint8 -> output:T, mkl_output:uint8; attr=ksize:list(int),min=4; attr=strides:list(int),min=4; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=T:type,allowed=[DT_FLOAT, DT_HALF, DT_DOUBLE, DT_BFLOAT16]>
  2023-01-12 09:34:38.354503: I tensorflow/core/framework/op.cc:132] Op<name=_MklBatchMatMul; signature=x:T, y:T -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=adj_x:bool,default=false; attr=adj_y:bool,default=false>
  2023-01-12 09:34:38.354742: I tensorflow/core/framework/op.cc:132] Op<name=_MklBatchMatMulV2; signature=x:T, y:T -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=adj_x:bool,default=false; attr=adj_y:bool,default=false>
  2023-01-12 09:34:38.354885: I tensorflow/core/framework/op.cc:132] Op<name=_MklConcat; signature=concat_dim:int32, values:N*T, mkl_concat_dim:uint8, mkl_values:N*uint8 -> output:T, mkl_output:uint8; attr=N:int,min=2; attr=T:type>
  2023-01-12 09:34:38.355003: I tensorflow/core/framework/op.cc:132] Op<name=_MklConcatV2; signature=values:N*T, axis:Tidx, mkl_values:N*uint8, mkl_axis:uint8 -> output:T, mkl_output:uint8; attr=N:int,min=2; attr=T:type; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.355077: I tensorflow/core/framework/op.cc:132] Op<name=_MklConjugateTranspose; signature=x:T, perm:Tperm -> y:T; attr=T:type; attr=Tperm:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.355191: I tensorflow/core/framework/op.cc:132] Op<name=_MklConv2D; signature=input:T, filter:T, mkl_input:uint8, mkl_filter:uint8 -> output:T, filter_output:T, mkl_output:uint8, mkl_filter_output:uint8; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=strides:list(int); attr=use_cudnn_on_gpu:bool,default=true; attr=is_filter_const:bool,default=false; attr=padding:string,allowed=["SAME", "VALID", "EXPLICIT"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=explicit_paddings:list(int),default=[]; attr=dilations:list(int),default=[1, 1, 1, 1]>
  2023-01-12 09:34:38.355380: I tensorflow/core/framework/op.cc:132] Op<name=_MklConv2DBackpropFilter; signature=input:T, filter_sizes:int32, out_backprop:T, mkl_input:uint8, mkl_filter_size:uint8, mkl_out_backprop:uint8 -> output:T, mkl_output:uint8; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=strides:list(int); attr=use_cudnn_on_gpu:bool,default=true; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=explicit_paddings:list(int),default=[]; attr=dilations:list(int),default=[1, 1, 1, 1]>
  2023-01-12 09:34:38.355808: I tensorflow/core/framework/op.cc:132] Op<name=_MklConv2DBackpropFilterWithBias; signature=input:T, filter_sizes:int32, out_backprop:T, mkl_input:uint8, mkl_filter_size:uint8, mkl_out_backprop:uint8 -> output:T, bias_grad:T, mkl_output:uint8, mkl_bias_grad:uint8; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=strides:list(int); attr=use_cudnn_on_gpu:bool,default=true; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=dilations:list(int),default=[1, 1, 1, 1]>
  2023-01-12 09:34:38.356886: I tensorflow/core/framework/op.cc:132] Op<name=_MklConv2DBackpropInput; signature=input_sizes:int32, filter:T, out_backprop:T, mkl_input_sizes:uint8, mkl_filter:uint8, mkl_out_backprop:uint8 -> output:T, mkl_output:uint8; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=strides:list(int); attr=use_cudnn_on_gpu:bool,default=true; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=explicit_paddings:list(int),default=[]; attr=dilations:list(int),default=[1, 1, 1, 1]>
  2023-01-12 09:34:38.357175: I tensorflow/core/framework/op.cc:132] Op<name=_MklConv2DWithBias; signature=input:T, filter:T, bias:T, mkl_input:uint8, mkl_filter:uint8, mkl_bias:uint8 -> output:T, filter_output:T, mkl_output:uint8, mkl_filter_output:uint8; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=strides:list(int); attr=use_cudnn_on_gpu:bool,default=true; attr=is_filter_const:bool,default=false; attr=padding:string,allowed=["SAME", "VALID", "EXPLICIT"]; attr=explicit_paddings:list(int),default=[]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=dilations:list(int),default=[1, 1, 1, 1]>
  2023-01-12 09:34:38.357310: I tensorflow/core/framework/op.cc:132] Op<name=_MklConv3D; signature=input:T, filter:T, mkl_input:uint8, mkl_filter:uint8 -> output:T, filter_output:T, mkl_output:uint8, mkl_filter_output:uint8; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=strides:list(int),min=5; attr=is_filter_const:bool,default=false; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NDHWC",allowed=["NDHWC", "NCDHW"]; attr=dilations:list(int),default=[1, 1, 1, 1, 1]>
  2023-01-12 09:34:38.357385: I tensorflow/core/framework/op.cc:132] Op<name=_MklConv3DBackpropFilterV2; signature=input:T, filter_sizes:int32, out_backprop:T, mkl_input:uint8, mkl_filter_size:uint8, mkl_out_backprop:uint8 -> output:T, mkl_output:uint8; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=strides:list(int); attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NDHWC",allowed=["NDHWC", "NCDHW"]; attr=dilations:list(int),default=[1, 1, 1, 1, 1]>
  2023-01-12 09:34:38.357690: I tensorflow/core/framework/op.cc:132] Op<name=_MklConv3DBackpropInputV2; signature=input_sizes:Tshape, filter:T, out_backprop:T, mkl_input_sizes:uint8, mkl_filter:uint8, mkl_out_backprop:uint8 -> output:T, mkl_output:uint8; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=strides:list(int),min=5; attr=dilations:list(int),default=[1, 1, 1, 1, 1]; attr=Tshape:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NDHWC",allowed=["NDHWC", "NCDHW"]>
  2023-01-12 09:34:38.357836: I tensorflow/core/framework/op.cc:132] Op<name=_MklDepthwiseConv2dNative; signature=input:T, filter:T, mkl_input:uint8, mkl_filter:uint8 -> output:T, filter_output:T, mkl_output:uint8, mkl_filter_output:uint8; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]; attr=strides:list(int); attr=is_filter_const:bool,default=false; attr=padding:string,allowed=["SAME", "VALID", "EXPLICIT"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=explicit_paddings:list(int),default=[]; attr=dilations:list(int),default=[1, 1, 1, 1]>
  2023-01-12 09:34:38.358224: I tensorflow/core/framework/op.cc:132] Op<name=_MklDepthwiseConv2dNativeBackpropFilter; signature=input:T, filter_sizes:int32, out_backprop:T, mkl_input:uint8, mkl_filter:uint8, mkl_out_backprop:uint8 -> output:T, mkl_output:uint8; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]; attr=strides:list(int); attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=explicit_paddings:list(int),default=[]; attr=dilations:list(int),default=[1, 1, 1, 1]>
  2023-01-12 09:34:38.358331: I tensorflow/core/framework/op.cc:132] Op<name=_MklDepthwiseConv2dNativeBackpropInput; signature=input_sizes:int32, filter:T, out_backprop:T, mkl_input:uint8, mkl_filter:uint8, mkl_out_backprop:uint8 -> output:T, mkl_output:uint8; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]; attr=strides:list(int); attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=explicit_paddings:list(int),default=[]; attr=dilations:list(int),default=[1, 1, 1, 1]>
  2023-01-12 09:34:38.358422: I tensorflow/core/framework/op.cc:132] Op<name=_MklDequantize; signature=input:T, min_range:float, max_range:float -> output:float; attr=T:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=narrow_range:bool,default=false; attr=axis:int,default=-1; attr=mode:string,default="SCALED",allowed=["MIN_COMBINED", "MIN_FIRST", "SCALED"]; attr=dtype:type,default=DT_FLOAT,allowed=[DT_BFLOAT16, DT_FLOAT]>
  2023-01-12 09:34:38.358527: I tensorflow/core/framework/op.cc:132] Op<name=_MklEinsum; signature=inputs:N*T -> output:T; attr=equation:string; attr=N:int,min=1; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]>
  2023-01-12 09:34:38.358595: I tensorflow/core/framework/op.cc:132] Op<name=_MklElu; signature=features:T, mkl_features:uint8 -> activations:T, mkl_activations:uint8; attr=T:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_BFLOAT16]>
  2023-01-12 09:34:38.358964: I tensorflow/core/framework/op.cc:132] Op<name=_MklEluGrad; signature=gradients:T, features:T, mkl_gradients:uint8, mkl_features:uint8 -> backprops:T, mkl_backprops:uint8; attr=T:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_BFLOAT16]>
  2023-01-12 09:34:38.359294: I tensorflow/core/framework/op.cc:132] Op<name=_MklFusedBatchMatMulV2; signature=x:T, y:T, args:num_args*T -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=adj_x:bool,default=false; attr=adj_y:bool,default=false; attr=num_args:int,min=0; attr=fused_ops:list(string),default=[]>
  2023-01-12 09:34:38.359659: I tensorflow/core/framework/op.cc:132] Op<name=_MklFusedBatchNorm; signature=x:T, scale:T, offset:T, mean:T, variance:T, mkl_x:uint8, mkl_scale:uint8, mkl_offset:uint8, mkl_mean:uint8, mkl_variance:uint8 -> y:T, batch_mean:T, batch_variance:T, reserve_space_1:T, reserve_space_2:T, mkl_y:uint8, mkl_batch_mean:uint8, mkl_batch_variance:uint8, mkl_reserve_space_1:uint8, mkl_reserve_space_2:uint8; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=epsilon:float,default=0.0001; attr=data_format:string,default="NHWC"; attr=exponential_avg_factor:float,default=1; attr=is_training:bool,default=true>
  2023-01-12 09:34:38.359946: I tensorflow/core/framework/op.cc:132] Op<name=_MklFusedBatchNormEx; signature=x:T, scale:U, offset:U, mean:U, variance:U, side_input:num_side_inputs*T, mkl_x:uint8, mkl_scale:uint8, mkl_offset:uint8, mkl_mean:uint8, mkl_variance:uint8, mkl_side_input:num_side_inputs*uint8 -> y:T, batch_mean:U, batch_variance:U, reserve_space_1:U, reserve_space_2:U, reserve_space_3:U, mkl_y:uint8, mkl_batch_mean:uint8, mkl_batch_variance:uint8, mkl_reserve_space_1:uint8, mkl_reserve_space_2:uint8, mkl_reserve_space_3:uint8; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=U:type,allowed=[DT_FLOAT]; attr=epsilon:float,default=0.0001; attr=exponential_avg_factor:float,default=1; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=num_side_inputs:int,default=0,min=0; attr=activation_mode:string,default="Identity"; attr=is_training:bool,default=true>
  2023-01-12 09:34:38.360388: I tensorflow/core/framework/op.cc:132] Op<name=_MklFusedBatchNormGrad; signature=y_backprop:T, x:T, scale:T, reserve_space_1:T, reserve_space_2:T, mkl_y_backprop:uint8, mkl_x:uint8, mkl_scale:uint8, mkl_reserve_space_1:uint8, mkl_reserve_space_2:uint8 -> x_backprop:T, scale_backprop:T, offset_backprop:T, reserve_space_3:T, reserve_space_4:T, mkl_x_backprop:uint8, mkl_scale_backprop:uint8, mkl_offset_backprop:uint8, mkl_reserve_space_3:uint8, mkl_reserve_space_4:uint8; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=epsilon:float,default=0.0001; attr=data_format:string,default="NHWC"; attr=is_training:bool,default=true>
  2023-01-12 09:34:38.360771: I tensorflow/core/framework/op.cc:132] Op<name=_MklFusedBatchNormGradV2; signature=y_backprop:T, x:T, scale:float, reserve_space_1:U, reserve_space_2:U, mkl_y_backprop:uint8, mkl_x:uint8, mkl_scale:uint8, mkl_reserve_space_1:uint8, mkl_reserve_space_2:uint8 -> x_backprop:T, scale_backprop:U, offset_backprop:U, reserve_space_3:U, reserve_space_4:U, mkl_x_backprop:uint8, mkl_scale_backprop:uint8, mkl_offset_backprop:uint8, mkl_reserve_space_3:uint8, mkl_reserve_space_4:uint8; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=U:type,allowed=[DT_FLOAT]; attr=epsilon:float,default=0.0001; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=is_training:bool,default=true>
  2023-01-12 09:34:38.360961: I tensorflow/core/framework/op.cc:132] Op<name=_MklFusedBatchNormGradV3; signature=y_backprop:T, x:T, scale:float, reserve_space_1:U, reserve_space_2:U, reserve_space_3:U, mkl_y_backprop:uint8, mkl_x:uint8, mkl_scale:uint8, mkl_reserve_space_1:uint8, mkl_reserve_space_2:uint8, mkl_reserve_space_3:uint8 -> x_backprop:T, scale_backprop:U, offset_backprop:U, reserve_space_4:U, reserve_space_5:U, mkl_x_backprop:uint8, mkl_scale_backprop:uint8, mkl_offset_backprop:uint8, mkl_reserve_space_4:uint8, mkl_reserve_space_5:uint8; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT]; attr=U:type,allowed=[DT_FLOAT]; attr=epsilon:float,default=0.0001; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=is_training:bool,default=true>
  2023-01-12 09:34:38.361338: I tensorflow/core/framework/op.cc:132] Op<name=_MklFusedBatchNormV2; signature=x:T, scale:U, offset:U, mean:U, variance:U, mkl_x:uint8, mkl_scale:uint8, mkl_offset:uint8, mkl_mean:uint8, mkl_variance:uint8 -> y:T, batch_mean:U, batch_variance:U, reserve_space_1:U, reserve_space_2:U, mkl_y:uint8, mkl_batch_mean:uint8, mkl_batch_variance:uint8, mkl_reserve_space_1:uint8, mkl_reserve_space_2:uint8; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=U:type,allowed=[DT_FLOAT]; attr=epsilon:float,default=0.0001; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=exponential_avg_factor:float,default=1; attr=is_training:bool,default=true>
  2023-01-12 09:34:38.363237: I tensorflow/core/framework/op.cc:132] Op<name=_MklFusedBatchNormV3; signature=x:T, scale:U, offset:U, mean:U, variance:U, mkl_x:uint8, mkl_scale:uint8, mkl_offset:uint8, mkl_mean:uint8, mkl_variance:uint8 -> y:T, batch_mean:U, batch_variance:U, reserve_space_1:U, reserve_space_2:U, reserve_space_3:U, mkl_y:uint8, mkl_batch_mean:uint8, mkl_batch_variance:uint8, mkl_reserve_space_1:uint8, mkl_reserve_space_2:uint8, mkl_reserve_space_3:uint8; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT]; attr=U:type,allowed=[DT_FLOAT]; attr=epsilon:float,default=0.0001; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=exponential_avg_factor:float,default=1; attr=is_training:bool,default=true>
  2023-01-12 09:34:38.364040: I tensorflow/core/framework/op.cc:132] Op<name=_MklFusedConv2D; signature=input:T, filter:T, args:num_args*T, mkl_input:uint8, mkl_filter:uint8, mkl_args:num_args*uint8 -> output:T, filter_output:T, mkl_output:uint8, mkl_filter_output:uint8; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=num_args:int,min=0; attr=strides:list(int); attr=is_filter_const:bool,default=false; attr=padding:string,allowed=["SAME", "VALID", "EXPLICIT"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=explicit_paddings:list(int),default=[]; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=use_cudnn_on_gpu:bool,default=true; attr=fused_ops:list(string),default=[]; attr=epsilon:float,default=0.0001; attr=leakyrelu_alpha:float,default=0.2>
  2023-01-12 09:34:38.364197: I tensorflow/core/framework/op.cc:132] Op<name=_MklFusedDepthwiseConv2dNative; signature=input:T, filter:T, args:num_args*T, mkl_input:uint8, mkl_filter:uint8, mkl_args:num_args*uint8 -> output:T, filter_output:T, mkl_output:uint8, mkl_filter_output:uint8; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=num_args:int,min=0; attr=strides:list(int); attr=is_filter_const:bool,default=false; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=fused_ops:list(string),default=[]; attr=epsilon:float,default=0.0001; attr=leakyrelu_alpha:float,default=0.2>
  2023-01-12 09:34:38.364285: I tensorflow/core/framework/op.cc:132] Op<name=_MklFusedMatMul; signature=a:T, b:T, args:num_args*T, mkl_a:uint8, mkl_b:uint8, mkl_args:num_args*uint8 -> product:T, mkl_product:uint8; attr=is_filter_const:bool,default=false; attr=transpose_a:bool,default=false; attr=transpose_b:bool,default=false; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=num_args:int,min=0; attr=fused_ops:list(string),default=[]; attr=epsilon:float,default=0.0001; attr=leakyrelu_alpha:float,default=0.2>
  2023-01-12 09:34:38.364347: I tensorflow/core/framework/op.cc:132] Op<name=_MklFusedMish; signature=features:T -> activations:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]>
  2023-01-12 09:34:38.364434: I tensorflow/core/framework/op.cc:132] Op<name=_MklIdentity; signature=input:T, mkl_input:uint8 -> output:T, mkl_output:uint8; attr=T:type>
  2023-01-12 09:34:38.364587: I tensorflow/core/framework/op.cc:132] Op<name=_MklInputConversion; signature=input_0:T, input_1:T, mkl_input_0:uint8, mkl_input_1:uint8 -> output_0:T, output_1:T, mkl_output_0:uint8, mkl_output_1:uint8; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_BFLOAT16, DT_DOUBLE, DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_INT32, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW", "NDHWC", "NCDHW"]>
  2023-01-12 09:34:38.364727: I tensorflow/core/framework/op.cc:132] Op<name=_MklLRN; signature=input:T, mkl_input:uint8 -> output:T, workspace:uint8, mkl_output:uint8, mkl_workspace:uint8; attr=depth_radius:int,default=5; attr=bias:float,default=1; attr=alpha:float,default=1; attr=beta:float,default=0.5; attr=workspace_enabled:bool,default=false; attr=T:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_HALF]>
  2023-01-12 09:34:38.364772: I tensorflow/core/framework/op.cc:132] Op<name=_MklLRNGrad; signature=input_grads:T, input_image:T, output_image:T, workspace:uint8, mkl_input_grads:uint8, mkl_input_image:uint8, mkl_output_image:uint8, mkl_workspace:uint8 -> output:T, mkl_output:uint8; attr=depth_radius:int,default=5; attr=bias:float,default=1; attr=alpha:float,default=1; attr=beta:float,default=0.5; attr=workspace_enabled:bool,default=false; attr=T:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_HALF]>
  2023-01-12 09:34:38.364804: I tensorflow/core/framework/op.cc:132] Op<name=_MklLayerNorm; signature=x:T, scale:T, offset:T -> y:T; attr=T:type,allowed=[DT_FLOAT, DT_BFLOAT16]; attr=epsilon:float,default=0.001>
  2023-01-12 09:34:38.364851: I tensorflow/core/framework/op.cc:132] Op<name=_MklLeakyRelu; signature=features:T, mkl_features:uint8 -> activations:T, mkl_activations:uint8; attr=T:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_BFLOAT16]; attr=alpha:float,default=0.2>
  2023-01-12 09:34:38.364884: I tensorflow/core/framework/op.cc:132] Op<name=_MklLeakyReluGrad; signature=gradients:T, features:T, mkl_gradients:uint8, mkl_features:uint8 -> backprops:T, mkl_backprops:uint8; attr=T:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_BFLOAT16]; attr=alpha:float,default=0.2>
  2023-01-12 09:34:38.364910: I tensorflow/core/framework/op.cc:132] Op<name=_MklMatMul; signature=a:T, b:T -> product:T; attr=transpose_a:bool,default=false; attr=transpose_b:bool,default=false; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]>
  2023-01-12 09:34:38.364946: I tensorflow/core/framework/op.cc:132] Op<name=_MklMaxPool; signature=input:T, mkl_input:uint8 -> output:T, workspace:uint8, mkl_output:uint8, mkl_workspace:uint8; attr=T:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_HALF, DT_BFLOAT16]; attr=ksize:list(int),min=4; attr=strides:list(int),min=4; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=explicit_paddings:list(int),default=[]; attr=workspace_enabled:bool,default=false>
  2023-01-12 09:34:38.364981: I tensorflow/core/framework/op.cc:132] Op<name=_MklMaxPool3D; signature=input:T, mkl_input:uint8 -> output:T, workspace:uint8, mkl_output:uint8, mkl_workspace:uint8; attr=ksize:list(int),min=5; attr=strides:list(int),min=5; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NDHWC",allowed=["NDHWC", "NCDHW"]; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT]; attr=workspace_enabled:bool,default=false>
  2023-01-12 09:34:38.365020: I tensorflow/core/framework/op.cc:132] Op<name=_MklMaxPool3DGrad; signature=orig_input:TInput, orig_output:TInput, grad:T, workspace:uint8, mkl_orig_input:uint8, mkl_orig_output:uint8, mkl_grad:uint8, mkl_workspace:uint8 -> output:T, mkl_output:uint8; attr=ksize:list(int),min=5; attr=strides:list(int),min=5; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NDHWC",allowed=["NDHWC", "NCDHW"]; attr=T:type,default=DT_FLOAT,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT]; attr=TInput:type,default=DT_FLOAT,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT]; attr=workspace_enabled:bool,default=false>
  2023-01-12 09:34:38.365058: I tensorflow/core/framework/op.cc:132] Op<name=_MklMaxPoolGrad; signature=orig_input:T, orig_output:T, grad:T, workspace:uint8, mkl_orig_input:uint8, mkl_orig_output:uint8, mkl_grad:uint8, mkl_workspace:uint8 -> output:T, mkl_output:uint8; attr=T:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_HALF, DT_BFLOAT16]; attr=ksize:list(int),min=4; attr=strides:list(int),min=4; attr=workspace_enabled:bool,default=false; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=explicit_paddings:list(int),default=[]>
  2023-01-12 09:34:38.365086: I tensorflow/core/framework/op.cc:132] Op<name=_MklMaximum; signature=x:T, y:T, mkl_x:uint8, mkl_y:uint8 -> z:T, mkl_z:uint8; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64, DT_BFLOAT16]>
  2023-01-12 09:34:38.365113: I tensorflow/core/framework/op.cc:132] Op<name=_MklMul; signature=x:T, y:T, mkl_x:uint8, mkl_y:uint8 -> z:T, mkl_z:uint8; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_INT32, DT_UINT32, DT_UINT64, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:38.365166: I tensorflow/core/framework/op.cc:132] Op<name=_MklNativeAvgPool; signature=value:T -> output:T; attr=ksize:list(int),min=4; attr=strides:list(int),min=4; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=T:type,allowed=[DT_FLOAT, DT_HALF, DT_DOUBLE, DT_BFLOAT16]>
  2023-01-12 09:34:38.365204: I tensorflow/core/framework/op.cc:132] Op<name=_MklNativeAvgPool3D; signature=value:T -> output:T; attr=ksize:list(int),min=5; attr=strides:list(int),min=5; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NDHWC",allowed=["NDHWC", "NCDHW"]; attr=T:type,allowed=[DT_FLOAT, DT_HALF, DT_DOUBLE, DT_BFLOAT16]>
  2023-01-12 09:34:38.365238: I tensorflow/core/framework/op.cc:132] Op<name=_MklNativeAvgPool3DGrad; signature=orig_input_shape:int32, grad:T -> output:T; attr=ksize:list(int),min=5; attr=strides:list(int),min=5; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NDHWC",allowed=["NDHWC", "NCDHW"]; attr=T:type,allowed=[DT_FLOAT, DT_HALF, DT_DOUBLE, DT_BFLOAT16]>
  2023-01-12 09:34:38.365269: I tensorflow/core/framework/op.cc:132] Op<name=_MklNativeAvgPoolGrad; signature=orig_input_shape:int32, grad:T -> output:T; attr=ksize:list(int),min=4; attr=strides:list(int),min=4; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=T:type,allowed=[DT_FLOAT, DT_HALF, DT_DOUBLE, DT_BFLOAT16]>
  2023-01-12 09:34:38.365306: I tensorflow/core/framework/op.cc:132] Op<name=_MklNativeConv2D; signature=input:T, filter:T -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=strides:list(int); attr=use_cudnn_on_gpu:bool,default=true; attr=is_filter_const:bool,default=false; attr=padding:string,allowed=["SAME", "VALID", "EXPLICIT"]; attr=explicit_paddings:list(int),default=[]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=dilations:list(int),default=[1, 1, 1, 1]>
  2023-01-12 09:34:38.365369: I tensorflow/core/framework/op.cc:132] Op<name=_MklNativeConv2DBackpropFilter; signature=input:T, filter_sizes:int32, out_backprop:T -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=strides:list(int); attr=use_cudnn_on_gpu:bool,default=true; attr=padding:string,allowed=["SAME", "VALID", "EXPLICIT"]; attr=explicit_paddings:list(int),default=[]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=dilations:list(int),default=[1, 1, 1, 1]>
  2023-01-12 09:34:38.365409: I tensorflow/core/framework/op.cc:132] Op<name=_MklNativeConv2DBackpropFilterWithBias; signature=input:T, filter_sizes:int32, out_backprop:T -> output:T, bias_grad:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=strides:list(int); attr=use_cudnn_on_gpu:bool,default=true; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=dilations:list(int),default=[1, 1, 1, 1]>
  2023-01-12 09:34:38.365492: I tensorflow/core/framework/op.cc:132] Op<name=_MklNativeConv2DBackpropInput; signature=input_sizes:int32, filter:T, out_backprop:T -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=strides:list(int); attr=use_cudnn_on_gpu:bool,default=true; attr=padding:string,allowed=["SAME", "VALID", "EXPLICIT"]; attr=explicit_paddings:list(int),default=[]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=dilations:list(int),default=[1, 1, 1, 1]>
  2023-01-12 09:34:38.365714: I tensorflow/core/framework/op.cc:132] Op<name=_MklNativeConv2DWithBias; signature=input:T, filter:T, bias:T -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=strides:list(int); attr=use_cudnn_on_gpu:bool,default=true; attr=is_filter_const:bool,default=false; attr=padding:string,allowed=["SAME", "VALID", "EXPLICIT"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=explicit_paddings:list(int),default=[]; attr=dilations:list(int),default=[1, 1, 1, 1]>
  2023-01-12 09:34:38.366062: I tensorflow/core/framework/op.cc:132] Op<name=_MklNativeConv3D; signature=input:T, filter:T -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=strides:list(int),min=5; attr=is_filter_const:bool,default=false; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NDHWC",allowed=["NDHWC", "NCDHW"]; attr=dilations:list(int),default=[1, 1, 1, 1, 1]>
  2023-01-12 09:34:38.366169: I tensorflow/core/framework/op.cc:132] Op<name=_MklNativeConv3DBackpropFilterV2; signature=input:T, filter_sizes:int32, out_backprop:T -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=strides:list(int); attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NDHWC",allowed=["NDHWC", "NCDHW"]; attr=dilations:list(int),default=[1, 1, 1, 1, 1]>
  2023-01-12 09:34:38.366457: I tensorflow/core/framework/op.cc:132] Op<name=_MklNativeConv3DBackpropInputV2; signature=input_sizes:Tshape, filter:T, out_backprop:T -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=strides:list(int),min=5; attr=dilations:list(int),default=[1, 1, 1, 1, 1]; attr=Tshape:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NDHWC",allowed=["NDHWC", "NCDHW"]>
  2023-01-12 09:34:38.366528: I tensorflow/core/framework/op.cc:132] Op<name=_MklNativeDepthwiseConv2dNative; signature=input:T, filter:T -> output:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]; attr=strides:list(int); attr=is_filter_const:bool,default=false; attr=padding:string,allowed=["SAME", "VALID", "EXPLICIT"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=explicit_paddings:list(int),default=[]; attr=dilations:list(int),default=[1, 1, 1, 1]>
  2023-01-12 09:34:38.366611: I tensorflow/core/framework/op.cc:132] Op<name=_MklNativeDepthwiseConv2dNativeBackpropFilter; signature=input:T, filter_sizes:int32, out_backprop:T -> output:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]; attr=strides:list(int); attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=explicit_paddings:list(int),default=[]; attr=dilations:list(int),default=[1, 1, 1, 1]>
  2023-01-12 09:34:38.366663: I tensorflow/core/framework/op.cc:132] Op<name=_MklNativeDepthwiseConv2dNativeBackpropInput; signature=input_sizes:int32, filter:T, out_backprop:T -> output:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]; attr=strides:list(int); attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=explicit_paddings:list(int),default=[]; attr=dilations:list(int),default=[1, 1, 1, 1]>
  2023-01-12 09:34:38.366866: I tensorflow/core/framework/op.cc:132] Op<name=_MklNativeFusedBatchNorm; signature=x:T, scale:T, offset:T, mean:T, variance:T -> y:T, batch_mean:T, batch_variance:T, reserve_space_1:T, reserve_space_2:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=epsilon:float,default=0.0001; attr=data_format:string,default="NHWC"; attr=exponential_avg_factor:float,default=1; attr=is_training:bool,default=true>
  2023-01-12 09:34:38.366920: I tensorflow/core/framework/op.cc:132] Op<name=_MklNativeFusedBatchNormEx; signature=x:T, scale:U, offset:U, mean:U, variance:U, side_input:num_side_inputs*T -> y:T, batch_mean:U, batch_variance:U, reserve_space_1:U, reserve_space_2:U, reserve_space_3:U; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=U:type,allowed=[DT_FLOAT]; attr=epsilon:float,default=0.0001; attr=exponential_avg_factor:float,default=1; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=num_side_inputs:int,default=0,min=0; attr=activation_mode:string,default="Identity"; attr=is_training:bool,default=true>
  2023-01-12 09:34:38.366965: I tensorflow/core/framework/op.cc:132] Op<name=_MklNativeFusedBatchNormGrad; signature=y_backprop:T, x:T, scale:T, reserve_space_1:T, reserve_space_2:T -> x_backprop:T, scale_backprop:T, offset_backprop:T, reserve_space_3:T, reserve_space_4:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=epsilon:float,default=0.0001; attr=data_format:string,default="NHWC"; attr=is_training:bool,default=true>
  2023-01-12 09:34:38.367014: I tensorflow/core/framework/op.cc:132] Op<name=_MklNativeFusedBatchNormGradV2; signature=y_backprop:T, x:T, scale:float, reserve_space_1:U, reserve_space_2:U -> x_backprop:T, scale_backprop:U, offset_backprop:U, reserve_space_3:U, reserve_space_4:U; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=U:type,allowed=[DT_FLOAT]; attr=epsilon:float,default=0.0001; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=is_training:bool,default=true>
  2023-01-12 09:34:38.367061: I tensorflow/core/framework/op.cc:132] Op<name=_MklNativeFusedBatchNormGradV3; signature=y_backprop:T, x:T, scale:float, reserve_space_1:U, reserve_space_2:U, reserve_space_3:U -> x_backprop:T, scale_backprop:U, offset_backprop:U, reserve_space_4:U, reserve_space_5:U; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT]; attr=U:type,allowed=[DT_FLOAT]; attr=epsilon:float,default=0.0001; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=is_training:bool,default=true>
  2023-01-12 09:34:38.367281: I tensorflow/core/framework/op.cc:132] Op<name=_MklNativeFusedBatchNormV2; signature=x:T, scale:U, offset:U, mean:U, variance:U -> y:T, batch_mean:U, batch_variance:U, reserve_space_1:U, reserve_space_2:U; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=U:type,allowed=[DT_FLOAT]; attr=epsilon:float,default=0.0001; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=exponential_avg_factor:float,default=1; attr=is_training:bool,default=true>
  2023-01-12 09:34:38.367779: I tensorflow/core/framework/op.cc:132] Op<name=_MklNativeFusedBatchNormV3; signature=x:T, scale:U, offset:U, mean:U, variance:U -> y:T, batch_mean:U, batch_variance:U, reserve_space_1:U, reserve_space_2:U, reserve_space_3:U; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT]; attr=U:type,allowed=[DT_FLOAT]; attr=epsilon:float,default=0.0001; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=exponential_avg_factor:float,default=1; attr=is_training:bool,default=true>
  2023-01-12 09:34:38.368111: I tensorflow/core/framework/op.cc:132] Op<name=_MklNativeFusedConv2D; signature=input:T, filter:T, args:num_args*T -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=num_args:int,min=0; attr=strides:list(int); attr=is_filter_const:bool,default=false; attr=padding:string,allowed=["SAME", "VALID", "EXPLICIT"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=explicit_paddings:list(int),default=[]; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=use_cudnn_on_gpu:bool,default=true; attr=fused_ops:list(string),default=[]; attr=epsilon:float,default=0.0001; attr=leakyrelu_alpha:float,default=0.2>
  2023-01-12 09:34:38.369495: I tensorflow/core/framework/op.cc:132] Op<name=_MklNativeFusedConv3D; signature=input:T, filter:T, args:num_args*T -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=num_args:int,min=0; attr=strides:list(int),min=5; attr=is_filter_const:bool,default=false; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NDHWC",allowed=["NDHWC", "NCDHW"]; attr=dilations:list(int),default=[1, 1, 1, 1, 1]; attr=padding_list:list(int),default=[]; attr=fused_ops:list(string),default=[]; attr=epsilon:float,default=0.0001; attr=leakyrelu_alpha:float,default=0.2>
  2023-01-12 09:34:38.369748: I tensorflow/core/framework/op.cc:132] Op<name=_MklNativeFusedDepthwiseConv2dNative; signature=input:T, filter:T, args:num_args*T -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=num_args:int,min=0; attr=strides:list(int); attr=is_filter_const:bool,default=false; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=fused_ops:list(string),default=[]; attr=epsilon:float,default=0.0001; attr=leakyrelu_alpha:float,default=0.2>
  2023-01-12 09:34:38.369867: I tensorflow/core/framework/op.cc:132] Op<name=_MklNativeFusedMatMul; signature=a:T, b:T, args:num_args*T -> product:T; attr=is_filter_const:bool,default=false; attr=transpose_a:bool,default=false; attr=transpose_b:bool,default=false; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=num_args:int,min=0; attr=fused_ops:list(string),default=[]; attr=epsilon:float,default=0.0001; attr=leakyrelu_alpha:float,default=0.2>
  2023-01-12 09:34:38.370177: I tensorflow/core/framework/op.cc:132] Op<name=_MklNativeMaxPool; signature=input:T -> output:T, workspace:uint8; attr=T:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_HALF, DT_BFLOAT16]; attr=ksize:list(int),min=4; attr=strides:list(int),min=4; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=explicit_paddings:list(int),default=[]; attr=workspace_enabled:bool,default=false>
  2023-01-12 09:34:38.370474: I tensorflow/core/framework/op.cc:132] Op<name=_MklNativeMaxPool3D; signature=input:T -> output:T, workspace:uint8; attr=ksize:list(int),min=5; attr=strides:list(int),min=5; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NDHWC",allowed=["NDHWC", "NCDHW"]; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT]; attr=workspace_enabled:bool,default=false>
  2023-01-12 09:34:38.370559: I tensorflow/core/framework/op.cc:132] Op<name=_MklNativeMaxPool3DGrad; signature=orig_input:TInput, orig_output:TInput, grad:T, workspace:uint8 -> output:T; attr=ksize:list(int),min=5; attr=strides:list(int),min=5; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NDHWC",allowed=["NDHWC", "NCDHW"]; attr=T:type,default=DT_FLOAT,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT]; attr=TInput:type,default=DT_FLOAT,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT]; attr=workspace_enabled:bool,default=false>
  2023-01-12 09:34:38.370629: I tensorflow/core/framework/op.cc:132] Op<name=_MklNativeMaxPoolGrad; signature=orig_input:T, orig_output:T, grad:T, workspace:uint8 -> output:T; attr=T:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_HALF, DT_BFLOAT16]; attr=ksize:list(int),min=4; attr=strides:list(int),min=4; attr=workspace_enabled:bool,default=false; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=explicit_paddings:list(int),default=[]>
  2023-01-12 09:34:38.370736: I tensorflow/core/framework/op.cc:132] Op<name=_MklNativePadWithConv2D; signature=input:T, filter:T, paddings:Tpaddings -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=strides:list(int); attr=use_cudnn_on_gpu:bool,default=true; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=is_filter_const:bool,default=false; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=Tpaddings:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.370865: I tensorflow/core/framework/op.cc:132] Op<name=_MklNativePadWithFusedConv2D; signature=input:T, filter:T, args:num_args*T, paddings:Tpaddings -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=num_args:int,min=0; attr=strides:list(int); attr=is_filter_const:bool,default=false; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=fused_ops:list(string),default=[]; attr=Tpaddings:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=epsilon:float,default=0.0001; attr=leakyrelu_alpha:float,default=0.2>
  2023-01-12 09:34:38.370963: I tensorflow/core/framework/op.cc:132] Op<name=_MklPadWithConv2D; signature=input:T, filter:T, paddings:Tpaddings, mkl_input:uint8, mkl_filter:uint8, mkl_paddings:uint8 -> output:T, filter_output:T, mkl_output:uint8, mkl_filter_output:uint8; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=strides:list(int); attr=use_cudnn_on_gpu:bool,default=true; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=is_filter_const:bool,default=false; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=Tpaddings:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.371086: I tensorflow/core/framework/op.cc:132] Op<name=_MklPadWithFusedConv2D; signature=input:T, filter:T, args:num_args*T, paddings:Tpaddings, mkl_input:uint8, mkl_filter:uint8, mkl_args:num_args*uint8, mkl_paddings:uint8 -> output:T, filter_output:T, mkl_output:uint8, mkl_filter_output:uint8; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=num_args:int,min=0; attr=strides:list(int); attr=is_filter_const:bool,default=false; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=fused_ops:list(string),default=[]; attr=Tpaddings:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=epsilon:float,default=0.0001; attr=leakyrelu_alpha:float,default=0.2>
  2023-01-12 09:34:38.371199: I tensorflow/core/framework/op.cc:132] Op<name=_MklQuantizeV2; signature=input:float, min_range:float, max_range:float -> output:T, output_min:float, output_max:float; attr=T:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=mode:string,default="SCALED",allowed=["MIN_COMBINED", "MIN_FIRST", "SCALED"]; attr=round_mode:string,default="HALF_AWAY_FROM_ZERO",allowed=["HALF_AWAY_FROM_ZERO", "HALF_TO_EVEN"]; attr=narrow_range:bool,default=false; attr=axis:int,default=-1; attr=ensure_minimum_range:float,default=0.01>
  2023-01-12 09:34:38.371405: I tensorflow/core/framework/op.cc:132] Op<name=_MklQuantizedAvgPool; signature=input:T, min_input:float, max_input:float -> output:T, min_output:float, max_output:float; attr=T:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=ksize:list(int),min=4; attr=strides:list(int),min=4; attr=padding:string,allowed=["SAME", "VALID"]>
  2023-01-12 09:34:38.371488: I tensorflow/core/framework/op.cc:132] Op<name=_MklQuantizedConcatV2; signature=values:N*T, axis:Tidx, input_mins:N*float, input_maxes:N*float -> output:T, output_min:float, output_max:float; attr=N:int,min=2; attr=T:type; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.372121: I tensorflow/core/framework/op.cc:132] Op<name=_MklQuantizedConv2D; signature=input:Tinput, filter:Tfilter, min_input:float, max_input:float, min_filter:float, max_filter:float -> output:out_type, min_output:float, max_output:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tfilter:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=out_type:type,default=DT_QINT32,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=data_format:string,default="NHWC"; attr=strides:list(int); attr=is_filter_const:bool,default=true; attr=padding:string,allowed=["SAME", "VALID"]; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=padding_list:list(int),default=[]>
  2023-01-12 09:34:38.372381: I tensorflow/core/framework/op.cc:132] Op<name=_MklQuantizedConv2DAndRelu; signature=input:Tinput, filter:Tfilter, min_input:float, max_input:float, min_filter:float, max_filter:float -> output:out_type, min_output:float, max_output:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tfilter:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=out_type:type,default=DT_QINT32,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=data_format:string,default="NHWC"; attr=strides:list(int); attr=is_filter_const:bool,default=true; attr=padding:string,allowed=["SAME", "VALID"]; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=padding_list:list(int),default=[]>
  2023-01-12 09:34:38.372508: I tensorflow/core/framework/op.cc:132] Op<name=_MklQuantizedConv2DAndReluAndRequantize; signature=input:Tinput, filter:Tfilter, min_input:float, max_input:float, min_filter:float, max_filter:float, min_freezed_output:float, max_freezed_output:float -> output:out_type, min_output:float, max_output:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tfilter:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=out_type:type,default=DT_QUINT8,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=data_format:string,default="NHWC"; attr=strides:list(int); attr=is_filter_const:bool,default=true; attr=padding:string,allowed=["SAME", "VALID"]; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=padding_list:list(int),default=[]>
  2023-01-12 09:34:38.372715: I tensorflow/core/framework/op.cc:132] Op<name=_MklQuantizedConv2DAndRequantize; signature=input:Tinput, filter:Tfilter, min_input:float, max_input:float, min_filter:float, max_filter:float, min_freezed_output:float, max_freezed_output:float -> output:out_type, min_output:float, max_output:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tfilter:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=out_type:type,default=DT_QINT8,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=data_format:string,default="NHWC"; attr=strides:list(int); attr=is_filter_const:bool,default=true; attr=padding:string,allowed=["SAME", "VALID"]; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=padding_list:list(int),default=[]>
  2023-01-12 09:34:38.372859: I tensorflow/core/framework/op.cc:132] Op<name=_MklQuantizedConv2DPerChannel; signature=input:Tinput, filter:Tfilter, min_input:float, max_input:float, min_filter:float, max_filter:float -> output:out_type, min_output:float, max_output:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tfilter:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=out_type:type,default=DT_QINT32,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=data_format:string,default="NHWC"; attr=strides:list(int); attr=is_filter_const:bool,default=false; attr=padding:string,allowed=["SAME", "VALID"]; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=padding_list:list(int),default=[]>
  2023-01-12 09:34:38.372999: I tensorflow/core/framework/op.cc:132] Op<name=_MklQuantizedConv2DWithBias; signature=input:Tinput, filter:Tfilter, bias:float, min_input:float, max_input:float, min_filter:float, max_filter:float -> output:out_type, min_output:float, max_output:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tfilter:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=out_type:type,default=DT_QINT32,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=data_format:string,default="NHWC"; attr=strides:list(int); attr=is_filter_const:bool,default=true; attr=is_bias_const:bool,default=true; attr=padding:string,allowed=["SAME", "VALID"]; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=padding_list:list(int),default=[]>
  2023-01-12 09:34:38.373134: I tensorflow/core/framework/op.cc:132] Op<name=_MklQuantizedConv2DWithBiasAndRelu; signature=input:Tinput, filter:Tfilter, bias:float, min_input:float, max_input:float, min_filter:float, max_filter:float -> output:out_type, min_output:float, max_output:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tfilter:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=out_type:type,default=DT_QINT32,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=data_format:string,default="NHWC"; attr=strides:list(int); attr=is_filter_const:bool,default=true; attr=is_bias_const:bool,default=true; attr=padding:string,allowed=["SAME", "VALID"]; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=padding_list:list(int),default=[]>
  2023-01-12 09:34:38.373516: I tensorflow/core/framework/op.cc:132] Op<name=_MklQuantizedConv2DWithBiasAndReluAndRequantize; signature=input:Tinput, filter:Tfilter, bias:Tbias, min_input:float, max_input:float, min_filter:float, max_filter:float, min_freezed_output:float, max_freezed_output:float -> output:out_type, min_output:float, max_output:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tfilter:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tbias:type,allowed=[DT_FLOAT, DT_QINT32]; attr=out_type:type,default=DT_QUINT8,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=data_format:string,default="NHWC"; attr=strides:list(int); attr=is_filter_const:bool,default=true; attr=is_bias_const:bool,default=true; attr=padding:string,allowed=["SAME", "VALID"]; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=padding_list:list(int),default=[]>
  2023-01-12 09:34:38.375097: I tensorflow/core/framework/op.cc:132] Op<name=_MklQuantizedConv2DWithBiasAndRequantize; signature=input:Tinput, filter:Tfilter, bias:Tbias, min_input:float, max_input:float, min_filter:float, max_filter:float, min_freezed_output:float, max_freezed_output:float -> output:out_type, min_output:float, max_output:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tfilter:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tbias:type,allowed=[DT_FLOAT, DT_QINT32]; attr=out_type:type,default=DT_QINT8,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=data_format:string,default="NHWC"; attr=strides:list(int); attr=is_filter_const:bool,default=true; attr=is_bias_const:bool,default=true; attr=padding:string,allowed=["SAME", "VALID"]; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=padding_list:list(int),default=[]>
  2023-01-12 09:34:38.375303: I tensorflow/core/framework/op.cc:132] Op<name=_MklQuantizedConv2DWithBiasSignedSumAndReluAndRequantize; signature=input:Tinput, filter:Tfilter, bias:Tbias, min_input:float, max_input:float, min_filter:float, max_filter:float, min_freezed_output:float, max_freezed_output:float, summand:Tsummand, min_summand:float, max_summand:float -> output:out_type, min_output:float, max_output:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tfilter:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tbias:type,allowed=[DT_FLOAT, DT_QINT32]; attr=Tsummand:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=out_type:type,default=DT_QUINT8,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=data_format:string,default="NHWC"; attr=strides:list(int); attr=is_filter_const:bool,default=true; attr=is_bias_const:bool,default=true; attr=padding:string,allowed=["SAME", "VALID"]; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=padding_list:list(int),default=[]>
  2023-01-12 09:34:38.375413: I tensorflow/core/framework/op.cc:132] Op<name=_MklQuantizedConv2DWithBiasSumAndRelu; signature=input:Tinput, filter:Tfilter, bias:float, min_input:float, max_input:float, min_filter:float, max_filter:float, summand:float -> output:out_type, min_output:float, max_output:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tfilter:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=out_type:type,default=DT_QINT32,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=data_format:string,default="NHWC"; attr=strides:list(int); attr=is_filter_const:bool,default=true; attr=is_bias_const:bool,default=true; attr=padding:string,allowed=["SAME", "VALID"]; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=padding_list:list(int),default=[]>
  2023-01-12 09:34:38.375556: I tensorflow/core/framework/op.cc:132] Op<name=_MklQuantizedConv2DWithBiasSumAndReluAndRequantize; signature=input:Tinput, filter:Tfilter, bias:Tbias, min_input:float, max_input:float, min_filter:float, max_filter:float, min_freezed_output:float, max_freezed_output:float, summand:Tsummand, min_summand:float, max_summand:float -> output:out_type, min_output:float, max_output:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tfilter:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tbias:type,allowed=[DT_FLOAT, DT_QINT32]; attr=Tsummand:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=out_type:type,default=DT_QUINT8,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=data_format:string,default="NHWC"; attr=strides:list(int); attr=is_filter_const:bool,default=true; attr=is_bias_const:bool,default=true; attr=padding:string,allowed=["SAME", "VALID"]; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=padding_list:list(int),default=[]>
  2023-01-12 09:34:38.375700: I tensorflow/core/framework/op.cc:132] Op<name=_MklQuantizedDepthwiseConv2D; signature=input:Tinput, filter:Tfilter, min_input:float, max_input:float, min_filter:float, max_filter:float -> output:out_type, min_output:float, max_output:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tfilter:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=out_type:type,default=DT_QINT32,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=data_format:string,default="NHWC"; attr=strides:list(int); attr=is_filter_const:bool,default=true; attr=padding:string,allowed=["SAME", "VALID"]; attr=dilations:list(int),default=[1, 1, 1, 1]>
  2023-01-12 09:34:38.375788: I tensorflow/core/framework/op.cc:132] Op<name=_MklQuantizedDepthwiseConv2DWithBias; signature=input:Tinput, filter:Tfilter, bias:float, min_input:float, max_input:float, min_filter:float, max_filter:float -> output:out_type, min_output:float, max_output:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tfilter:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=out_type:type,default=DT_QINT32,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=data_format:string,default="NHWC"; attr=strides:list(int); attr=is_filter_const:bool,default=true; attr=is_bias_const:bool,default=true; attr=padding:string,allowed=["SAME", "VALID"]; attr=dilations:list(int),default=[1, 1, 1, 1]>
  2023-01-12 09:34:38.375866: I tensorflow/core/framework/op.cc:132] Op<name=_MklQuantizedDepthwiseConv2DWithBiasAndRelu; signature=input:Tinput, filter:Tfilter, bias:float, min_input:float, max_input:float, min_filter:float, max_filter:float -> output:out_type, min_output:float, max_output:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tfilter:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=out_type:type,default=DT_QINT32,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=data_format:string,default="NHWC"; attr=strides:list(int); attr=is_filter_const:bool,default=true; attr=is_bias_const:bool,default=true; attr=padding:string,allowed=["SAME", "VALID"]; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=padding_list:list(int),default=[]>
  2023-01-12 09:34:38.375953: I tensorflow/core/framework/op.cc:132] Op<name=_MklQuantizedDepthwiseConv2DWithBiasAndReluAndRequantize; signature=input:Tinput, filter:Tfilter, bias:Tbias, min_input:float, max_input:float, min_filter:float, max_filter:float, min_freezed_output:float, max_freezed_output:float -> output:out_type, min_output:float, max_output:float; attr=Tinput:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tfilter:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tbias:type,allowed=[DT_FLOAT, DT_QINT32]; attr=out_type:type,default=DT_QUINT8,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=data_format:string,default="NHWC"; attr=strides:list(int); attr=is_filter_const:bool,default=true; attr=is_bias_const:bool,default=true; attr=padding:string,allowed=["SAME", "VALID"]; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=padding_list:list(int),default=[]>
  2023-01-12 09:34:38.376051: I tensorflow/core/framework/op.cc:132] Op<name=_MklQuantizedMatMulWithBias; signature=a:T1, b:T2, bias:Tbias, min_a:float, max_a:float, min_b:float, max_b:float -> out:Toutput, min_out:float, max_out:float; attr=T1:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=T2:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tbias:type,allowed=[DT_FLOAT, DT_QINT32]; attr=Toutput:type,default=DT_QINT32,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=transpose_a:bool,default=false; attr=transpose_b:bool,default=false; attr=input_quant_mode:string,default="MIN_FIRST",allowed=["MIN_FIRST", "SCALED"]; attr=is_weight_const:bool,default=true>
  2023-01-12 09:34:38.376143: I tensorflow/core/framework/op.cc:132] Op<name=_MklQuantizedMatMulWithBiasAndDequantize; signature=a:T1, b:T2, bias:Tbias, min_a:float, max_a:float, min_b:float, max_b:float, min_freezed_output:float, max_freezed_output:float -> out:Toutput; attr=T1:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=T2:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tbias:type,allowed=[DT_FLOAT, DT_QINT32]; attr=Toutput:type,allowed=[DT_FLOAT]; attr=transpose_a:bool,default=false; attr=transpose_b:bool,default=false; attr=input_quant_mode:string,default="MIN_FIRST",allowed=["MIN_FIRST", "SCALED"]; attr=is_weight_const:bool,default=true>
  2023-01-12 09:34:38.376191: I tensorflow/core/framework/op.cc:132] Op<name=_MklQuantizedMatMulWithBiasAndRelu; signature=a:T1, b:T2, bias:float, min_a:float, max_a:float, min_b:float, max_b:float -> out:Toutput, min_out:float, max_out:float; attr=T1:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=T2:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Toutput:type,default=DT_QINT32,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=transpose_a:bool,default=false; attr=transpose_b:bool,default=false; attr=input_quant_mode:string,default="MIN_FIRST",allowed=["MIN_FIRST", "SCALED"]; attr=is_weight_const:bool,default=true>
  2023-01-12 09:34:38.376265: I tensorflow/core/framework/op.cc:132] Op<name=_MklQuantizedMatMulWithBiasAndReluAndRequantize; signature=a:T1, b:T2, bias:Tbias, min_a:float, max_a:float, min_b:float, max_b:float, min_freezed_output:float, max_freezed_output:float -> out:Toutput, min_out:float, max_out:float; attr=T1:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=T2:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tbias:type,allowed=[DT_FLOAT, DT_QINT32]; attr=Toutput:type,default=DT_QUINT8,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=transpose_a:bool,default=false; attr=transpose_b:bool,default=false; attr=input_quant_mode:string,default="MIN_FIRST",allowed=["MIN_FIRST", "SCALED"]; attr=is_weight_const:bool,default=true>
  2023-01-12 09:34:38.376322: I tensorflow/core/framework/op.cc:132] Op<name=_MklQuantizedMatMulWithBiasAndRequantize; signature=a:T1, b:T2, bias:Tbias, min_a:float, max_a:float, min_b:float, max_b:float, min_freezed_output:float, max_freezed_output:float -> out:Toutput, min_out:float, max_out:float; attr=T1:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=T2:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tbias:type,allowed=[DT_FLOAT, DT_QINT32]; attr=Toutput:type,default=DT_QUINT8,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=transpose_a:bool,default=false; attr=transpose_b:bool,default=false; attr=input_quant_mode:string,default="MIN_FIRST",allowed=["MIN_FIRST", "SCALED"]; attr=is_weight_const:bool,default=true>
  2023-01-12 09:34:38.376357: I tensorflow/core/framework/op.cc:132] Op<name=_MklQuantizedMaxPool; signature=input:T, min_input:float, max_input:float -> output:T, min_output:float, max_output:float; attr=T:type,allowed=[DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=ksize:list(int),min=4; attr=strides:list(int),min=4; attr=padding:string,allowed=["SAME", "VALID"]>
  2023-01-12 09:34:38.376381: I tensorflow/core/framework/op.cc:132] Op<name=_MklRelu; signature=features:T, mkl_features:uint8 -> activations:T, mkl_activations:uint8; attr=T:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_BFLOAT16]>
  2023-01-12 09:34:38.376405: I tensorflow/core/framework/op.cc:132] Op<name=_MklRelu6; signature=features:T, mkl_features:uint8 -> activations:T, mkl_activations:uint8; attr=T:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_BFLOAT16]>
  2023-01-12 09:34:38.376428: I tensorflow/core/framework/op.cc:132] Op<name=_MklRelu6Grad; signature=gradients:T, features:T, mkl_gradients:uint8, mkl_features:uint8 -> backprops:T, mkl_backprops:uint8; attr=T:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_BFLOAT16]>
  2023-01-12 09:34:38.382715: I tensorflow/core/framework/op.cc:132] Op<name=_MklReluGrad; signature=gradients:T, features:T, mkl_gradients:uint8, mkl_features:uint8 -> backprops:T, mkl_backprops:uint8; attr=T:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_BFLOAT16]>
  2023-01-12 09:34:38.383370: I tensorflow/core/framework/op.cc:132] Op<name=_MklReshape; signature=tensor:T, shape:Tshape, mkl_tensor:uint8, mkl_shape:uint8 -> output:T, mkl_output:uint8; attr=T:type; attr=Tshape:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.383475: I tensorflow/core/framework/op.cc:132] Op<name=_MklSlice; signature=input:T, begin:Index, size:Index, mkl_input:uint8, mkl_begin:uint8, mkl_size:uint8 -> output:T, mkl_output:uint8; attr=T:type; attr=Index:type,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.383545: I tensorflow/core/framework/op.cc:132] Op<name=_MklSoftmax; signature=logits:T, mkl_logits:uint8 -> softmax:T, mkl_softmax:uint8; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]>
  2023-01-12 09:34:38.383706: I tensorflow/core/framework/op.cc:132] Op<name=_MklSquaredDifference; signature=x:T, y:T, mkl_x:uint8, mkl_y:uint8 -> z:T, mkl_z:uint8; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:38.383752: I tensorflow/core/framework/op.cc:132] Op<name=_MklSub; signature=x:T, y:T, mkl_x:uint8, mkl_y:uint8 -> z:T, mkl_z:uint8; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]>
  2023-01-12 09:34:38.383788: I tensorflow/core/framework/op.cc:132] Op<name=_MklSwish; signature=features:T -> activations:T; attr=T:type,default=DT_FLOAT,allowed=[DT_FLOAT, DT_BFLOAT16]>
  2023-01-12 09:34:38.383854: I tensorflow/core/framework/op.cc:132] Op<name=_MklTanh; signature=features:T, mkl_features:uint8 -> activations:T, mkl_activations:uint8; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:38.383934: I tensorflow/core/framework/op.cc:132] Op<name=_MklTanhGrad; signature=gradients:T, features:T, mkl_gradients:uint8, mkl_features:uint8 -> backprops:T, mkl_backprops:uint8; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64]>
  2023-01-12 09:34:38.384147: I tensorflow/core/framework/op.cc:132] Op<name=_MklToTf; signature=input:T, mkl_input:uint8 -> output:T; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE, DT_BFLOAT16, DT_QINT8, DT_QUINT8, DT_QINT32]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW", "NDHWC", "NCDHW"]>
  2023-01-12 09:34:38.384232: I tensorflow/core/framework/op.cc:132] Op<name=_MklTranspose; signature=x:T, perm:Tperm -> y:T; attr=T:type; attr=Tperm:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.384306: I tensorflow/core/framework/op.cc:132] Op<name=_NcclBroadcastRecv; signature=shape:int32 -> output:T; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64]; attr=num_devices:int; attr=shared_name:string; is_stateful=true>
  2023-01-12 09:34:38.384388: I tensorflow/core/framework/op.cc:132] Op<name=_NcclBroadcastSend; signature=input:T -> ; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64]; attr=num_devices:int; attr=shared_name:string; is_stateful=true>
  2023-01-12 09:34:38.384583: I tensorflow/core/framework/op.cc:132] Op<name=_NcclReduceRecv; signature=input:T -> data:T; attr=reduction:string,allowed=["min", "max", "prod", "sum"]; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64]; attr=num_devices:int; attr=shared_name:string; is_stateful=true>
  2023-01-12 09:34:38.384954: I tensorflow/core/framework/op.cc:132] Op<name=_NcclReduceSend; signature=input:T -> ; attr=reduction:string,allowed=["min", "max", "prod", "sum"]; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64]; attr=num_devices:int; attr=shared_name:string; is_stateful=true>
  2023-01-12 09:34:38.384996: I tensorflow/core/framework/op.cc:132] Op<name=_ParallelConcatStart; signature= -> output:dtype; attr=shape:shape; attr=dtype:type; is_stateful=true>
  2023-01-12 09:34:38.385019: I tensorflow/core/framework/op.cc:132] Op<name=_ParallelConcatUpdate; signature=value:T, update:T -> output:T; attr=T:type; attr=loc:int>
  2023-01-12 09:34:38.385040: I tensorflow/core/framework/op.cc:132] Op<name=_ReadVariablesOp; signature=resources:N*resource -> values:; attr=N:int,min=0; attr=dtypes:list(type),min=1; is_stateful=true>
  2023-01-12 09:34:38.385065: I tensorflow/core/framework/op.cc:132] Op<name=_Recv; signature= -> tensor:tensor_type; attr=tensor_type:type; attr=tensor_name:string; attr=send_device:string; attr=send_device_incarnation:int; attr=recv_device:string; attr=client_terminated:bool,default=false; is_stateful=true; is_distributed_communication=true>
  2023-01-12 09:34:38.385102: I tensorflow/core/framework/op.cc:132] Op<name=_Retval; signature=input:T -> ; attr=T:type; attr=index:int,min=0; is_stateful=true>
  2023-01-12 09:34:38.385135: I tensorflow/core/framework/op.cc:132] Op<name=_ScopedAllocator; signature= -> output:T; attr=shapes:list(shape); attr=shape:shape; attr=T:type; attr=sa_name:string; attr=id:int; attr=expected_call_count:int; is_stateful=true>
  2023-01-12 09:34:38.385205: I tensorflow/core/framework/op.cc:132] Op<name=_ScopedAllocatorConcat; signature=backing:T, inputs:N*T -> output:T; attr=shape:shape; attr=T:type; attr=reshape:bool,default=false; attr=sa_name:string; attr=id:int; attr=N:int,min=2; is_stateful=true>
  2023-01-12 09:34:38.385256: I tensorflow/core/framework/op.cc:132] Op<name=_ScopedAllocatorSplit; signature=concat:T, split:N*T -> output:N*T; attr=T:type; attr=sa_name:string; attr=id:int; attr=N:int,min=2; attr=shapes:list(shape); is_stateful=true>
  2023-01-12 09:34:38.385326: I tensorflow/core/framework/op.cc:132] Op<name=_Send; signature=tensor:T -> ; attr=T:type; attr=tensor_name:string; attr=send_device:string; attr=send_device_incarnation:int; attr=recv_device:string; attr=client_terminated:bool,default=false; is_stateful=true>
  2023-01-12 09:34:38.385410: I tensorflow/core/framework/op.cc:132] Op<name=_SetGlobalTPUArray; signature=topology:string -> ; is_stateful=true>
  2023-01-12 09:34:38.385498: I tensorflow/core/framework/op.cc:132] Op<name=_ShutdownDistributedTPU; signature= -> ; is_stateful=true>
  2023-01-12 09:34:38.385563: I tensorflow/core/framework/op.cc:132] Op<name=_SwitchN; signature=data:T, output_index:int32 -> outputs:num_outs*T; attr=num_outs:int,min=1; attr=T:type>
  2023-01-12 09:34:38.385808: I tensorflow/core/framework/op.cc:132] Op<name=_TPUCompileMlir; signature=dynamic_shapes:NumDynamicShapes*int64 -> compilation_status:string, program:num_computations*string; attr=num_computations:int,min=0; attr=mlir_module:string,default=""; attr=metadata:string; attr=NumDynamicShapes:int,min=0; is_stateful=true>
  2023-01-12 09:34:38.385898: I tensorflow/core/framework/op.cc:132] Op<name=_TPUCompileMlirPlaceholderProgramKey; signature= -> program:string; is_stateful=true>
  2023-01-12 09:34:38.385986: I tensorflow/core/framework/op.cc:132] Op<name=_TPUReplicate; signature=inputs:, broadcast_inputs:, variables:NumVariables*resource, guaranteed_constants: -> outputs:; attr=computation:func; attr=num_replicas:int,min=1; attr=num_cores_per_replica:int,default=1; attr=topology:string,default=""; attr=use_tpu:bool,default=true; attr=device_assignment:list(int),default=[]; attr=host_compute_core:list(string),default=[]; attr=Tinputs:list(type),min=0; attr=Tbroadcast_inputs:list(type),min=0; attr=NumVariables:int,min=0; attr=Tguaranteed_constants:list(type),min=0; attr=output_types:list(type),min=0; attr=padding_map:list(string),default=[]; attr=step_marker_location:string,default="STEP_MARK_AT_ENTRY"; attr=allow_soft_placement:bool,default=false; attr=num_distributed_variables:int,default=0; attr=use_spmd_for_xla_partitioning:bool,default=false; attr=tpu_compile_options_proto:string,default=""; is_stateful=true>
  2023-01-12 09:34:38.386069: I tensorflow/core/framework/op.cc:132] Op<name=_TensorToHashBucketFast; signature=input:T -> output:int64; attr=T:type,allowed=[DT_INT8, DT_UINT8, DT_INT16, DT_UINT16, DT_INT32, DT_UINT32, DT_INT64, DT_UINT64]; attr=num_buckets:int,min=1>
  2023-01-12 09:34:38.386128: I tensorflow/core/framework/op.cc:132] Op<name=_UnaryOpsComposition; signature=x:T -> y:T; attr=T:type,allowed=[DT_FLOAT, DT_HALF, DT_DOUBLE]; attr=op_names:list(string)>
  2023-01-12 09:34:38.386170: I tensorflow/core/framework/op.cc:132] Op<name=_VarHandlesOp; signature= -> resources:N*resource; attr=containers:list(string); attr=shared_names:list(string); attr=N:int,min=0; attr=dtypes:list(type); attr=shapes:list(shape); is_stateful=true>
  2023-01-12 09:34:38.386254: I tensorflow/core/framework/op.cc:132] Op<name=_WaitForDistributedTPU; signature=inputs:N*int32 -> topology:string; attr=startup_timeout_sec:int,default=20; attr=N:int,min=1; is_stateful=true>
  2023-01-12 09:34:38.386278: I tensorflow/core/framework/op.cc:132] Op<name=_While; signature=input: -> output:; attr=T:list(type),min=0; attr=cond:func; attr=body:func; is_stateful=true>
  2023-01-12 09:34:38.386345: I tensorflow/core/framework/op.cc:132] Op<name=_XlaAotOnlyVarHandleOp; signature= -> resource:resource; attr=container:string,default=""; attr=shared_name:string,default=""; attr=dtype:type; attr=shape:shape; is_stateful=true>
  2023-01-12 09:34:38.386420: I tensorflow/core/framework/op.cc:132] Op<name=_XlaCompile; signature=constants:, args:, resources:Nresources*resource -> key:string, compilation_successful:bool; attr=Tconstants:list(type),min=0; attr=must_compile:bool; attr=Targs:list(type),min=0; attr=Nresources:int,min=0; attr=function:func; is_stateful=true>
  2023-01-12 09:34:38.386498: I tensorflow/core/framework/op.cc:132] Op<name=_XlaHostComputeMlir; signature=inputs: -> outputs:; attr=Tinputs:list(type),min=0; attr=Toutputs:list(type),min=0; attr=send_key:string; attr=recv_key:string; attr=host_mlir_module:string,default=""; is_stateful=true>
  2023-01-12 09:34:38.386569: I tensorflow/core/framework/op.cc:132] Op<name=_XlaMerge; signature=partitioned_call:T, xla_run:T -> output:T; attr=T:type>
  2023-01-12 09:34:38.386595: I tensorflow/core/framework/op.cc:132] Op<name=_XlaRecvAtHost; signature=dynamic_key:string -> outputs:; attr=Toutputs:list(type),min=0; attr=key:string; attr=device_ordinal:int; is_stateful=true>
  2023-01-12 09:34:38.386611: I tensorflow/core/framework/op.cc:132] Op<name=_XlaRecvAtHostV2; signature=dynamic_key:string, device_ordinal:int64 -> outputs:; attr=Toutputs:list(type),min=0; attr=key:string; is_stateful=true>
  2023-01-12 09:34:38.386626: I tensorflow/core/framework/op.cc:132] Op<name=_XlaRun; signature=args:, key:string -> results:; attr=Targs:list(type),min=0; attr=Tresults:list(type),min=0; is_stateful=true>
  2023-01-12 09:34:38.386673: I tensorflow/core/framework/op.cc:132] Op<name=_XlaSendFromHost; signature=inputs:, dynamic_key:string -> ; attr=Tinputs:list(type),min=0; attr=key:string; attr=device_ordinal:int; is_stateful=true>
  2023-01-12 09:34:38.386730: I tensorflow/core/framework/op.cc:132] Op<name=_XlaSendFromHostV2; signature=inputs:, dynamic_key:string, device_ordinal:int64 -> ; attr=Tinputs:list(type),min=0; attr=key:string; is_stateful=true>
  2023-01-12 09:34:38.386814: I tensorflow/core/framework/op.cc:132] Op<name=__MklDummyConv2DBackpropFilterWithBias; signature=input:T, filter_sizes:int32, out_backprop:T -> output:T, bias_grad:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=strides:list(int); attr=use_cudnn_on_gpu:bool,default=true; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=dilations:list(int),default=[1, 1, 1, 1]>
  2023-01-12 09:34:38.386893: I tensorflow/core/framework/op.cc:132] Op<name=__MklDummyConv2DWithBias; signature=input:T, filter:T, bias:T -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=strides:list(int); attr=use_cudnn_on_gpu:bool,default=true; attr=is_filter_const:bool,default=false; attr=padding:string,allowed=["SAME", "VALID", "EXPLICIT"]; attr=explicit_paddings:list(int),default=[]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=dilations:list(int),default=[1, 1, 1, 1]>
  2023-01-12 09:34:38.386970: I tensorflow/core/framework/op.cc:132] Op<name=__MklDummyPadWithConv2D; signature=input:T, filter:T, paddings:Tpaddings -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=strides:list(int); attr=use_cudnn_on_gpu:bool,default=true; attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=Tpaddings:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
  2023-01-12 09:34:38.387072: I tensorflow/core/framework/op.cc:132] Op<name=__MklDummyPadWithFusedConv2D; signature=input:T, filter:T, args:num_args*T, paddings:Tpaddings -> output:T, filter_output:T, mkl_output:uint8, mkl_filter_output:uint8; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]; attr=num_args:int,min=0; attr=strides:list(int); attr=padding:string,allowed=["SAME", "VALID"]; attr=data_format:string,default="NHWC",allowed=["NHWC", "NCHW"]; attr=dilations:list(int),default=[1, 1, 1, 1]; attr=fused_ops:list(string),default=[]; attr=Tpaddings:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=epsilon:float,default=0.0001; attr=leakyrelu_alpha:float,default=0.2>
2023-01-12 09:34:38.595722: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "NOT_FOUND: Op type not registered '__wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0' in binary running on docker-desktop. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.". *** Begin stack trace ***

        tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
        tsl::Status tsl::errors::NotFound<char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*, char const*>(char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*, char const*)

        tensorflow::OpRegistry::LookUp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::OpRegistrationData const**) const
        tensorflow::OpRegistryInterface::LookUpOpDef(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::OpDef const**) const
        tensorflow::FunctionLibraryDefinition::AddFunctionDefHelper(tensorflow::FunctionDef const&, std::unordered_map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::shared_ptr<tensorflow::AbstractStackTrace>, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::shared_ptr<tensorflow::AbstractStackTrace> > > > const&, bool*)
        tensorflow::FunctionLibraryDefinition::AddFunctionDef(tensorflow::FunctionDef const&, std::unordered_map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::shared_ptr<tensorflow::AbstractStackTrace>, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::shared_ptr<tensorflow::AbstractStackTrace> > > > const&)
        tensorflow::EagerContext::AddFunctionDef(tensorflow::FunctionDef const&, tensorflow::FunctionDefLibrary const&, bool, std::unordered_map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::shared_ptr<tensorflow::AbstractStackTrace>, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::shared_ptr<tensorflow::AbstractStackTrace> > > > const&)
        tensorflow::EagerContext::AddFunctionDef(tensorflow::FunctionDef const&)



        tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
        tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
        tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
        TFE_Execute
        tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
        tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
        tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
        EagerTensor_init
2023-01-12 09:34:38.595849: I tensorflow/core/framework/op.cc:80] NOT_FOUND: Op type not registered '__wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0' in binary running on docker-desktop. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.
2023-01-12 09:34:38.716170: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "NOT_FOUND: Op type not registered '__wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0' in binary running on docker-desktop. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.". *** Begin stack trace ***

        tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
        tsl::Status tsl::errors::NotFound<char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*, char const*>(char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*, char const*)

        tensorflow::OpRegistry::LookUp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::OpRegistrationData const**) const
        tensorflow::OpDefForOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::OpDef const**)
        tensorflow::AttrTypeMapForOp(char const*, std::unordered_map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, unsigned int, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned int> > > const**, bool*)
        tensorflow::EagerOperation::Reset(char const*, char const*, bool, tensorflow::EagerExecutor*, std::optional<tensorflow::EagerFunctionParams>)
        tensorflow::EagerOperation::Reset(char const*, char const*)



        tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
        tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
        tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
        TFE_Execute
        tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
        tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
        tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
        EagerTensor_init
2023-01-12 09:34:38.716311: I tensorflow/core/framework/op.cc:80] NOT_FOUND: Op type not registered '__wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0' in binary running on docker-desktop. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.
2023-01-12 09:34:38.805936: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "NOT_FOUND: Op type not registered '__wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0' in binary running on docker-desktop. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.". *** Begin stack trace ***

        tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
        tsl::Status tsl::errors::NotFound<char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*, char const*>(char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*, char const*)

        tensorflow::OpRegistry::LookUp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::OpRegistrationData const**) const
        tensorflow::OpDefForOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::OpDef const**)
        tensorflow::AttrBuilder::FillAttrValueMap(google::protobuf::Map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tensorflow::AttrValue>*) const
        tensorflow::AttrBuilder::BuildNodeDef()


        tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
        tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
        tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
        TFE_Execute
        tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
        tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
        tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
        EagerTensor_init
*** End stack trace ***

2023-01-12 09:34:38.806077: I tensorflow/core/framework/op.cc:80] NOT_FOUND: Op type not registered '__wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0' in binary running on docker-desktop. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.
2023-01-12 09:34:38.806582: I tensorflow/core/common_runtime/eager/execute.cc:1214] Running __wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0 using multi-device function. Full node_def=name: "__wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0"
op: "__wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0"
input: "dummy_input"
attr {
  key: "T"
  value {
    type: DT_DOUBLE
  }
}

2023-01-12 09:34:38.810878: I tensorflow/core/common_runtime/process_function_library_runtime.cc:951] Instantiating MultiDevice function "__wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0" on default device "/job:localhost/replica:0/task:0/device:CPU:0"
  2023-01-12 09:34:38.810960: I tensorflow/core/common_runtime/process_function_library_runtime.cc:955] Requested input devices:
  2023-01-12 09:34:38.810981: I tensorflow/core/common_runtime/process_function_library_runtime.cc:957]     [input 0] /job:localhost/replica:0/task:0/device:CPU:0
  2023-01-12 09:34:38.810990: I tensorflow/core/common_runtime/process_function_library_runtime.cc:960] Requested output devices:
  2023-01-12 09:34:38.811218: I tensorflow/core/framework/function.cc:742] Instantiate function definition: name=__wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0 #input_args=1 #output_args=1 #control_output=0
  2023-01-12 09:34:38.811550: I tensorflow/core/framework/function.cc:747] || 
  2023-01-12 09:34:38.811657: I tensorflow/core/framework/function.cc:747] || __wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0[T:<Unknown AttrValue type>](input:T) -> (output:T) {
  2023-01-12 09:34:38.811686: I tensorflow/core/framework/function.cc:747] ||   _EagerConst = _EagerConst[T=$T, device=CPU:0](input:0)
  2023-01-12 09:34:38.811728: I tensorflow/core/framework/function.cc:747] ||   return output = _EagerConst:output:0
  2023-01-12 09:34:38.811752: I tensorflow/core/framework/function.cc:747] || }
  2023-01-12 09:34:38.811763: I tensorflow/core/framework/function.cc:747] || 
  2023-01-12 09:34:38.815158: I tensorflow/core/graph/graph.cc:529] AddNode: no type constructor for _SOURCE
  2023-01-12 09:34:38.816208: I tensorflow/core/graph/graph.cc:529] AddNode: no type constructor for _SINK
  2023-01-12 09:34:38.828623: I tensorflow/core/graph/graph.cc:529] AddNode: no type constructor for input
  2023-01-12 09:34:38.828811: I tensorflow/core/graph/graph.cc:529] AddNode: no type constructor for _EagerConst
  2023-01-12 09:34:38.828896: I tensorflow/core/graph/graph.cc:529] AddNode: no type constructor for output_RetVal
  2023-01-12 09:34:38.836004: I tensorflow/core/common_runtime/process_function_library_runtime.cc:483] Trying to determine device for node output_RetVal[T=double]
  2023-01-12 09:34:38.836088: I tensorflow/core/common_runtime/process_function_library_runtime.cc:496] Considering src: _EagerConst src_device: /job:localhost/replica:0/task:0/device:CPU:0 colo group: 
  2023-01-12 09:34:38.836245: I tensorflow/core/common_runtime/process_function_library_runtime.cc:602] Setting output device to /job:localhost/replica:0/task:0/device:CPU:0 for node {{node output_RetVal}} = _Retval[T=DT_DOUBLE, index=0](_EagerConst)
  2023-01-12 09:34:38.839553: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:180] None of the MLIR Optimization Passes are enabled (registered 3)
  2023-01-12 09:34:38.840129: I tensorflow/core/common_runtime/function_utils.cc:78] Graph Before running PRE_PLACEMENT passes #nodes 5 #edges 5
  2023-01-12 09:34:38.841098: I tensorflow/core/common_runtime/function_utils.cc:82] || 
  2023-01-12 09:34:38.841330: I tensorflow/core/common_runtime/function_utils.cc:82] || (n2:double@CPU:0) -> (n3:double@CPU:0) {
  2023-01-12 09:34:38.841410: I tensorflow/core/common_runtime/function_utils.cc:82] ||   n3 = _EagerConst[T=double, device=CPU:0](n2)
  2023-01-12 09:34:38.841520: I tensorflow/core/common_runtime/function_utils.cc:82] || }
  2023-01-12 09:34:38.841561: I tensorflow/core/common_runtime/function_utils.cc:82] || 
  2023-01-12 09:34:38.841824: I tensorflow/core/common_runtime/optimization_registry.cc:54] Starting optimization of a group 0
    2023-01-12 09:34:38.842111: W tensorflow/core/util/dump_graph.cc:134] Failed to dump before_grouping_0_94667550137232 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
      2023-01-12 09:34:38.958539: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

              tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
              tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


              tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
              tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)

              tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
              tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
              tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
              tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
              tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
              tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


              tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
              tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
              tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
              TFE_Execute
              tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
              tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
              tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
              EagerTensor_init
              _PyObject_MakeTpCall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              PyObject_Call
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault


              PyEval_EvalCode



              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              PyEval_EvalCode


              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall

              Py_RunMain
              Py_BytesMain

              __libc_start_main
              _start
      *** End stack trace ***

      2023-01-12 09:34:38.959157: I tensorflow/core/common_runtime/optimization_registry.cc:66] Running optimization phase 0
      2023-01-12 09:34:38.959239: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: MlirV1CompatGraphOptimizationPass
      2023-01-12 09:34:38.959429: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_0_phase_0_MlirV1CompatGraphOptimizationPass_94667550137232 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
      2023-01-12 09:34:39.056523: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

              tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
              tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


              tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
              tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)

              tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
              tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
              tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
              tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
              tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
              tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


              tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
              tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
              tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
              TFE_Execute
              tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
              tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
              tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
              EagerTensor_init
              _PyObject_MakeTpCall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              PyObject_Call
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault


              PyEval_EvalCode



              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              PyEval_EvalCode


              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall

              Py_RunMain
              Py_BytesMain

              __libc_start_main
              _start
      *** End stack trace ***

      2023-01-12 09:34:39.057152: I tensorflow/core/common_runtime/optimization_registry.cc:66] Running optimization phase 9
      2023-01-12 09:34:39.057227: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: ControlFlowDepsToChainsPass
      2023-01-12 09:34:39.057261: I tensorflow/core/common_runtime/control_flow_deps_to_chains.cc:37] ControlFlowDepsToChainsPass::Run
      2023-01-12 09:34:39.057393: W tensorflow/core/util/dump_graph.cc:134] Failed to dump control_flow_deps_to_chains_before because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
      2023-01-12 09:34:39.155278: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

              tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
              tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


              tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
              tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
              tensorflow::ControlFlowDepsToChainsPass::Run(tensorflow::GraphOptimizationPassOptions const&)
              tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
              tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
              tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
              tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
              tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
              tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


              tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
              tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
              tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
              TFE_Execute
              tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
              tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
              tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
              EagerTensor_init
              _PyObject_MakeTpCall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              PyObject_Call
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault


              PyEval_EvalCode



              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              PyEval_EvalCode


              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall

              Py_RunMain
              Py_BytesMain

              __libc_start_main
              _start
      *** End stack trace ***

      2023-01-12 09:34:39.155964: W tensorflow/core/util/dump_graph.cc:134] Failed to dump control_flow_deps_to_chains_after because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
      2023-01-12 09:34:39.262700: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

              tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
              tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


              tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
              tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
              tensorflow::ControlFlowDepsToChainsPass::Run(tensorflow::GraphOptimizationPassOptions const&)
              tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
              tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
              tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
              tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
              tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
              tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


              tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
              tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
              tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
              TFE_Execute
              tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
              tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
              tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
              EagerTensor_init
              _PyObject_MakeTpCall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              PyObject_Call
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault


              PyEval_EvalCode



              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              PyEval_EvalCode


              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall

              Py_RunMain
              Py_BytesMain

              __libc_start_main
              _start
      *** End stack trace ***

      2023-01-12 09:34:39.263345: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_0_phase_9_ControlFlowDepsToChainsPass_94667550137232 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
      2023-01-12 09:34:39.348799: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

              tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
              tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


              tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
              tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)

              tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
              tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
              tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
              tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
              tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
              tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


              tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
              tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
              tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
              TFE_Execute
              tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
              tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
              tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
              EagerTensor_init
              _PyObject_MakeTpCall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              PyObject_Call
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault


              PyEval_EvalCode



              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              PyEval_EvalCode


              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall

              Py_RunMain
              Py_BytesMain

              __libc_start_main
              _start
      *** End stack trace ***

      2023-01-12 09:34:39.349269: I tensorflow/core/common_runtime/optimization_registry.cc:66] Running optimization phase 10
      2023-01-12 09:34:39.349340: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: AccumulateNV2RemovePass
      2023-01-12 09:34:39.349526: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_0_phase_10_AccumulateNV2RemovePass_94667550137232 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
      2023-01-12 09:34:39.458367: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

              tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
              tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


              tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
              tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)

              tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
              tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
              tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
              tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
              tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
              tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


              tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
              tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
              tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
              TFE_Execute
              tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
              tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
              tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
              EagerTensor_init
              _PyObject_MakeTpCall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              PyObject_Call
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault


              PyEval_EvalCode



              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              PyEval_EvalCode


              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall

              Py_RunMain
              Py_BytesMain

              __libc_start_main
              _start
      *** End stack trace ***

      2023-01-12 09:34:39.458590: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: LowerFunctionalOpsPass
      2023-01-12 09:34:39.459187: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_0_phase_10_LowerFunctionalOpsPass_94667550137232 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
      2023-01-12 09:34:39.556216: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

              tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
              tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


              tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
              tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)

              tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
              tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
              tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
              tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
              tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
              tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


              tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
              tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
              tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
              TFE_Execute
              tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
              tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
              tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
              EagerTensor_init
              _PyObject_MakeTpCall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              PyObject_Call
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault


              PyEval_EvalCode



              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              PyEval_EvalCode


              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall

              Py_RunMain
              Py_BytesMain

              __libc_start_main
              _start
      *** End stack trace ***

      2023-01-12 09:34:39.556428: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: ParallelConcatRemovePass
      2023-01-12 09:34:39.556742: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_0_phase_10_ParallelConcatRemovePass_94667550137232 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
      2023-01-12 09:34:39.651309: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

              tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
              tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


              tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
              tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)

              tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
              tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
              tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
              tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
              tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
              tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


              tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
              tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
              tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
              TFE_Execute
              tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
              tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
              tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
              EagerTensor_init
              _PyObject_MakeTpCall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              PyObject_Call
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault


              PyEval_EvalCode



              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              PyEval_EvalCode


              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall

              Py_RunMain
              Py_BytesMain

              __libc_start_main
              _start
      *** End stack trace ***

      2023-01-12 09:34:39.651550: I tensorflow/core/common_runtime/optimization_registry.cc:66] Running optimization phase 35
      2023-01-12 09:34:39.651661: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: IsolatePlacerInspectionRequiredOpsPass
      2023-01-12 09:34:39.651680: I tensorflow/core/common_runtime/isolate_placer_inspection_required_ops_pass.cc:34] IsolatePlacerInspectionRequiredOpsPass::Run
      2023-01-12 09:34:39.653830: I tensorflow/core/util/dump_graph.cc:171] /tmp/isolate_deep_ops_before.pbtxt
      2023-01-12 09:34:39.653888: I tensorflow/core/util/dump_graph.cc:172] node {
        name: "input"
        op: "_Arg"
        device: "/job:localhost/replica:0/task:0/device:CPU:0"
        attr {
          key: "T"
          value {
            type: DT_DOUBLE
          }
        }
        attr {
          key: "index"
          value {
            i: 0
          }
        }
      }
      node {
        name: "_EagerConst"
        op: "_EagerConst"
        input: "input"
        device: "/job:localhost/replica:0/task:0/device:CPU:0"
        attr {
          key: "T"
          value {
            type: DT_DOUBLE
          }
        }
      }
      node {
        name: "output_RetVal"
        op: "_Retval"
        input: "_EagerConst"
        device: "/job:localhost/replica:0/task:0/device:CPU:0"
        attr {
          key: "T"
          value {
            type: DT_DOUBLE
          }
        }
        attr {
          key: "index"
          value {
            i: 0
          }
        }
      }
      library {
      }
      versions {
        producer: 1286
      }

      2023-01-12 09:34:39.655013: I tensorflow/core/util/dump_graph.cc:206] Dumped Graph to /tmp/isolate_deep_ops_before.pbtxt
      2023-01-12 09:34:39.656114: I tensorflow/core/util/dump_graph.cc:171] /tmp/isolate_deep_ops_after.pbtxt
      2023-01-12 09:34:39.656204: I tensorflow/core/util/dump_graph.cc:172] node {
        name: "input"
        op: "_Arg"
        device: "/job:localhost/replica:0/task:0/device:CPU:0"
        attr {
          key: "T"
          value {
            type: DT_DOUBLE
          }
        }
        attr {
          key: "index"
          value {
            i: 0
          }
        }
      }
      node {
        name: "_EagerConst"
        op: "_EagerConst"
        input: "input"
        device: "/job:localhost/replica:0/task:0/device:CPU:0"
        attr {
          key: "T"
          value {
            type: DT_DOUBLE
          }
        }
      }
      node {
        name: "output_RetVal"
        op: "_Retval"
        input: "_EagerConst"
        device: "/job:localhost/replica:0/task:0/device:CPU:0"
        attr {
          key: "T"
          value {
            type: DT_DOUBLE
          }
        }
        attr {
          key: "index"
          value {
            i: 0
          }
        }
      }
      library {
      }
      versions {
        producer: 1286
      }

      2023-01-12 09:34:39.656531: I tensorflow/core/util/dump_graph.cc:206] Dumped Graph to /tmp/isolate_deep_ops_after.pbtxt
      2023-01-12 09:34:39.656817: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_0_phase_35_IsolatePlacerInspectionRequiredOpsPass_94667550137232 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
      2023-01-12 09:34:39.750712: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

              tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
              tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


              tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
              tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)

              tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
              tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
              tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
              tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
              tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
              tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


              tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
              tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
              tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
              TFE_Execute
              tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
              tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
              tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
              EagerTensor_init
              _PyObject_MakeTpCall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              PyObject_Call
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault


              PyEval_EvalCode



              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              PyEval_EvalCode


              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall

              Py_RunMain
              Py_BytesMain

              __libc_start_main
              _start
      *** End stack trace ***

      2023-01-12 09:34:39.751211: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: IntroduceFloatingPointJitterPass
      2023-01-12 09:34:39.751323: I tensorflow/compiler/jit/introduce_floating_point_jitter_pass.cc:126] Nothing to do
      2023-01-12 09:34:39.751560: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_0_phase_35_IntroduceFloatingPointJitterPass_94667550137232 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
      2023-01-12 09:34:39.842714: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

              tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
              tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


              tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
              tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)

              tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
              tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
              tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
              tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
              tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
              tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


              tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
              tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
              tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
              TFE_Execute
              tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
              tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
              tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
              EagerTensor_init
              _PyObject_MakeTpCall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              PyObject_Call
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault


              PyEval_EvalCode



              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              PyEval_EvalCode


              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall

              Py_RunMain
              Py_BytesMain

              __libc_start_main
              _start
      *** End stack trace ***

      2023-01-12 09:34:39.843228: I tensorflow/core/common_runtime/optimization_registry.cc:66] Running optimization phase 36
      2023-01-12 09:34:39.843258: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: EncapsulateXlaComputationsPass
      2023-01-12 09:34:39.843434: W tensorflow/core/util/dump_graph.cc:134] Failed to dump encapsulate_xla_computations_before because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
      2023-01-12 09:34:39.943996: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

              tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
              tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


              tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
              tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
              tensorflow::EncapsulateXlaComputationsPass::Run(tensorflow::GraphOptimizationPassOptions const&)
              tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
              tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
              tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
              tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
              tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
              tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


              tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
              tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
              tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
              TFE_Execute
              tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
              tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
              tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
              EagerTensor_init
              _PyObject_MakeTpCall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              PyObject_Call
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault


              PyEval_EvalCode



              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              PyEval_EvalCode


              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall

              Py_RunMain
              Py_BytesMain

              __libc_start_main
              _start
      *** End stack trace ***

      2023-01-12 09:34:39.944481: I tensorflow/compiler/jit/encapsulate_xla_computations_pass.cc:382] EncapsulateXlaComputations(): (failed to create writable file: INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified)
      2023-01-12 09:34:39.945744: I tensorflow/core/graph/graph.cc:529] AddNode: no type constructor for _SOURCE
      2023-01-12 09:34:39.945891: I tensorflow/core/graph/graph.cc:529] AddNode: no type constructor for _SINK
      2023-01-12 09:34:39.946236: I tensorflow/core/graph/graph.cc:529] AddNode: no type constructor for _SOURCE
      2023-01-12 09:34:39.946333: I tensorflow/core/graph/graph.cc:529] AddNode: no type constructor for _SINK
      2023-01-12 09:34:39.946775: W tensorflow/core/util/dump_graph.cc:134] Failed to dump encapsulate_xla_computations_halfway because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
      2023-01-12 09:34:40.047939: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

              tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
              tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


              tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
              tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
              tensorflow::EncapsulateXlaComputationsPass::Run(tensorflow::GraphOptimizationPassOptions const&)
              tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
              tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
              tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
              tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
              tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
              tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


              tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
              tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
              tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
              TFE_Execute
              tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
              tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
              tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
              EagerTensor_init
              _PyObject_MakeTpCall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              PyObject_Call
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault


              PyEval_EvalCode



              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              PyEval_EvalCode


              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall

              Py_RunMain
              Py_BytesMain

              __libc_start_main
              _start
      *** End stack trace ***

      2023-01-12 09:34:40.048524: I tensorflow/compiler/jit/encapsulate_xla_computations_pass.cc:393] EncapsulateXlaComputations() half-way: (failed to create writable file: INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified)
      2023-01-12 09:34:40.048753: W tensorflow/core/util/dump_graph.cc:134] Failed to dump encapsulate_xla_computations_after because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
      2023-01-12 09:34:40.144636: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

              tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
              tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


              tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
              tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
              tensorflow::EncapsulateXlaComputationsPass::Run(tensorflow::GraphOptimizationPassOptions const&)
              tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
              tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
              tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
              tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
              tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
              tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


              tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
              tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
              tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
              TFE_Execute
              tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
              tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
              tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
              EagerTensor_init
              _PyObject_MakeTpCall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              PyObject_Call
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault


              PyEval_EvalCode



              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              PyEval_EvalCode


              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall

              Py_RunMain
              Py_BytesMain

              __libc_start_main
              _start
      *** End stack trace ***

      2023-01-12 09:34:40.145158: I tensorflow/compiler/jit/encapsulate_xla_computations_pass.cc:399] EncapsulateXlaComputations() finished: (failed to create writable file: INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified)
      2023-01-12 09:34:40.145385: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_0_phase_36_EncapsulateXlaComputationsPass_94667551040240 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
      2023-01-12 09:34:40.239913: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

              tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
              tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


              tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
              tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)

              tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
              tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
              tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
              tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
              tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
              tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


              tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
              tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
              tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
              TFE_Execute
              tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
              tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
              tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
              EagerTensor_init
              _PyObject_MakeTpCall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              PyObject_Call
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault


              PyEval_EvalCode



              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              PyEval_EvalCode


              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall

              Py_RunMain
              Py_BytesMain

              __libc_start_main
              _start
      *** End stack trace ***

      2023-01-12 09:34:40.240428: I tensorflow/core/common_runtime/optimization_registry.cc:66] Running optimization phase 37
      2023-01-12 09:34:40.240565: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: FunctionalizeControlFlowForXlaPass
      2023-01-12 09:34:40.240752: W tensorflow/core/util/dump_graph.cc:134] Failed to dump functionalize_control_flow_before because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
      2023-01-12 09:34:40.369760: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

              tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
              tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


              tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
              tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
              tensorflow::FunctionalizeControlFlowForXlaPass::Run(tensorflow::GraphOptimizationPassOptions const&)
              tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
              tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
              tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
              tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
              tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
              tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


              tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
              tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
              tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
              TFE_Execute
              tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
              tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
              tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
              EagerTensor_init
              _PyObject_MakeTpCall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              PyObject_Call
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault


              PyEval_EvalCode



              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              PyEval_EvalCode


              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall

              Py_RunMain
              Py_BytesMain

              __libc_start_main
              _start
      *** End stack trace ***

      2023-01-12 09:34:40.374650: W tensorflow/core/util/dump_graph.cc:134] Failed to dump functionalize_control_flow_after because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
      2023-01-12 09:34:40.477476: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

              tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
              tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


              tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
              tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
              tensorflow::FunctionalizeControlFlowForXlaPass::Run(tensorflow::GraphOptimizationPassOptions const&)
              tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
              tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
              tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
              tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
              tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
              tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


              tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
              tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
              tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
              TFE_Execute
              tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
              tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
              tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
              EagerTensor_init
              _PyObject_MakeTpCall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              PyObject_Call
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault


              PyEval_EvalCode



              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              PyEval_EvalCode


              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall

              Py_RunMain
              Py_BytesMain

              __libc_start_main
              _start
      *** End stack trace ***

      2023-01-12 09:34:40.478233: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_0_phase_37_FunctionalizeControlFlowForXlaPass_94667551040240 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
      2023-01-12 09:34:40.577820: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

              tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
              tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


              tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
              tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)

              tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
              tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
              tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
              tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
              tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
              tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


              tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
              tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
              tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
              TFE_Execute
              tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
              tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
              tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
              EagerTensor_init
              _PyObject_MakeTpCall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              PyObject_Call
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault


              PyEval_EvalCode



              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              PyEval_EvalCode


              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall

              Py_RunMain
              Py_BytesMain

              __libc_start_main
              _start
      *** End stack trace ***

      2023-01-12 09:34:40.578361: I tensorflow/core/common_runtime/optimization_registry.cc:66] Running optimization phase 99999
      2023-01-12 09:34:40.578442: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: WeakTypeInferencePass
      2023-01-12 09:34:40.578547: I tensorflow/core/common_runtime/type_inference.cc:141] TypeInferencePass::Run
      2023-01-12 09:34:40.578731: W tensorflow/core/util/dump_graph.cc:134] Failed to dump forward_type_inference_before because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
      2023-01-12 09:34:40.675240: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

              tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
              tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


              tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
              tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
              tensorflow::TypeInferencePass::Run(tensorflow::GraphOptimizationPassOptions const&)
              tensorflow::WeakTypeInferencePass::Run(tensorflow::GraphOptimizationPassOptions const&)
              tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
              tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
              tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
              tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
              tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
              tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


              tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
              tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
              tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
              TFE_Execute
              tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
              tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
              tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
              EagerTensor_init
              _PyObject_MakeTpCall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              PyObject_Call
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault


              PyEval_EvalCode



              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault

              _PyFunction_Vectorcall

              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault

              PyEval_EvalCode


              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall
              _PyEval_EvalFrameDefault
              _PyFunction_Vectorcall

              Py_RunMain
              Py_BytesMain

              __libc_start_main
              _start
      *** End stack trace ***

    2023-01-12 09:34:40.675992: I tensorflow/core/common_runtime/type_inference.cc:162] 
      node: name: "_SOURCE"
    op: "NoOp"

      op def: name: "NoOp"

    2023-01-12 09:34:40.676102: I tensorflow/core/common_runtime/type_inference.cc:162] 
      node: name: "_SINK"
    op: "NoOp"

      op def: name: "NoOp"

    2023-01-12 09:34:40.676377: I tensorflow/core/common_runtime/type_inference.cc:162] 
      node: name: "input"
    op: "_Arg"
    attr {
      key: "T"
      value {
        type: DT_DOUBLE
      }
    }
    attr {
      key: "index"
      value {
        i: 0
      }
    }

      op def: name: "_Arg"
    output_arg {
      name: "output"
      description: "The argument."
      type_attr: "T"
    }
    attr {
      name: "T"
      type: "type"
    }
    attr {
      name: "index"
      type: "int"
      description: "This argument is the index-th argument of the function.\n\nAttributes for shape inference:\n1. _output_shapes: this attribute should contain a list of TensorShapeProto\n   describing the shape(s) of the tensor(s) this _Arg node will produce. If set,\n   _Arg node\'s shape inference function will use it as the node\'s output shapes.\n2. _handle_dtypes and _handle_shapes: these attributes can be set on an _Arg\n   node producing resource output(s). If set, value of _handle_dtypes should\n   contain the dtype(s) of the resource(s) and value of _handle_shapes should\n   contain the shape(s) of the resource(s). If both attributes are set, _Arg\n   node\'s shape inference function will use their values as the node\'s output\n   handle\'s type(s) and shape(s)."
      has_minimum: true
    }
    summary: "A graph node which represents an argument to a function."
    is_stateful: true

    2023-01-12 09:34:40.676686: I tensorflow/core/common_runtime/type_inference.cc:162] 
      node: name: "_EagerConst"
    op: "_EagerConst"
    input: "input"
    device: "/job:localhost/replica:0/task:0/device:CPU:0"
    attr {
      key: "T"
      value {
        type: DT_DOUBLE
      }
    }

      op def: name: "_EagerConst"
    input_arg {
      name: "input"
      type_attr: "T"
    }
    output_arg {
      name: "output"
      type_attr: "T"
    }
    attr {
      name: "T"
      type: "type"
    }

    2023-01-12 09:34:40.676951: I tensorflow/core/common_runtime/type_inference.cc:162] 
      node: name: "output_RetVal"
    op: "_Retval"
    input: "_EagerConst"
    attr {
      key: "T"
      value {
        type: DT_DOUBLE
      }
    }
    attr {
      key: "index"
      value {
        i: 0
      }
    }

      op def: name: "_Retval"
    input_arg {
      name: "input"
      description: "The return value."
      type_attr: "T"
    }
    attr {
      name: "T"
      type: "type"
    }
    attr {
      name: "index"
      type: "int"
      description: "This return value is the index-th return value of the function."
      has_minimum: true
    }
    summary: "A graph node which represents a return value of a function."
    is_stateful: true

    2023-01-12 09:34:40.679957: I tensorflow/core/common_runtime/type_inference.cc:258] Iteration 0, 3 nodes in queue
    2023-01-12 09:34:40.680080: I tensorflow/core/common_runtime/type_inference.cc:263]   visiting _SOURCE
    2023-01-12 09:34:40.680190: I tensorflow/core/common_runtime/type_inference.cc:272]   done name: "_SOURCE"
    op: "NoOp"

    2023-01-12 09:34:40.680246: I tensorflow/core/common_runtime/type_inference.cc:284]   closing _SOURCE - all sources closed
    2023-01-12 09:34:40.680278: I tensorflow/core/common_runtime/type_inference.cc:263]   visiting _SINK
    2023-01-12 09:34:40.680321: I tensorflow/core/common_runtime/type_inference.cc:272]   done name: "_SINK"
    op: "NoOp"

    2023-01-12 09:34:40.680352: I tensorflow/core/common_runtime/type_inference.cc:284]   closing _SINK - all sources closed
    2023-01-12 09:34:40.680373: I tensorflow/core/common_runtime/type_inference.cc:263]   visiting input
    2023-01-12 09:34:40.680581: I tensorflow/core/common_runtime/type_inference.cc:272]   done name: "input"
    op: "_Arg"
    attr {
      key: "T"
      value {
        type: DT_DOUBLE
      }
    }
    attr {
      key: "index"
      value {
        i: 0
      }
    }

    2023-01-12 09:34:40.680735: I tensorflow/core/common_runtime/type_inference.cc:284]   closing input - all sources closed
    2023-01-12 09:34:40.680788: I tensorflow/core/common_runtime/type_inference.cc:263]   visiting _EagerConst
    2023-01-12 09:34:40.680905: I tensorflow/core/common_runtime/type_inference.cc:272]   done name: "_EagerConst"
    op: "_EagerConst"
    input: "input"
    device: "/job:localhost/replica:0/task:0/device:CPU:0"
    attr {
      key: "T"
      value {
        type: DT_DOUBLE
      }
    }

    2023-01-12 09:34:40.680961: I tensorflow/core/common_runtime/type_inference.cc:284]   closing _EagerConst - all sources closed
    2023-01-12 09:34:40.680994: I tensorflow/core/common_runtime/type_inference.cc:263]   visiting output_RetVal
    2023-01-12 09:34:40.681200: I tensorflow/core/common_runtime/type_inference.cc:272]   done name: "output_RetVal"
    op: "_Retval"
    input: "_EagerConst"
    attr {
      key: "T"
      value {
        type: DT_DOUBLE
      }
    }
    attr {
      key: "index"
      value {
        i: 0
      }
    }

    2023-01-12 09:34:40.681354: I tensorflow/core/common_runtime/type_inference.cc:284]   closing output_RetVal - all sources closed
    2023-01-12 09:34:40.681447: I tensorflow/core/common_runtime/type_inference.cc:314] Done iteration 0, 5 nodes closed
    2023-01-12 09:34:40.681471: I tensorflow/core/common_runtime/type_inference.cc:318] Finished after 1 iterations; done 5 of 5 nodes in 5 visits
    2023-01-12 09:34:40.681574: W tensorflow/core/util/dump_graph.cc:134] Failed to dump forward_type_inference_after because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
    2023-01-12 09:34:40.798279: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

            tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
            tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


            tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
            tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
            tensorflow::TypeInferencePass::Run(tensorflow::GraphOptimizationPassOptions const&)
            tensorflow::WeakTypeInferencePass::Run(tensorflow::GraphOptimizationPassOptions const&)
            tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
            tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
            tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
            tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


            tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
            tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
            tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
            TFE_Execute
            tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
            tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
            tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
            EagerTensor_init
    *** End stack trace ***

    2023-01-12 09:34:40.799058: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_0_phase_99999_WeakTypeInferencePass_94667551040240 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
    2023-01-12 09:34:40.908042: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

            tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
            tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


            tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
            tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)

            tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
            tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
            tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
            tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


            tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
            tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
            tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
            TFE_Execute
            tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
            tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
            tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
            EagerTensor_init
    *** End stack trace ***

  2023-01-12 09:34:40.909907: I tensorflow/core/common_runtime/optimization_registry.cc:87] Finished optimization of a group 0
  2023-01-12 09:34:40.910549: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_grouping_0_94667551040240 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
  2023-01-12 09:34:41.028222: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

          tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
          tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


          tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
          tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)

          tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
          tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
          tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
          tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
          tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
          tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


          tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
          tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
          tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
          TFE_Execute
          tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
          tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
          tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
          EagerTensor_init
  *** End stack trace ***

  2023-01-12 09:34:41.028738: I tensorflow/core/common_runtime/function_utils.cc:78] Graph Before calling Placer #nodes 5 #edges 6
  2023-01-12 09:34:41.029003: I tensorflow/core/common_runtime/function_utils.cc:82] || 
  2023-01-12 09:34:41.029055: I tensorflow/core/common_runtime/function_utils.cc:82] || (n2:double@CPU:0) -> (n3:double@CPU:0) {
  2023-01-12 09:34:41.029071: I tensorflow/core/common_runtime/function_utils.cc:82] ||   n3 = _EagerConst[T=double, device=CPU:0](n2)
  2023-01-12 09:34:41.029082: I tensorflow/core/common_runtime/function_utils.cc:82] || }
  2023-01-12 09:34:41.029092: I tensorflow/core/common_runtime/function_utils.cc:82] || 
    2023-01-12 09:34:41.029176: W tensorflow/core/util/dump_graph.cc:134] Failed to dump placer_input because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
    2023-01-12 09:34:41.140685: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

            tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
            tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


            tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
            tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
            tensorflow::Placer::Run()
            tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
            tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
            tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


            tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
            tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
            tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
            TFE_Execute
            tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
            tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
            tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
            EagerTensor_init
    *** End stack trace ***

    2023-01-12 09:34:41.144105: I tensorflow/core/common_runtime/placer.cc:178]     input: requested: '' assigned: '/job:localhost/replica:0/task:0/device:CPU:0'
    2023-01-12 09:34:41.144996: I tensorflow/core/common_runtime/placer.cc:178]     _EagerConst: requested: '/job:localhost/replica:0/task:0/device:CPU:0' assigned: ''
    2023-01-12 09:34:41.145029: I tensorflow/core/common_runtime/placer.cc:178]     output_RetVal: requested: '' assigned: '/job:localhost/replica:0/task:0/device:CPU:0'
    2023-01-12 09:34:41.145945: I tensorflow/core/common_runtime/placer.cc:120] 
    Node:
    name: "input"
    op: "_Arg"
    attr {
      key: "T"
      value {
        type: DT_DOUBLE
      }
    }
    attr {
      key: "index"
      value {
        i: 0
      }
    }
    placed on: /job:localhost/replica:0/task:0/device:CPU:0
    2023-01-12 09:34:41.146630: I tensorflow/core/common_runtime/placer.cc:120] 
    Node:
    name: "_EagerConst"
    op: "_EagerConst"
    input: "input"
    device: "/job:localhost/replica:0/task:0/device:CPU:0"
    attr {
      key: "T"
      value {
        type: DT_DOUBLE
      }
    }
    placed on: /job:localhost/replica:0/task:0/device:CPU:0
    2023-01-12 09:34:41.146944: I tensorflow/core/common_runtime/placer.cc:120] 
    Node:
    name: "output_RetVal"
    op: "_Retval"
    input: "_EagerConst"
    attr {
      key: "T"
      value {
        type: DT_DOUBLE
      }
    }
    attr {
      key: "index"
      value {
        i: 0
      }
    }
    placed on: /job:localhost/replica:0/task:0/device:CPU:0
    2023-01-12 09:34:41.147106: W tensorflow/core/util/dump_graph.cc:134] Failed to dump placer_output because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
    2023-01-12 09:34:41.259327: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

            tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
            tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


            tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
            tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
            tensorflow::Placer::Run()
            tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
            tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
            tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


            tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
            tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
            tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
            TFE_Execute
            tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
            tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
            tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
            EagerTensor_init

    *** End stack trace ***

    2023-01-12 09:34:41.349374: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INTERNAL: Failed to get the directory for colocation_graph because dump location is not specified through TF_DUMP_GRAPH_PREFIX environment variable". *** Begin stack trace ***

            tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
            tsl::Status tsl::errors::Internal<char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*>(char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*)


            tensorflow::Placer::Run()
            tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
            tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
            tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


            tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
            tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
            tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
            TFE_Execute
            tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
            tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
            tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
            EagerTensor_init
    *** End stack trace ***

  2023-01-12 09:34:41.349517: E tensorflow/core/common_runtime/placer.cc:93] Failed to write final colocation graph to file  with INTERNAL: Failed to get the directory for colocation_graph because dump location is not specified through TF_DUMP_GRAPH_PREFIX environment variable
  2023-01-12 09:34:41.349717: I tensorflow/core/common_runtime/function_utils.cc:78] Graph Before running POST_PLACEMENT passes #nodes 5 #edges 6
  2023-01-12 09:34:41.349998: I tensorflow/core/common_runtime/function_utils.cc:82] || 
  2023-01-12 09:34:41.350042: I tensorflow/core/common_runtime/function_utils.cc:82] || (n2:double@CPU:0) -> (n3:double@CPU:0) {
  2023-01-12 09:34:41.350061: I tensorflow/core/common_runtime/function_utils.cc:82] ||   n3 = _EagerConst[T=double, device=CPU:0](n2)
  2023-01-12 09:34:41.350067: I tensorflow/core/common_runtime/function_utils.cc:82] || }
  2023-01-12 09:34:41.350072: I tensorflow/core/common_runtime/function_utils.cc:82] || 
  2023-01-12 09:34:41.350122: I tensorflow/core/common_runtime/optimization_registry.cc:54] Starting optimization of a group 1
    2023-01-12 09:34:41.350221: W tensorflow/core/util/dump_graph.cc:134] Failed to dump before_grouping_1_94667551040240 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
    2023-01-12 09:34:41.446536: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

            tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
            tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


            tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
            tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)

            tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
            tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
            tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
            tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


            tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
            tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
            tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
            TFE_Execute
            tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
            tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
            tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
            EagerTensor_init
    *** End stack trace ***

  2023-01-12 09:34:41.447121: I tensorflow/core/common_runtime/optimization_registry.cc:87] Finished optimization of a group 1
  2023-01-12 09:34:41.447325: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_grouping_1_94667551040240 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
  2023-01-12 09:34:41.542925: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

          tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
          tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


          tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
          tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)

          tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
          tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
          tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
          tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
          tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
          tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


          tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
          tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
          tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
          TFE_Execute
          tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
          tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
          tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
          EagerTensor_init
  *** End stack trace ***

  2023-01-12 09:34:41.543681: I tensorflow/core/common_runtime/function_utils.cc:78] Graph Before running POST_REWRITE_FOR_EXEC passes #nodes 5 #edges 6
  2023-01-12 09:34:41.544114: I tensorflow/core/common_runtime/function_utils.cc:82] || 
  2023-01-12 09:34:41.544176: I tensorflow/core/common_runtime/function_utils.cc:82] || (n2:double@CPU:0) -> (n3:double@CPU:0) {
  2023-01-12 09:34:41.544194: I tensorflow/core/common_runtime/function_utils.cc:82] ||   n3 = _EagerConst[T=double, device=CPU:0](n2)
  2023-01-12 09:34:41.544206: I tensorflow/core/common_runtime/function_utils.cc:82] || }
  2023-01-12 09:34:41.544217: I tensorflow/core/common_runtime/function_utils.cc:82] || 
  2023-01-12 09:34:41.544245: I tensorflow/core/common_runtime/optimization_registry.cc:54] Starting optimization of a group 2
    2023-01-12 09:34:41.544375: W tensorflow/core/util/dump_graph.cc:134] Failed to dump before_grouping_2_94667551040240 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
    2023-01-12 09:34:41.640135: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

            tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
            tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


            tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
            tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)

            tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
            tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
            tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
            tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


            tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
            tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
            tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
            TFE_Execute
            tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
            tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
            tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
            EagerTensor_init
    *** End stack trace ***

    2023-01-12 09:34:41.640708: I tensorflow/core/common_runtime/optimization_registry.cc:66] Running optimization phase 5
    2023-01-12 09:34:41.640769: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: CloneConstantsForBetterClusteringPass
    2023-01-12 09:34:41.640836: I tensorflow/compiler/jit/xla_cluster_util.cc:297] GetGlobalJitLevelForGraph returning -1
    2023-01-12 09:34:41.641013: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_2_phase_5_CloneConstantsForBetterClusteringPass_94667551040240 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
    2023-01-12 09:34:41.732535: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

            tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
            tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


            tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
            tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)

            tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
            tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
            tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
            tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


            tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
            tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
            tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
            TFE_Execute
            tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
            tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
            tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
            EagerTensor_init
    *** End stack trace ***

    2023-01-12 09:34:41.733120: I tensorflow/core/common_runtime/optimization_registry.cc:66] Running optimization phase 9
    2023-01-12 09:34:41.733151: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: ClusterScopingPass
    2023-01-12 09:34:41.733200: I tensorflow/compiler/jit/xla_cluster_util.cc:297] GetGlobalJitLevelForGraph returning -1
    2023-01-12 09:34:41.733537: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_2_phase_9_ClusterScopingPass_94667551040240 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
    2023-01-12 09:34:41.829186: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

            tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
            tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


            tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
            tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)

            tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
            tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
            tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
            tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


            tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
            tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
            tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
            TFE_Execute
            tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
            tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
            tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
            EagerTensor_init
            _PyObject_MakeTpCall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            PyObject_Call
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault


            PyEval_EvalCode



            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            PyEval_EvalCode


            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall

            Py_RunMain
            Py_BytesMain

            __libc_start_main
            _start
    *** End stack trace ***

    2023-01-12 09:34:41.829772: I tensorflow/core/common_runtime/optimization_registry.cc:66] Running optimization phase 10
    2023-01-12 09:34:41.829805: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: MarkForCompilationPass
    2023-01-12 09:34:41.829896: I tensorflow/compiler/jit/xla_cluster_util.cc:297] GetGlobalJitLevelForGraph returning -1
    2023-01-12 09:34:41.830393: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaWhile
    2023-01-12 09:34:41.830677: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: While
    2023-01-12 09:34:41.830837: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Case
    2023-01-12 09:34:41.830910: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Svd
    2023-01-12 09:34:41.830963: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SelfAdjointEigV2
    2023-01-12 09:34:41.831039: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaVariadicReduce
    2023-01-12 09:34:41.831099: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaPad
    2023-01-12 09:34:41.831204: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaDotV2
    2023-01-12 09:34:41.831350: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaDot
    2023-01-12 09:34:41.831569: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaDequantize
    2023-01-12 09:34:41.831696: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaCustomCallV2
    2023-01-12 09:34:41.831788: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaCustomCall
    2023-01-12 09:34:41.831850: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaConv
    2023-01-12 09:34:41.831906: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaBroadcastHelper
    2023-01-12 09:34:41.831980: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceScatterNdAdd
    2023-01-12 09:34:41.832041: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceScatterNdUpdate
    2023-01-12 09:34:41.832097: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceScatterMin
    2023-01-12 09:34:41.832157: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceScatterAdd
    2023-01-12 09:34:41.832235: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: AssignVariableOp
    2023-01-12 09:34:41.832310: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ReadVariableOp
    2023-01-12 09:34:41.832502: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Unpack
    2023-01-12 09:34:41.832592: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: _UnaryOpsComposition
    2023-01-12 09:34:41.832680: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Digamma
    2023-01-12 09:34:41.832782: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Lgamma
    2023-01-12 09:34:41.832865: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Tanh
    2023-01-12 09:34:41.833011: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Square
    2023-01-12 09:34:41.833122: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Softsign
    2023-01-12 09:34:41.833189: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Softplus
    2023-01-12 09:34:41.833348: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Sinh
    2023-01-12 09:34:41.833483: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Neg
    2023-01-12 09:34:41.833580: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: PopulationCount
    2023-01-12 09:34:41.833752: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceScatterDiv
    2023-01-12 09:34:41.833853: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Log1p
    2023-01-12 09:34:41.833984: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Reciprocal
    2023-01-12 09:34:41.834126: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Inv
    2023-01-12 09:34:41.834240: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceScatterSub
    2023-01-12 09:34:41.834389: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Expm1
    2023-01-12 09:34:41.834525: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Exp
    2023-01-12 09:34:41.834664: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Sin
    2023-01-12 09:34:41.834771: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Ceil
    2023-01-12 09:34:41.834865: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Where
    2023-01-12 09:34:41.834939: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Asinh
    2023-01-12 09:34:41.835023: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Asin
    2023-01-12 09:34:41.835121: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Abs
    2023-01-12 09:34:41.835174: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: IsNan
    2023-01-12 09:34:41.835259: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Conj
    2023-01-12 09:34:41.835368: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Angle
    2023-01-12 09:34:41.835468: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TridiagonalSolve
    2023-01-12 09:34:41.835543: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: InvertPermutation
    2023-01-12 09:34:41.835631: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ConjugateTranspose
    2023-01-12 09:34:41.835744: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyPowerSign
    2023-01-12 09:34:41.835889: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Real
    2023-01-12 09:34:41.835949: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyAddSign
    2023-01-12 09:34:41.836092: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaConvV2
    2023-01-12 09:34:41.836257: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyAdadelta
    2023-01-12 09:34:41.836338: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyAdagradDA
    2023-01-12 09:34:41.836478: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyAdagradV2
    2023-01-12 09:34:41.836628: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyAdagrad
    2023-01-12 09:34:41.837097: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyMomentum
    2023-01-12 09:34:41.837281: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyGradientDescent
    2023-01-12 09:34:41.837394: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TopKV2
    2023-01-12 09:34:41.837521: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ToBool
    2023-01-12 09:34:41.837625: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorListPushBack
    2023-01-12 09:34:41.837719: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorListSetItem
    2023-01-12 09:34:41.837827: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorListConcatV2
    2023-01-12 09:34:41.838040: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceScatterMax
    2023-01-12 09:34:41.838157: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorListStack
    2023-01-12 09:34:41.838265: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorListGetItem
    2023-01-12 09:34:41.838334: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorListElementShape
    2023-01-12 09:34:41.838394: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: EmptyTensorList
    2023-01-12 09:34:41.838484: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorListReserve
    2023-01-12 09:34:41.838561: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorListLength
    2023-01-12 09:34:41.838761: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorListSplit
    2023-01-12 09:34:41.838873: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorArrayGradV3
    2023-01-12 09:34:41.838991: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorArrayConcatV3
    2023-01-12 09:34:41.839054: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorArrayScatterV3
    2023-01-12 09:34:41.839107: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorArrayGatherV3
    2023-01-12 09:34:41.839160: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorStridedSliceUpdate
    2023-01-12 09:34:41.839235: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StridedSliceGrad
    2023-01-12 09:34:41.839293: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorArraySplitV3
    2023-01-12 09:34:41.839337: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessRandomGetAlg
    2023-01-12 09:34:41.839400: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessRandomGetKeyCounter
    2023-01-12 09:34:41.839462: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessRandomNormalV2
    2023-01-12 09:34:41.839596: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Sign
    2023-01-12 09:34:41.839723: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessRandomUniformFullIntV2
    2023-01-12 09:34:41.840050: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessRandomUniformIntV2
    2023-01-12 09:34:41.840218: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Atan
    2023-01-12 09:34:41.840331: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessParameterizedTruncatedNormal
    2023-01-12 09:34:41.840463: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessTruncatedNormal
    2023-01-12 09:34:41.840607: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessRandomUniformFullInt
    2023-01-12 09:34:41.840677: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessRandomUniformInt
    2023-01-12 09:34:41.840739: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatefulUniformFullInt
    2023-01-12 09:34:41.840813: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatefulTruncatedNormal
    2023-01-12 09:34:41.840927: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatefulUniform
    2023-01-12 09:34:41.841424: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StackCloseV2
    2023-01-12 09:34:41.841610: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyAdam
    2023-01-12 09:34:41.841753: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StackPopV2
    2023-01-12 09:34:41.841908: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StackPushV2
    2023-01-12 09:34:41.842007: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessRandomNormal
    2023-01-12 09:34:41.842109: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StackV2
    2023-01-12 09:34:41.842230: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaSpmdShardToFullShape
    2023-01-12 09:34:41.842365: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorArrayWriteV3
    2023-01-12 09:34:41.842460: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SplitV
    2023-01-12 09:34:41.842634: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Split
    2023-01-12 09:34:41.842706: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SpaceToDepth
    2023-01-12 09:34:41.842766: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SpaceToBatch
    2023-01-12 09:34:41.842842: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SpaceToBatchND
    2023-01-12 09:34:41.842933: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaVariadicSort
    2023-01-12 09:34:41.843033: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SparseSoftmaxCrossEntropyWithLogits
    2023-01-12 09:34:41.843133: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SoftmaxCrossEntropyWithLogits
    2023-01-12 09:34:41.843240: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: LogSoftmax
    2023-01-12 09:34:41.843353: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Softmax
    2023-01-12 09:34:41.843510: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Slice
    2023-01-12 09:34:41.843608: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: AssignVariableXlaConcatND
    2023-01-12 09:34:41.843756: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaReduce
    2023-01-12 09:34:41.843883: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaConcatND
    2023-01-12 09:34:41.843963: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ComplexAbs
    2023-01-12 09:34:41.844047: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ReadVariableXlaSplitND
    2023-01-12 09:34:41.860890: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaSplitND
    2023-01-12 09:34:41.861044: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: OnesLike
    2023-01-12 09:34:41.861099: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ZerosLike
    2023-01-12 09:34:41.861218: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Squeeze
    2023-01-12 09:34:41.861275: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ExpandDims
    2023-01-12 09:34:41.861327: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Rank
    2023-01-12 09:34:41.861418: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ShapeN
    2023-01-12 09:34:41.861524: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaSetDynamicDimensionSize
    2023-01-12 09:34:41.861582: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Cos
    2023-01-12 09:34:41.861631: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaSetBound
    2023-01-12 09:34:41.861678: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Tile
    2023-01-12 09:34:41.861806: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorListFromTensor
    2023-01-12 09:34:41.861922: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Shape
    2023-01-12 09:34:41.862119: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Range
    2023-01-12 09:34:41.862279: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaVariadicReduceV2
    2023-01-12 09:34:41.862353: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaRecv
    2023-01-12 09:34:41.862429: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaSend
    2023-01-12 09:34:41.862548: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SelectV2
    2023-01-12 09:34:41.862668: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FakeQuantWithMinMaxVarsGradient
    2023-01-12 09:34:41.862745: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FakeParam
    2023-01-12 09:34:41.862858: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ExtractImagePatches
    2023-01-12 09:34:41.863109: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: AddV2
    2023-01-12 09:34:41.863522: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FusedBatchNormGradV3
    2023-01-12 09:34:41.863708: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Einsum
    2023-01-12 09:34:41.863771: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: DynamicStitch
    2023-01-12 09:34:41.863856: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: DynamicPartition
    2023-01-12 09:34:41.863912: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ReciprocalGrad
    2023-01-12 09:34:41.864082: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: DepthToSpace
    2023-01-12 09:34:41.864361: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Div
    2023-01-12 09:34:41.864578: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MaxPool3DGrad
    2023-01-12 09:34:41.864719: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Acosh
    2023-01-12 09:34:41.864970: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Conv3DBackpropFilterV2
    2023-01-12 09:34:41.865080: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Conv2DBackpropFilter
    2023-01-12 09:34:41.865143: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SoftplusGrad
    2023-01-12 09:34:41.865217: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceStridedSliceAssign
    2023-01-12 09:34:41.865281: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FFT3D
    2023-01-12 09:34:41.865510: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Conv2DBackpropInput
    2023-01-12 09:34:41.865673: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaOptimizationBarrier
    2023-01-12 09:34:41.865793: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Elu
    2023-01-12 09:34:41.865971: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: AddN
    2023-01-12 09:34:41.866098: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ControlTrigger
    2023-01-12 09:34:41.866185: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Reshape
    2023-01-12 09:34:41.866289: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyFtrlV2
    2023-01-12 09:34:41.866414: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ConcatOffset
    2023-01-12 09:34:41.866506: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: PlaceholderWithDefault
    2023-01-12 09:34:41.866650: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FakeQuantWithMinMaxVars
    2023-01-12 09:34:41.866771: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BroadcastGradientArgs
    2023-01-12 09:34:41.866921: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Xdivy
    2023-01-12 09:34:41.866988: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Atanh
    2023-01-12 09:34:41.867063: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FloorMod
    2023-01-12 09:34:41.867120: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Const
    2023-01-12 09:34:41.867331: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessIf
    2023-01-12 09:34:41.867667: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BatchMatMul
    2023-01-12 09:34:41.867912: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Rint
    2023-01-12 09:34:41.868093: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: NonMaxSuppressionV4
    2023-01-12 09:34:41.868324: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixDiagV2
    2023-01-12 09:34:41.868495: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Min
    2023-01-12 09:34:41.868664: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessMultinomial
    2023-01-12 09:34:41.868782: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Betainc
    2023-01-12 09:34:41.868972: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatefulPartitionedCall
    2023-01-12 09:34:41.869111: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Cast
    2023-01-12 09:34:41.869213: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyProximalGradientDescent
    2023-01-12 09:34:41.869303: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RandomGammaGrad
    2023-01-12 09:34:41.869491: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorListPopBack
    2023-01-12 09:34:41.869776: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SquaredDifference
    2023-01-12 09:34:41.869875: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Empty
    2023-01-12 09:34:41.870048: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BesselI1e
    2023-01-12 09:34:41.870254: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ApproxTopK
    2023-01-12 09:34:41.870398: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: LogicalAnd
    2023-01-12 09:34:41.870699: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: LessEqual
    2023-01-12 09:34:41.870908: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Zeta
    2023-01-12 09:34:41.871108: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TridiagonalMatMul
    2023-01-12 09:34:41.871233: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaSharding
    2023-01-12 09:34:41.871299: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Polygamma
    2023-01-12 09:34:41.871354: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: VariableShape
    2023-01-12 09:34:41.871411: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Igammac
    2023-01-12 09:34:41.871465: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResizeNearestNeighbor
    2023-01-12 09:34:41.871569: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: _ArrayToList
    2023-01-12 09:34:41.871672: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: AvgPoolGrad
    2023-01-12 09:34:41.871834: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: IgammaGradA
    2023-01-12 09:34:41.871973: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: OneHot
    2023-01-12 09:34:41.872099: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceScatterNdSub
    2023-01-12 09:34:41.872208: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceGather
    2023-01-12 09:34:41.872313: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MaxPoolGradGrad
    2023-01-12 09:34:41.872424: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessCase
    2023-01-12 09:34:41.872518: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: IsFinite
    2023-01-12 09:34:41.872581: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Pow
    2023-01-12 09:34:41.872640: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BesselI0e
    2023-01-12 09:34:41.872696: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SigmoidGrad
    2023-01-12 09:34:41.872746: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FakeQuantWithMinMaxVarsPerChannel
    2023-01-12 09:34:41.872798: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaSvd
    2023-01-12 09:34:41.872853: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: VarIsInitializedOp
    2023-01-12 09:34:41.873034: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RandomUniform
    2023-01-12 09:34:41.873233: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyFtrl
    2023-01-12 09:34:41.873331: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SoftsignGrad
    2023-01-12 09:34:41.873482: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessRandomUniformV2
    2023-01-12 09:34:41.873556: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RsqrtGrad
    2023-01-12 09:34:41.873722: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatMul
    2023-01-12 09:34:41.873824: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Bincount
    2023-01-12 09:34:41.873902: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: LeakyRelu
    2023-01-12 09:34:41.873980: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyRMSProp
    2023-01-12 09:34:41.874109: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BatchMatMulV3
    2023-01-12 09:34:41.874655: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MaxPool3DGradGrad
    2023-01-12 09:34:41.874788: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: LeftShift
    2023-01-12 09:34:41.874894: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessTruncatedNormalV2
    2023-01-12 09:34:41.874959: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Xlogy
    2023-01-12 09:34:41.875027: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaKeyValueSort
    2023-01-12 09:34:41.875100: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: DeviceIndex
    2023-01-12 09:34:41.875146: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: NextAfter
    2023-01-12 09:34:41.875196: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Sqrt
    2023-01-12 09:34:41.875257: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SqrtGrad
    2023-01-12 09:34:41.875315: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BatchToSpaceND
    2023-01-12 09:34:41.875372: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Erfc
    2023-01-12 09:34:41.875462: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyProximalAdagrad
    2023-01-12 09:34:41.875529: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorScatterMax
    2023-01-12 09:34:41.875680: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Selu
    2023-01-12 09:34:41.875775: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Unique
    2023-01-12 09:34:41.875875: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BitwiseOr
    2023-01-12 09:34:41.875988: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FusedBatchNormV3
    2023-01-12 09:34:41.876077: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaGather
    2023-01-12 09:34:41.876178: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Floor
    2023-01-12 09:34:41.876306: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StridedSlice
    2023-01-12 09:34:41.876454: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: PadV2
    2023-01-12 09:34:41.876595: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Igamma
    2023-01-12 09:34:41.876739: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixSetDiag
    2023-01-12 09:34:41.876836: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Conv3DBackpropInputV2
    2023-01-12 09:34:41.876923: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FusedBatchNormGradV2
    2023-01-12 09:34:41.877030: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FusedBatchNormGrad
    2023-01-12 09:34:41.877121: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RngReadAndSkip
    2023-01-12 09:34:41.877269: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FakeQuantWithMinMaxArgs
    2023-01-12 09:34:41.877385: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: GatherV2
    2023-01-12 09:34:41.877530: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Imag
    2023-01-12 09:34:41.877762: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Cross
    2023-01-12 09:34:41.878029: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Invert
    2023-01-12 09:34:41.878142: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorScatterUpdate
    2023-01-12 09:34:41.878291: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BitwiseAnd
    2023-01-12 09:34:41.878461: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BiasAddGrad
    2023-01-12 09:34:41.878550: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: IsInf
    2023-01-12 09:34:41.878683: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FloorDiv
    2023-01-12 09:34:41.878870: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ApproximateEqual
    2023-01-12 09:34:41.879000: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Less
    2023-01-12 09:34:41.879180: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Fill
    2023-01-12 09:34:41.879468: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: _FusedBatchNormEx
    2023-01-12 09:34:41.879702: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: IdentityN
    2023-01-12 09:34:41.879884: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyKerasMomentum
    2023-01-12 09:34:41.880170: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaDynamicSlice
    2023-01-12 09:34:41.880457: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Sigmoid
    2023-01-12 09:34:41.880785: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Equal
    2023-01-12 09:34:41.880977: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: AssignSubVariableOp
    2023-01-12 09:34:41.881078: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Concat
    2023-01-12 09:34:41.881191: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorListGather
    2023-01-12 09:34:41.881309: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FusedBatchNorm
    2023-01-12 09:34:41.881409: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Assert
    2023-01-12 09:34:41.881607: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TanhGrad
    2023-01-12 09:34:41.881749: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: CheckNumerics
    2023-01-12 09:34:41.881937: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaRemoveDynamicDimensionSize
    2023-01-12 09:34:41.882067: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: LogicalOr
    2023-01-12 09:34:41.882169: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BiasAdd
    2023-01-12 09:34:41.882280: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BiasAddV1
    2023-01-12 09:34:41.882442: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Bucketize
    2023-01-12 09:34:41.882564: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: CollectiveAssignGroupV2
    2023-01-12 09:34:41.882683: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaReduceWindow
    2023-01-12 09:34:41.882865: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: DepthwiseConv2dNativeBackpropInput
    2023-01-12 09:34:41.883008: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FusedBatchNormV2
    2023-01-12 09:34:41.883192: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: DepthwiseConv2dNativeBackpropFilter
    2023-01-12 09:34:41.883293: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: IFFT
    2023-01-12 09:34:41.883567: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: If
    2023-01-12 09:34:41.883805: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatefulStandardNormalV2
    2023-01-12 09:34:41.883970: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: DepthwiseConv2dNative
    2023-01-12 09:34:41.884225: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaEinsum
    2023-01-12 09:34:41.884794: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Ndtri
    2023-01-12 09:34:41.884978: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Rsqrt
    2023-01-12 09:34:41.885215: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: _Arg
    2023-01-12 09:34:41.885476: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FFT
    2023-01-12 09:34:41.885613: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Mod
    2023-01-12 09:34:41.885729: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Atan2
    2023-01-12 09:34:41.885946: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ParallelDynamicStitch
    2023-01-12 09:34:41.886187: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Complex
    2023-01-12 09:34:41.886482: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaDynamicUpdateSlice
    2023-01-12 09:34:41.886572: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Mul
    2023-01-12 09:34:41.886719: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Tan
    2023-01-12 09:34:41.886834: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: DivNoNan
    2023-01-12 09:34:41.886923: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MulNoNan
    2023-01-12 09:34:41.887097: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SeluGrad
    2023-01-12 09:34:41.887217: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: _XlaAotOnlyVarHandleOp
    2023-01-12 09:34:41.887365: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Xlog1py
    2023-01-12 09:34:41.887481: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Diag
    2023-01-12 09:34:41.887596: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Sub
    2023-01-12 09:34:41.887764: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Maximum
    2023-01-12 09:34:41.887939: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: LogicalNot
    2023-01-12 09:34:41.888056: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: DataFormatVecPermute
    2023-01-12 09:34:41.888174: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: DataFormatVecPermute
    2023-01-12 09:34:41.888359: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: LinSpace
    2023-01-12 09:34:41.888681: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Conv2D
    2023-01-12 09:34:41.888925: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BitwiseXor
    2023-01-12 09:34:41.889177: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RightShift
    2023-01-12 09:34:41.889284: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixDiagPart
    2023-01-12 09:34:41.889339: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Conv3D
    2023-01-12 09:34:41.889476: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: EnsureShape
    2023-01-12 09:34:41.889600: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RealDiv
    2023-01-12 09:34:41.889814: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessRandomUniform
    2023-01-12 09:34:41.889925: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: DataFormatDimMap
    2023-01-12 09:34:41.890043: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MirrorPad
    2023-01-12 09:34:41.890145: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FakeQuantWithMinMaxVarsPerChannelGradient
    2023-01-12 09:34:41.890209: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BroadcastArgs
    2023-01-12 09:34:41.890311: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: CollectiveReduceV2
    2023-01-12 09:34:41.890405: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FFT2D
    2023-01-12 09:34:41.890497: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: DiagPart
    2023-01-12 09:34:41.890544: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: IFFT2D
    2023-01-12 09:34:41.890623: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: IFFT3D
    2023-01-12 09:34:41.890758: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorArrayV3
    2023-01-12 09:34:41.890895: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Size
    2023-01-12 09:34:41.891108: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: DenseBincount
    2023-01-12 09:34:41.891222: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RFFT
    2023-01-12 09:34:41.891343: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RFFT2D
    2023-01-12 09:34:41.891421: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaIf
    2023-01-12 09:34:41.891575: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Relu6
    2023-01-12 09:34:41.891823: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RFFT3D
    2023-01-12 09:34:41.892027: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MaxPoolGrad
    2023-01-12 09:34:41.892181: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: IRFFT
    2023-01-12 09:34:41.892309: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: IRFFT2D
    2023-01-12 09:34:41.892392: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessWhile
    2023-01-12 09:34:41.892486: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: IRFFT3D
    2023-01-12 09:34:41.892582: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Erfinv
    2023-01-12 09:34:41.892667: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BroadcastTo
    2023-01-12 09:34:41.892776: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: _ListToArray
    2023-01-12 09:34:41.892913: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Minimum
    2023-01-12 09:34:41.893067: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SymbolicGradient
    2023-01-12 09:34:41.893288: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: _FusedConv2D
    2023-01-12 09:34:41.893418: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RandomStandardNormal
    2023-01-12 09:34:41.893529: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: LowerBound
    2023-01-12 09:34:41.893623: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResizeBilinearGrad
    2023-01-12 09:34:41.893819: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Reverse
    2023-01-12 09:34:41.893929: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyCenteredRMSProp
    2023-01-12 09:34:41.894059: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RngSkip
    2023-01-12 09:34:41.894160: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: GatherNd
    2023-01-12 09:34:41.894269: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaScatter
    2023-01-12 09:34:41.894408: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Identity
    2023-01-12 09:34:41.894842: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RGBToHSV
    2023-01-12 09:34:41.894999: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaSelfAdjointEig
    2023-01-12 09:34:41.895130: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MaxPoolGradV2
    2023-01-12 09:34:41.895314: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: PreventGradient
    2023-01-12 09:34:41.895833: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaReducePrecision
    2023-01-12 09:34:41.895989: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StopGradient
    2023-01-12 09:34:41.896095: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BatchToSpace
    2023-01-12 09:34:41.896178: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: _EagerConst
    2023-01-12 09:34:41.896239: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: AdjustContrastv2
    2023-01-12 09:34:41.896313: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: AdjustSaturation
    2023-01-12 09:34:41.896508: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: AdjustHue
    2023-01-12 09:34:41.896594: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Cosh
    2023-01-12 09:34:41.897068: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: NonMaxSuppressionV3
    2023-01-12 09:34:41.897245: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResizeBilinear
    2023-01-12 09:34:41.897362: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyAdaMax
    2023-01-12 09:34:41.897478: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: InTopKV2
    2023-01-12 09:34:41.897590: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Greater
    2023-01-12 09:34:41.897756: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ArgMax
    2023-01-12 09:34:41.897863: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: EluGrad
    2023-01-12 09:34:41.897955: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: QuantizeAndDequantizeV2
    2023-01-12 09:34:41.898036: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FakeQuantWithMinMaxArgsGradient
    2023-01-12 09:34:41.898161: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ArgMin
    2023-01-12 09:34:41.898364: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: L2Loss
    2023-01-12 09:34:41.898495: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: UnsortedSegmentSum
    2023-01-12 09:34:41.898904: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: AvgPool
    2023-01-12 09:34:41.899032: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ListDiff
    2023-01-12 09:34:41.899149: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaCallModule
    2023-01-12 09:34:41.899254: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ReverseSequence
    2023-01-12 09:34:41.899460: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: UpperBound
    2023-01-12 09:34:41.899785: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ClipByValue
    2023-01-12 09:34:41.900004: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: LRN
    2023-01-12 09:34:41.900211: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Cumsum
    2023-01-12 09:34:41.900371: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: LRNGrad
    2023-01-12 09:34:41.900491: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Round
    2023-01-12 09:34:41.900646: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SparseMatMul
    2023-01-12 09:34:41.900749: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Log
    2023-01-12 09:34:41.900892: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Select
    2023-01-12 09:34:41.900980: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Cholesky
    2023-01-12 09:34:41.901090: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TruncateMod
    2023-01-12 09:34:41.901239: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixDiag
    2023-01-12 09:34:41.901408: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: AssignAddVariableOp
    2023-01-12 09:34:41.901479: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaRngBitGenerator
    2023-01-12 09:34:41.901538: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MaxPool3D
    2023-01-12 09:34:41.901591: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixDiagV3
    2023-01-12 09:34:41.901797: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixDiagPartV2
    2023-01-12 09:34:41.901920: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceScatterMul
    2023-01-12 09:34:41.902086: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixDiagPartV3
    2023-01-12 09:34:41.902264: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixSetDiagV2
    2023-01-12 09:34:41.902730: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixSetDiagV3
    2023-01-12 09:34:41.903001: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorArrayReadV3
    2023-01-12 09:34:41.903224: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ReverseV2
    2023-01-12 09:34:41.903498: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixSolve
    2023-01-12 09:34:41.903686: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Relu
    2023-01-12 09:34:41.903797: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BatchMatMulV2
    2023-01-12 09:34:41.903934: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixTriangularSolve
    2023-01-12 09:34:41.904019: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Multinomial
    2023-01-12 09:34:41.904086: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: UnsortedSegmentMin
    2023-01-12 09:34:41.904156: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MirrorPadGrad
    2023-01-12 09:34:41.904218: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: NoOp
    2023-01-12 09:34:41.904313: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Add
    2023-01-12 09:34:41.904470: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: PartitionedCall
    2023-01-12 09:34:41.904883: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Pack
    2023-01-12 09:34:41.905029: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Pad
    2023-01-12 09:34:41.905245: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaSpmdFullToShardShape
    2023-01-12 09:34:41.905344: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MaxPool
    2023-01-12 09:34:41.905469: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: UniqueV2
    2023-01-12 09:34:41.905575: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessRandomGetKeyCounterAlg
    2023-01-12 09:34:41.905660: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: QuantizeAndDequantizeV4
    2023-01-12 09:34:41.905802: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaSort
    2023-01-12 09:34:41.905960: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Bitcast
    2023-01-12 09:34:41.906080: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MaxPoolV2
    2023-01-12 09:34:41.906192: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaSelectAndScatter
    2023-01-12 09:34:41.906334: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ConcatV2
    2023-01-12 09:34:41.906405: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Snapshot
    2023-01-12 09:34:41.906460: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: AvgPool3D
    2023-01-12 09:34:41.906513: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixInverse
    2023-01-12 09:34:41.906578: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: NotEqual
    2023-01-12 09:34:41.906633: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ParameterizedTruncatedNormal
    2023-01-12 09:34:41.906687: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: AvgPool3DGrad
    2023-01-12 09:34:41.906732: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorArrayCloseV3
    2023-01-12 09:34:41.906776: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MaxPoolGradGradV2
    2023-01-12 09:34:41.906905: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Gather
    2023-01-12 09:34:41.907084: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: UnsortedSegmentMax
    2023-01-12 09:34:41.907206: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: GreaterEqual
    2023-01-12 09:34:41.907311: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Qr
    2023-01-12 09:34:41.907410: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: HSVToRGB
    2023-01-12 09:34:41.907502: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: QuantizeAndDequantizeV3
    2023-01-12 09:34:41.907635: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RandomShuffle
    2023-01-12 09:34:41.907798: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RandomUniformInt
    2023-01-12 09:34:41.907960: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SparseToDense
    2023-01-12 09:34:41.908069: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Mean
    2023-01-12 09:34:41.908181: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TruncateDiv
    2023-01-12 09:34:41.908295: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TruncatedNormal
    2023-01-12 09:34:41.908362: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Max
    2023-01-12 09:34:41.908424: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Roll
    2023-01-12 09:34:41.908494: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Erf
    2023-01-12 09:34:41.908819: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Sum
    2023-01-12 09:34:41.908990: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Prod
    2023-01-12 09:34:41.909094: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: All
    2023-01-12 09:34:41.909204: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: LeakyReluGrad
    2023-01-12 09:34:41.909321: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Dequantize
    2023-01-12 09:34:41.909420: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Any
    2023-01-12 09:34:41.909567: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ReluGrad
    2023-01-12 09:34:41.909674: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatefulUniformInt
    2023-01-12 09:34:41.909831: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Relu6Grad
    2023-01-12 09:34:41.909929: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorArraySizeV3
    2023-01-12 09:34:41.909992: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaReplicaId
    2023-01-12 09:34:41.910074: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: _Retval
    2023-01-12 09:34:41.910176: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Cumprod
    2023-01-12 09:34:41.910308: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceScatterUpdate
    2023-01-12 09:34:41.910593: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorScatterMin
    2023-01-12 09:34:41.910776: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ScatterNd
    2023-01-12 09:34:41.910946: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Acos
    2023-01-12 09:34:41.911104: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorScatterAdd
    2023-01-12 09:34:41.911286: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixBandPart
    2023-01-12 09:34:41.911422: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorScatterSub
    2023-01-12 09:34:41.911586: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Transpose
    2023-01-12 09:34:41.912029: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: UnsortedSegmentProd
    2023-01-12 09:34:41.912661: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1263] Starting fuel: infinity
    2023-01-12 09:34:41.912761: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1268] sorted_nodes.size() = 3
    2023-01-12 09:34:41.915567: I tensorflow/compiler/tf2xla/xla_op_registry.cc:153] tf_xla_cpu_global_jit = 0
    2023-01-12 09:34:41.916862: I tensorflow/compiler/tf2xla/xla_op_registry.cc:51] LaunchOpHasKernelForDevice kernel_class_name: XlaLocalLaunchOp
    2023-01-12 09:34:41.917052: I tensorflow/compiler/tf2xla/xla_op_registry.cc:51] LaunchOpHasKernelForDevice kernel_class_name: XlaLocalLaunchOp
    2023-01-12 09:34:41.917128: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1293] Device type for input: CPU
    2023-01-12 09:34:42.089788: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "NOT_FOUND: No attr named '_XlaCompile' in NodeDef:". *** Begin stack trace ***

            tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
            tsl::Status tsl::errors::NotFound<char const*, std::basic_string_view<char, std::char_traits<char> >, char const*>(char const*, std::basic_string_view<char, std::char_traits<char> >, char const*)
            tensorflow::AttrSlice::CheckFind(std::basic_string_view<char, std::char_traits<char> >, tensorflow::AttrValue const*) const
            tensorflow::AttrSlice::Find(std::basic_string_view<char, std::char_traits<char> >, tensorflow::AttrValue const**) const
            tensorflow::GetNodeAttr(tensorflow::AttrSlice const&, std::basic_string_view<char, std::char_traits<char> >, bool*)





            tensorflow::MarkForCompilationPass::Run(tensorflow::GraphOptimizationPassOptions const&)
            tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
            tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
            tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
            tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


            tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
            tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
            tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
            TFE_Execute
            tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
            tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
            tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
            EagerTensor_init
            _PyObject_MakeTpCall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            PyObject_Call
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault


            PyEval_EvalCode



            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            PyEval_EvalCode


            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall

            Py_RunMain
            Py_BytesMain

            __libc_start_main
            _start
    *** End stack trace ***

    2023-01-12 09:34:42.216470: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: Attr _XlaCompile is not defined.". *** Begin stack trace ***

            tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
            tsl::Status tsl::errors::InvalidArgument<char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*>(char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*)
            tsl::Status tensorflow::FunctionLibraryDefinition::GetAttr<bool>(tensorflow::NodeDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool*) const
            tsl::Status tensorflow::FunctionLibraryDefinition::GetAttr<bool>(tensorflow::Node const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool*) const





            tensorflow::MarkForCompilationPass::Run(tensorflow::GraphOptimizationPassOptions const&)
            tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
            tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
            tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
            tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


            tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
            tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
            tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
            TFE_Execute
            tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
            tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
            tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
            EagerTensor_init
            _PyObject_MakeTpCall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            PyObject_Call
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault


            PyEval_EvalCode



            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            PyEval_EvalCode


            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall

            Py_RunMain
            Py_BytesMain

            __libc_start_main
            _start
    *** End stack trace ***

    2023-01-12 09:34:42.217027: I tensorflow/compiler/jit/compilability_check_util.cc:74] Found uncompilable node input (op _Arg): top level _Arg or _Retval
    2023-01-12 09:34:42.217119: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1293] Device type for _EagerConst: CPU
    2023-01-12 09:34:42.382433: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "NOT_FOUND: No attr named '_XlaCompile' in NodeDef:". *** Begin stack trace ***

            tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
            tsl::Status tsl::errors::NotFound<char const*, std::basic_string_view<char, std::char_traits<char> >, char const*>(char const*, std::basic_string_view<char, std::char_traits<char> >, char const*)
            tensorflow::AttrSlice::CheckFind(std::basic_string_view<char, std::char_traits<char> >, tensorflow::AttrValue const*) const
            tensorflow::AttrSlice::Find(std::basic_string_view<char, std::char_traits<char> >, tensorflow::AttrValue const**) const
            tensorflow::GetNodeAttr(tensorflow::AttrSlice const&, std::basic_string_view<char, std::char_traits<char> >, bool*)





            tensorflow::MarkForCompilationPass::Run(tensorflow::GraphOptimizationPassOptions const&)
            tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
            tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
            tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
            tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


            tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
            tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
            tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
            TFE_Execute
            tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
            tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
            tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
            EagerTensor_init
            _PyObject_MakeTpCall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            PyObject_Call
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault


            PyEval_EvalCode



            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            PyEval_EvalCode


            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall

            Py_RunMain
            Py_BytesMain

            __libc_start_main
            _start
    *** End stack trace ***

    2023-01-12 09:34:42.507831: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: Attr _XlaCompile is not defined.". *** Begin stack trace ***

            tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
            tsl::Status tsl::errors::InvalidArgument<char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*>(char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*)
            tsl::Status tensorflow::FunctionLibraryDefinition::GetAttr<bool>(tensorflow::NodeDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool*) const
            tsl::Status tensorflow::FunctionLibraryDefinition::GetAttr<bool>(tensorflow::Node const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool*) const





            tensorflow::MarkForCompilationPass::Run(tensorflow::GraphOptimizationPassOptions const&)
            tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
            tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
            tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
            tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


            tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
            tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
            tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
            TFE_Execute
            tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
            tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
            tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
            EagerTensor_init
            _PyObject_MakeTpCall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            PyObject_Call
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault


            PyEval_EvalCode



            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            PyEval_EvalCode


            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall

            Py_RunMain
            Py_BytesMain

            __libc_start_main
            _start
    *** End stack trace ***

    2023-01-12 09:34:42.508709: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1293] Device type for output_RetVal: CPU
    2023-01-12 09:34:42.634693: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "NOT_FOUND: No attr named '_XlaCompile' in NodeDef:". *** Begin stack trace ***

            tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
            tsl::Status tsl::errors::NotFound<char const*, std::basic_string_view<char, std::char_traits<char> >, char const*>(char const*, std::basic_string_view<char, std::char_traits<char> >, char const*)
            tensorflow::AttrSlice::CheckFind(std::basic_string_view<char, std::char_traits<char> >, tensorflow::AttrValue const*) const
            tensorflow::AttrSlice::Find(std::basic_string_view<char, std::char_traits<char> >, tensorflow::AttrValue const**) const
            tensorflow::GetNodeAttr(tensorflow::AttrSlice const&, std::basic_string_view<char, std::char_traits<char> >, bool*)





            tensorflow::MarkForCompilationPass::Run(tensorflow::GraphOptimizationPassOptions const&)
            tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
            tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
            tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
            tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


            tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
            tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
            tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
            TFE_Execute
            tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
            tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
            tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
            EagerTensor_init
            _PyObject_MakeTpCall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            PyObject_Call
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault


            PyEval_EvalCode



            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            PyEval_EvalCode


            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall

            Py_RunMain
            Py_BytesMain

            __libc_start_main
            _start
    *** End stack trace ***

    2023-01-12 09:34:42.758359: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: Attr _XlaCompile is not defined.". *** Begin stack trace ***

            tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
            tsl::Status tsl::errors::InvalidArgument<char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*>(char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*)
            tsl::Status tensorflow::FunctionLibraryDefinition::GetAttr<bool>(tensorflow::NodeDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool*) const
            tsl::Status tensorflow::FunctionLibraryDefinition::GetAttr<bool>(tensorflow::Node const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool*) const





            tensorflow::MarkForCompilationPass::Run(tensorflow::GraphOptimizationPassOptions const&)
            tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
            tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
            tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
            tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


            tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
            tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
            tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
            TFE_Execute
            tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
            tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
            tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
            EagerTensor_init
            _PyObject_MakeTpCall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            PyObject_Call
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault


            PyEval_EvalCode



            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            PyEval_EvalCode


            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall

            Py_RunMain
            Py_BytesMain

            __libc_start_main
            _start
    *** End stack trace ***

    2023-01-12 09:34:42.758891: I tensorflow/compiler/jit/compilability_check_util.cc:74] Found uncompilable node output_RetVal (op _Retval): top level _Arg or _Retval
    2023-01-12 09:34:42.758965: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1437] compilation_candidates_.size() = 1
    2023-01-12 09:34:42.761012: I tensorflow/compiler/jit/deadness_analysis.cc:1285] Visiting _SOURCE
    2023-01-12 09:34:42.761099: I tensorflow/compiler/jit/deadness_analysis.cc:1285] Visiting input
    2023-01-12 09:34:42.761125: I tensorflow/compiler/jit/deadness_analysis.cc:1285] Visiting _EagerConst
    2023-01-12 09:34:42.761141: I tensorflow/compiler/jit/deadness_analysis.cc:1285] Visiting output_RetVal
    2023-01-12 09:34:42.761169: I tensorflow/compiler/jit/deadness_analysis.cc:1444] Visiting _SOURCE
    2023-01-12 09:34:42.761466: I tensorflow/compiler/jit/deadness_analysis.cc:1444] Visiting input
    2023-01-12 09:34:42.761547: I tensorflow/compiler/jit/deadness_analysis.cc:1444] Visiting _EagerConst
    2023-01-12 09:34:42.761635: I tensorflow/compiler/jit/deadness_analysis.cc:1444] Visiting output_RetVal
    2023-01-12 09:34:42.761674: I tensorflow/compiler/jit/deadness_analysis.cc:1413] Done populating frame  using the pessimistic mode.
    2023-01-12 09:34:42.761721: I tensorflow/compiler/jit/deadness_analysis.cc:1561] ^_EagerConst -> #true
    2023-01-12 09:34:42.761747: I tensorflow/compiler/jit/deadness_analysis.cc:1561] _EagerConst:0 -> #true
    2023-01-12 09:34:42.761773: I tensorflow/compiler/jit/deadness_analysis.cc:1561] ^_SOURCE -> #true
    2023-01-12 09:34:42.761801: I tensorflow/compiler/jit/deadness_analysis.cc:1561] ^input -> #true
    2023-01-12 09:34:42.761826: I tensorflow/compiler/jit/deadness_analysis.cc:1561] input:0 -> #true
    2023-01-12 09:34:42.761855: I tensorflow/compiler/jit/deadness_analysis.cc:1561] ^output_RetVal -> #true
    2023-01-12 09:34:42.762241: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:650] DeadnessAnalysis time: 2.68 ms (cumulative: 2.68 ms, max: 2.68 ms, #called: 1)
    2023-01-12 09:34:42.762526: I tensorflow/compiler/jit/resource_operation_safety_analysis.cc:310] _SOURCE -> {}
    2023-01-12 09:34:42.762592: I tensorflow/compiler/jit/resource_operation_safety_analysis.cc:310] input -> {}
    2023-01-12 09:34:42.762628: I tensorflow/compiler/jit/resource_operation_safety_analysis.cc:310] _EagerConst -> {}
    2023-01-12 09:34:42.762720: I tensorflow/compiler/jit/resource_operation_safety_analysis.cc:310] output_RetVal -> {}
    2023-01-12 09:34:42.762745: I tensorflow/compiler/jit/resource_operation_safety_analysis.cc:310] _SINK -> {}
    2023-01-12 09:34:42.886102: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: Attr _XlaCompile is not defined.". *** Begin stack trace ***

            tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
            tsl::Status tsl::errors::InvalidArgument<char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*>(char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*)
            tsl::Status tensorflow::FunctionLibraryDefinition::GetAttr<bool>(tensorflow::NodeDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool*) const
            tsl::Status tensorflow::FunctionLibraryDefinition::GetAttr<bool>(tensorflow::Node const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool*) const





            tensorflow::MarkForCompilationPass::Run(tensorflow::GraphOptimizationPassOptions const&)
            tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
            tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
            tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
            tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


            tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
            tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
            tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
            TFE_Execute
            tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
            tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
            tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
            EagerTensor_init
            _PyObject_MakeTpCall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            PyObject_Call
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault


            PyEval_EvalCode



            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            PyEval_EvalCode


            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall

            Py_RunMain
            Py_BytesMain

            __libc_start_main
            _start
    *** End stack trace ***

    2023-01-12 09:34:42.886690: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:775] Running phase 0
    2023-01-12 09:34:42.886822: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:798] Running phase 1
    2023-01-12 09:34:42.886891: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:854] Running phase 2
    2023-01-12 09:34:42.886914: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:863] Checking idempotence
    2023-01-12 09:34:42.886985: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1801] Not compiling cluster with device /job:localhost/replica:0/task:0/device:CPU:0
    2023-01-12 09:34:42.887290: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1610] *** Clustering info for graph of size 5
    2023-01-12 09:34:42.888873: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1611]  Built 0 clusters, size 0 / 5 (0.00%)
    2023-01-12 09:34:42.888978: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1630]  Unclustered nodes: 5 / 5 (100.00%)
    2023-01-12 09:34:42.889018: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1635]   NoOp: 2 instances
    2023-01-12 09:34:42.889042: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1635]   _Arg: 1 instances
    2023-01-12 09:34:42.889066: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1635]   _EagerConst: 1 instances
    2023-01-12 09:34:42.889084: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1635]   _Retval: 1 instances
    2023-01-12 09:34:42.889117: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1690] *** Inter-Cluster edges:
    2023-01-12 09:34:42.889129: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1692]    [none]
    2023-01-12 09:34:42.889194: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1554] MarkForCompilationPassImpl::Run time: 977 ms (cumulative: 977 ms, max: 977 ms, #called: 1)
    2023-01-12 09:34:42.889449: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_2_phase_10_MarkForCompilationPass_94667551040240 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
    2023-01-12 09:34:42.985109: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

            tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
            tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


            tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
            tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)

            tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
            tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
            tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
            tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


            tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
            tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
            tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
            TFE_Execute
            tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
            tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
            tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
            EagerTensor_init
            _PyObject_MakeTpCall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            PyObject_Call
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault


            PyEval_EvalCode



            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            PyEval_EvalCode


            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall

            Py_RunMain
            Py_BytesMain

            __libc_start_main
            _start
    *** End stack trace ***

    2023-01-12 09:34:42.985663: I tensorflow/core/common_runtime/optimization_registry.cc:66] Running optimization phase 12
    2023-01-12 09:34:42.985710: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: ForceXlaConstantsOnHostPass
    2023-01-12 09:34:42.986009: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_2_phase_12_ForceXlaConstantsOnHostPass_94667551040240 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
    2023-01-12 09:34:43.076143: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

            tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
            tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


            tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
            tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)

            tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
            tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
            tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
            tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


            tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
            tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
            tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
            TFE_Execute
            tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
            tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
            tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
            EagerTensor_init
            _PyObject_MakeTpCall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            PyObject_Call
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault


            PyEval_EvalCode



            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            PyEval_EvalCode


            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall

            Py_RunMain
            Py_BytesMain

            __libc_start_main
            _start
    *** End stack trace ***

    2023-01-12 09:34:43.076671: I tensorflow/core/common_runtime/optimization_registry.cc:66] Running optimization phase 20
    2023-01-12 09:34:43.076703: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: IncreaseDynamismForAutoJitPass
    2023-01-12 09:34:43.076908: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_2_phase_20_IncreaseDynamismForAutoJitPass_94667551040240 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
    2023-01-12 09:34:43.168927: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

            tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
            tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


            tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
            tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)

            tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
            tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
            tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
            tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


            tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
            tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
            tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
            TFE_Execute
            tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
            tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
            tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
            EagerTensor_init
            _PyObject_MakeTpCall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            PyObject_Call
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault


            PyEval_EvalCode



            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            PyEval_EvalCode


            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall

            Py_RunMain
            Py_BytesMain

            __libc_start_main
            _start
    *** End stack trace ***

    2023-01-12 09:34:43.169556: I tensorflow/core/common_runtime/optimization_registry.cc:66] Running optimization phase 30
    2023-01-12 09:34:43.169695: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: PartiallyDeclusterPass
    2023-01-12 09:34:43.170164: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_2_phase_30_PartiallyDeclusterPass_94667551040240 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
    2023-01-12 09:34:43.263055: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

            tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
            tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


            tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
            tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)

            tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
            tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
            tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
            tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


            tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
            tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
            tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
            TFE_Execute
            tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
            tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
            tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
            EagerTensor_init
            _PyObject_MakeTpCall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            PyObject_Call
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault


            PyEval_EvalCode



            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            PyEval_EvalCode


            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall

            Py_RunMain
            Py_BytesMain

            __libc_start_main
            _start
    *** End stack trace ***

    2023-01-12 09:34:43.263568: I tensorflow/core/common_runtime/optimization_registry.cc:66] Running optimization phase 40
    2023-01-12 09:34:43.263683: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: ReportClusteringInfoPass
    2023-01-12 09:34:43.263819: I tensorflow/compiler/jit/xla_cluster_util.cc:297] GetGlobalJitLevelForGraph returning -1
    2023-01-12 09:34:43.264233: I tensorflow/compiler/jit/xla_activity_logging_listener.cc:39] Not logging: logger not ready yet.
    2023-01-12 09:34:43.264489: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_2_phase_40_ReportClusteringInfoPass_94667551040240 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
    2023-01-12 09:34:43.360136: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

            tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
            tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


            tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
            tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)

            tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
            tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
            tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
            tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


            tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
            tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
            tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
            TFE_Execute
            tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
            tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
            tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
            EagerTensor_init
            _PyObject_MakeTpCall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            PyObject_Call
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault


            PyEval_EvalCode



            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            PyEval_EvalCode


            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall

            Py_RunMain
            Py_BytesMain

            __libc_start_main
            _start
    *** End stack trace ***

    2023-01-12 09:34:43.360674: I tensorflow/core/common_runtime/optimization_registry.cc:66] Running optimization phase 50
    2023-01-12 09:34:43.360754: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: EncapsulateSubgraphsPass
    2023-01-12 09:34:43.361840: I tensorflow/compiler/jit/encapsulate_subgraphs_pass.cc:1139] EncapsulateSubgraphsPass::Run
    2023-01-12 09:34:43.362054: W tensorflow/core/util/dump_graph.cc:134] Failed to dump encapsulate_subgraphs_before because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
    2023-01-12 09:34:43.458351: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

            tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
            tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


            tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
            tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
            tensorflow::EncapsulateSubgraphsPass::Run(tensorflow::GraphOptimizationPassOptions const&)
            tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
            tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
            tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
            tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


            tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
            tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
            tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
            TFE_Execute
            tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
            tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
            tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
            EagerTensor_init
            _PyObject_MakeTpCall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            PyObject_Call
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault


            PyEval_EvalCode



            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            PyEval_EvalCode


            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall

            Py_RunMain
            Py_BytesMain

            __libc_start_main
            _start
    *** End stack trace ***

    2023-01-12 09:34:43.459715: I tensorflow/core/graph/graph.cc:529] AddNode: no type constructor for _SOURCE
    2023-01-12 09:34:43.459827: I tensorflow/core/graph/graph.cc:529] AddNode: no type constructor for _SINK
    2023-01-12 09:34:43.460039: W tensorflow/core/util/dump_graph.cc:134] Failed to dump encapsulate_subgraphs_after because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
    2023-01-12 09:34:43.558743: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

            tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
            tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


            tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
            tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
            tensorflow::EncapsulateSubgraphsPass::Run(tensorflow::GraphOptimizationPassOptions const&)
            tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
            tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
            tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
            tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


            tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
            tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
            tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
            TFE_Execute
            tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
            tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
            tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
            EagerTensor_init
            _PyObject_MakeTpCall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            PyObject_Call
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault


            PyEval_EvalCode



            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            PyEval_EvalCode


            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall

            Py_RunMain
            Py_BytesMain

            __libc_start_main
            _start
    *** End stack trace ***

    2023-01-12 09:34:43.560908: I tensorflow/compiler/jit/xla_cluster_util.cc:558] # iterations = 1
    2023-01-12 09:34:43.561026: I tensorflow/compiler/jit/xla_cluster_util.cc:558] # iterations = 1
    2023-01-12 09:34:43.561050: I tensorflow/compiler/jit/xla_cluster_util.cc:590] GetNodesRelatedToRefVariables() found 0 nodes
    2023-01-12 09:34:43.561345: I tensorflow/compiler/jit/encapsulate_subgraphs_pass.cc:1307] Has ref vars = 0, node: name: "_SOURCE"
    op: "NoOp"
    attr {
      key: "_XlaHasReferenceVars"
      value {
        b: false
      }
    }

    2023-01-12 09:34:43.561594: I tensorflow/compiler/jit/encapsulate_subgraphs_pass.cc:1307] Has ref vars = 0, node: name: "_SINK"
    op: "NoOp"
    attr {
      key: "_XlaHasReferenceVars"
      value {
        b: false
      }
    }

    2023-01-12 09:34:43.561850: I tensorflow/compiler/jit/encapsulate_subgraphs_pass.cc:1307] Has ref vars = 0, node: name: "input"
    op: "_Arg"
    attr {
      key: "T"
      value {
        type: DT_DOUBLE
      }
    }
    attr {
      key: "_XlaHasReferenceVars"
      value {
        b: false
      }
    }
    attr {
      key: "index"
      value {
        i: 0
      }
    }

    2023-01-12 09:34:43.562367: I tensorflow/compiler/jit/encapsulate_subgraphs_pass.cc:1307] Has ref vars = 0, node: name: "_EagerConst"
    op: "_EagerConst"
    input: "input"
    device: "/job:localhost/replica:0/task:0/device:CPU:0"
    attr {
      key: "T"
      value {
        type: DT_DOUBLE
      }
    }
    attr {
      key: "_XlaHasReferenceVars"
      value {
        b: false
      }
    }

    2023-01-12 09:34:43.562728: I tensorflow/compiler/jit/encapsulate_subgraphs_pass.cc:1307] Has ref vars = 0, node: name: "output_RetVal"
    op: "_Retval"
    input: "_EagerConst"
    attr {
      key: "T"
      value {
        type: DT_DOUBLE
      }
    }
    attr {
      key: "_XlaHasReferenceVars"
      value {
        b: false
      }
    }
    attr {
      key: "index"
      value {
        i: 0
      }
    }

    2023-01-12 09:34:43.563151: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_2_phase_50_EncapsulateSubgraphsPass_94667550137232 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
    2023-01-12 09:34:43.661808: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

            tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
            tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


            tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
            tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)

            tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
            tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
            tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
            tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


            tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
            tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
            tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
            TFE_Execute
            tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
            tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
            tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
            EagerTensor_init
            _PyObject_MakeTpCall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            PyObject_Call
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault


            PyEval_EvalCode



            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            PyEval_EvalCode


            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall

            Py_RunMain
            Py_BytesMain

            __libc_start_main
            _start
    *** End stack trace ***

    2023-01-12 09:34:43.662375: I tensorflow/core/common_runtime/optimization_registry.cc:66] Running optimization phase 60
    2023-01-12 09:34:43.662406: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: BuildXlaOpsPass
    2023-01-12 09:34:43.662597: I tensorflow/compiler/jit/build_xla_ops_pass.cc:603] print_outputs = 0
    2023-01-12 09:34:43.662653: I tensorflow/compiler/jit/build_xla_ops_pass.cc:604] check_input_numerics = 0
    2023-01-12 09:34:43.662669: I tensorflow/compiler/jit/build_xla_ops_pass.cc:605] check_output_numerics = 0
    2023-01-12 09:34:43.662811: W tensorflow/core/util/dump_graph.cc:134] Failed to dump build_xla_ops because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
    2023-01-12 09:34:43.761854: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

            tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
            tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


            tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
            tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
            tensorflow::BuildXlaOpsPass::Run(tensorflow::GraphOptimizationPassOptions const&)
            tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
            tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
            tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
            tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


            tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
            tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
            tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
            TFE_Execute
            tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
            tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
            tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
            EagerTensor_init
            _PyObject_MakeTpCall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            PyObject_Call
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault


            PyEval_EvalCode



            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            PyEval_EvalCode


            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall

            Py_RunMain
            Py_BytesMain

            __libc_start_main
            _start
    *** End stack trace ***

    2023-01-12 09:34:43.762579: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_2_phase_60_BuildXlaOpsPass_94667550137232 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
    2023-01-12 09:34:43.862180: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

            tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
            tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


            tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
            tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)

            tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
            tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
            tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
            tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


            tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
            tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
            tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
            TFE_Execute
            tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
            tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
            tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
            EagerTensor_init
            _PyObject_MakeTpCall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            PyObject_Call
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault


            PyEval_EvalCode



            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault

            _PyFunction_Vectorcall

            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault

            PyEval_EvalCode


            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall
            _PyEval_EvalFrameDefault
            _PyFunction_Vectorcall

            Py_RunMain
            Py_BytesMain

            __libc_start_main
            _start
    *** End stack trace ***

  2023-01-12 09:34:43.862749: I tensorflow/core/common_runtime/optimization_registry.cc:87] Finished optimization of a group 2
  2023-01-12 09:34:43.862944: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_grouping_2_94667550137232 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
  2023-01-12 09:34:43.955670: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

          tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
          tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


          tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
          tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)

          tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
          tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
          tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
          tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
          tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
          tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


          tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
          tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
          tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
          TFE_Execute
          tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
          tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
          tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
          EagerTensor_init
  *** End stack trace ***

  2023-01-12 09:34:43.956294: I tensorflow/core/common_runtime/replicate_per_replica_nodes.cc:277] No nodes with composiste device found.
  2023-01-12 09:34:43.956366: I tensorflow/core/common_runtime/process_function_library_runtime.cc:993] Main function graph to be partitioned:
  2023-01-12 09:34:43.956634: I tensorflow/core/common_runtime/process_function_library_runtime.cc:994] 
  (input:double@CPU:0) -> (_EagerConst:double@CPU:0) {
    _EagerConst = _EagerConst[T=double, _XlaHasReferenceVars=false, device=CPU:0](input)
  }

  2023-01-12 09:34:43.958675: I tensorflow/core/graph/graph_partition.cc:1251] Added send/recv: controls=0, data=0
  2023-01-12 09:34:43.958764: W tensorflow/core/util/dump_graph.cc:134] Failed to dump partition_/job:localhost/replica:0/task:0/device:CPU:0_94667554837512 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
  2023-01-12 09:34:44.060078: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

          tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
          tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


          tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
          tensorflow::Partition(tensorflow::PartitionOptions const&, tensorflow::Graph*, std::unordered_map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tensorflow::GraphDef, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, tensorflow::GraphDef> > >*)

          tensorflow::PartitionFunctionGraph(tensorflow::DeviceSet const&, std::unique_ptr<tensorflow::Graph, std::default_delete<tensorflow::Graph> >, std::unordered_map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::unique_ptr<tensorflow::Graph, std::default_delete<tensorflow::Graph> >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::unique_ptr<tensorflow::Graph, std::default_delete<tensorflow::Graph> > > > >*, std::function<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > (tensorflow::Edge const*)>)
          tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
          tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
          tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
          tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


          tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
          tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
          tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
          TFE_Execute
          tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
          tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
          tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
          EagerTensor_init
  *** End stack trace ***

  2023-01-12 09:34:44.060703: I tensorflow/core/graph/graph.cc:529] AddNode: no type constructor for _SOURCE
  2023-01-12 09:34:44.060900: I tensorflow/core/graph/graph.cc:529] AddNode: no type constructor for _SINK
  2023-01-12 09:34:44.061457: I tensorflow/core/graph/graph.cc:529] AddNode: no type constructor for input
  2023-01-12 09:34:44.061711: I tensorflow/core/graph/graph.cc:529] AddNode: no type constructor for _EagerConst
  2023-01-12 09:34:44.061880: I tensorflow/core/graph/graph.cc:529] AddNode: no type constructor for output_RetVal
  2023-01-12 09:34:44.062120: I tensorflow/core/common_runtime/function_utils.cc:78] Graph Before running POST_PARTITIONING passes (/job:localhost/replica:0/task:0/device:CPU:0) #nodes 5 #edges 5
  2023-01-12 09:34:44.062316: I tensorflow/core/common_runtime/function_utils.cc:82] || 
  2023-01-12 09:34:44.062369: I tensorflow/core/common_runtime/function_utils.cc:82] || (n2:double@CPU:0) -> (n3:double@CPU:0) {
  2023-01-12 09:34:44.062385: I tensorflow/core/common_runtime/function_utils.cc:82] ||   n3 = _EagerConst[T=double, _XlaHasReferenceVars=false, device=CPU:0](n2)
  2023-01-12 09:34:44.062396: I tensorflow/core/common_runtime/function_utils.cc:82] || }
  2023-01-12 09:34:44.062406: I tensorflow/core/common_runtime/function_utils.cc:82] || 
  2023-01-12 09:34:44.062422: I tensorflow/core/common_runtime/optimization_registry.cc:54] Starting optimization of a group 3
    2023-01-12 09:34:44.062574: W tensorflow/core/util/dump_graph.cc:134] Failed to dump before_grouping_3_partition_/job:localhost/replica:0/task:0/device:CPU:0_94667551040240 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
    2023-01-12 09:34:44.169968: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

            tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
            tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


            tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
            tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)

            tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
            tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
            tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


            tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
            tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
            tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
            TFE_Execute
            tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
            tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
            tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
            EagerTensor_init
    *** End stack trace ***

    2023-01-12 09:34:44.170667: I tensorflow/core/common_runtime/optimization_registry.cc:66] Running optimization phase 1
    2023-01-12 09:34:44.170759: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: MklLayoutRewritePass
    2023-01-12 09:34:44.170802: I tensorflow/core/common_runtime/mkl_layout_pass.cc:4198] TF-MKL: MKL is not enabled
    2023-01-12 09:34:44.170987: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_3_phase_1_MklLayoutRewritePass_partition_/job:localhost/replica:0/task:0/device:CPU:0_94667551040240 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
    2023-01-12 09:34:44.267202: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

            tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
            tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


            tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
            tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)

            tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
            tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
            tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


            tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
            tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
            tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
            TFE_Execute
            tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
            tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
            tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
            EagerTensor_init
    *** End stack trace ***

  2023-01-12 09:34:44.267829: I tensorflow/core/common_runtime/optimization_registry.cc:87] Finished optimization of a group 3
  2023-01-12 09:34:44.268014: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_grouping_3_partition_/job:localhost/replica:0/task:0/device:CPU:0_94667551040240 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
  2023-01-12 09:34:44.362372: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

          tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
          tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


          tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
          tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)

          tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
          tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
          tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
          tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
          tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


          tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
          tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
          tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
          TFE_Execute
          tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
          tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
          tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
          EagerTensor_init
  *** End stack trace ***

  2023-01-12 09:34:44.362956: I tensorflow/core/common_runtime/function_utils.cc:78] Graph After all optimization passes (/job:localhost/replica:0/task:0/device:CPU:0) #nodes 5 #edges 5
  2023-01-12 09:34:44.363246: I tensorflow/core/common_runtime/function_utils.cc:82] || 
  2023-01-12 09:34:44.363296: I tensorflow/core/common_runtime/function_utils.cc:82] || (n2:double@CPU:0) -> (n3:double@CPU:0) {
  2023-01-12 09:34:44.363311: I tensorflow/core/common_runtime/function_utils.cc:82] ||   n3 = _EagerConst[T=double, _XlaHasReferenceVars=false, device=CPU:0](n2)
  2023-01-12 09:34:44.363321: I tensorflow/core/common_runtime/function_utils.cc:82] || }
  2023-01-12 09:34:44.363330: I tensorflow/core/common_runtime/function_utils.cc:82] || 
  2023-01-12 09:34:44.363422: W tensorflow/core/util/dump_graph.cc:134] Failed to dump pflr_after_all_optimization_passes_94667551040240_/job:localhost/replica:0/task:0/device:CPU:0 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
  2023-01-12 09:34:44.448112: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

          tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
          tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


          tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
          tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
          tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
          tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
          tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


          tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
          tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
          tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
          TFE_Execute
          tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
          tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
          tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
          EagerTensor_init
  *** End stack trace ***

  2023-01-12 09:34:44.564328: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "NOT_FOUND: No attr named 'sub_index' in NodeDef:". *** Begin stack trace ***

          tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
          tsl::Status tsl::errors::NotFound<char const*, std::basic_string_view<char, std::char_traits<char> >, char const*>(char const*, std::basic_string_view<char, std::char_traits<char> >, char const*)
          tensorflow::AttrSlice::CheckFind(std::basic_string_view<char, std::char_traits<char> >, tensorflow::AttrValue const*) const
          tensorflow::AttrSlice::Find(std::basic_string_view<char, std::char_traits<char> >, tensorflow::AttrValue const**) const
          tensorflow::UpdateArgAndRetvalMetadata(tensorflow::Graph*, std::vector<tensorflow::FunctionArgIndex, std::allocator<tensorflow::FunctionArgIndex> >*, std::vector<int, std::allocator<int> >*, std::vector<tsl::AllocatorAttributes, std::allocator<tsl::AllocatorAttributes> >*, std::vector<tsl::AllocatorAttributes, std::allocator<tsl::AllocatorAttributes> >*, bool)




          std::function<void ()>::operator()() const

          tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
          tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
          tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
          tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


          tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
          tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
          tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
          TFE_Execute
          tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
          tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
          tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
          EagerTensor_init
  *** End stack trace ***

  2023-01-12 09:34:44.667247: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "NOT_FOUND: No attr named 'sub_index' in NodeDef:
          [[{{node input}}]]". *** Begin stack trace ***

          tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
          void tsl::errors::AppendToMessage<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >(tsl::Status*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)
          tensorflow::AttachDef(tsl::Status const&, tensorflow::NodeDef const&, bool)
          tensorflow::AttrSlice::CheckFind(std::basic_string_view<char, std::char_traits<char> >, tensorflow::AttrValue const*) const
          tensorflow::AttrSlice::Find(std::basic_string_view<char, std::char_traits<char> >, tensorflow::AttrValue const**) const
          tensorflow::UpdateArgAndRetvalMetadata(tensorflow::Graph*, std::vector<tensorflow::FunctionArgIndex, std::allocator<tensorflow::FunctionArgIndex> >*, std::vector<int, std::allocator<int> >*, std::vector<tsl::AllocatorAttributes, std::allocator<tsl::AllocatorAttributes> >*, std::vector<tsl::AllocatorAttributes, std::allocator<tsl::AllocatorAttributes> >*, bool)




          std::function<void ()>::operator()() const

          tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
          tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
          tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
          tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


          tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
          tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
          tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
          TFE_Execute
          tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
          tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
          tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
          EagerTensor_init
  *** End stack trace ***

  2023-01-12 09:34:44.767717: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "NOT_FOUND: Op type not registered '__wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0_4619141710927497548_0' in binary running on docker-desktop. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.". *** Begin stack trace ***

          tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
          tsl::Status tsl::errors::NotFound<char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*, char const*>(char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*, char const*)

          tensorflow::OpRegistry::LookUp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::OpRegistrationData const**) const
          tensorflow::OpRegistryInterface::LookUpOpDef(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::OpDef const**) const
          tensorflow::FunctionLibraryDefinition::AddFunctionDefHelper(tensorflow::FunctionDef const&, std::unordered_map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::shared_ptr<tensorflow::AbstractStackTrace>, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::shared_ptr<tensorflow::AbstractStackTrace> > > > const&, bool*)
          tensorflow::FunctionLibraryDefinition::AddFunctionDef(tensorflow::FunctionDef const&, std::unordered_map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::shared_ptr<tensorflow::AbstractStackTrace>, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::shared_ptr<tensorflow::AbstractStackTrace> > > > const&)




          std::function<void ()>::operator()() const

          tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
          tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
          tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
          tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)


          tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
          tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
          tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
          TFE_Execute
          tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
          tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
          tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
          EagerTensor_init
  *** End stack trace ***

  2023-01-12 09:34:44.768183: I tensorflow/core/framework/op.cc:80] NOT_FOUND: Op type not registered '__wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0_4619141710927497548_0' in binary running on docker-desktop. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.
  2023-01-12 09:34:44.768387: I tensorflow/core/common_runtime/process_function_library_runtime.cc:1150] Start instantiating component function __wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0_4619141710927497548_0 on device /job:localhost/replica:0/task:0/device:CPU:0
    2023-01-12 09:34:44.768549: I tensorflow/core/common_runtime/process_function_library_runtime.cc:1152] 
    __wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0_4619141710927497548_0(input:double) -> (output_retval:double) {
      _EagerConst = _EagerConst[T=double, _XlaHasReferenceVars=false, device=CPU:0](input)
      return output_retval = _EagerConst:output:0
    }

    2023-01-12 09:34:44.768690: I tensorflow/core/framework/function.cc:742] Instantiate function definition: name=__wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0_4619141710927497548_0 #input_args=1 #output_args=1 #control_output=0
    2023-01-12 09:34:44.768784: I tensorflow/core/framework/function.cc:747] || 
    2023-01-12 09:34:44.768813: I tensorflow/core/framework/function.cc:747] || __wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0_4619141710927497548_0(input:double) -> (output_retval:double) {
    2023-01-12 09:34:44.768825: I tensorflow/core/framework/function.cc:747] ||   _EagerConst = _EagerConst[T=double, _XlaHasReferenceVars=false, device=CPU:0](input)
    2023-01-12 09:34:44.768835: I tensorflow/core/framework/function.cc:747] ||   return output_retval = _EagerConst:output:0
    2023-01-12 09:34:44.768845: I tensorflow/core/framework/function.cc:747] || }
    2023-01-12 09:34:44.768854: I tensorflow/core/framework/function.cc:747] || 
    2023-01-12 09:34:44.769110: I tensorflow/core/graph/graph.cc:529] AddNode: no type constructor for _SOURCE
    2023-01-12 09:34:44.769221: I tensorflow/core/graph/graph.cc:529] AddNode: no type constructor for _SINK
    2023-01-12 09:34:44.769469: I tensorflow/core/graph/graph.cc:529] AddNode: no type constructor for input
    2023-01-12 09:34:44.769605: I tensorflow/core/graph/graph.cc:529] AddNode: no type constructor for _EagerConst
    2023-01-12 09:34:44.769756: I tensorflow/core/graph/graph.cc:529] AddNode: no type constructor for output_retval_RetVal
  2023-01-12 09:34:44.770186: I tensorflow/core/common_runtime/process_function_library_runtime.cc:1159] Finished instantiating component function __wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0_4619141710927497548_0 with handle 0 status: OK
2023-01-12 09:34:44.770327: I tensorflow/core/common_runtime/process_function_library_runtime.cc:1195] Instantiated MultiDevice function "__wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0" with handle 1
2023-01-12 09:34:44.770612: I tensorflow/core/common_runtime/eager/execute.cc:245] !is_function: 0
2023-01-12 09:34:44.770638: I tensorflow/core/common_runtime/eager/execute.cc:246] handle->Type(): 0
2023-01-12 09:34:44.770666: I tensorflow/core/common_runtime/eager/execute.cc:1445] Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0
2023-01-12 09:34:44.770769: I tensorflow/core/common_runtime/eager/tensor_handle.cc:495] TensorValue on TensorHandle: 0x56197e5a2bf0 device: 0
2023-01-12 09:34:44.772820: I tensorflow/core/common_runtime/process_function_library_runtime.cc:1347] Running component function on device /job:localhost/replica:0/task:0/device:CPU:0 from __wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0 with handle 0
2023-01-12 09:34:44.772890: I tensorflow/core/common_runtime/process_function_library_runtime.cc:1356]     with FLR::Options(step_id=-880841271269153403 rendezvous=set cancellation_manager=set collective_executor=set step_container=set stats_collector=unset runner=set remote_execution=0 source_device= create_rendezvous=0 allow_dead_tensors=1 args_alloc_attrs=[AllocatorAttributes(on_host=0 nic_compatible=0 gpu_compatible=0)] rets_alloc_attrs=[AllocatorAttributes(on_host=0 nic_compatible=0 gpu_compatible=0)])
2023-01-12 09:34:44.773013: I tensorflow/core/graph/graph.cc:529] AddNode: no type constructor for _SOURCE
2023-01-12 09:34:44.773076: I tensorflow/core/graph/graph.cc:529] AddNode: no type constructor for _SINK
2023-01-12 09:34:44.773147: I tensorflow/core/common_runtime/function.cc:893] Pruning function body: function_name=__wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0_4619141710927497548_0
2023-01-12 09:34:44.773291: I tensorflow/core/graph/algorithm.cc:235] Reverse reach : output_retval_RetVal from _EagerConst
2023-01-12 09:34:44.773327: I tensorflow/core/graph/algorithm.cc:235] Reverse reach : _EagerConst from input
2023-01-12 09:34:44.773348: I tensorflow/core/graph/algorithm.cc:235] Reverse reach : input from _SOURCE
2023-01-12 09:34:44.773378: I tensorflow/core/common_runtime/function_utils.cc:78] Graph Initial #nodes 5 #edges 6
2023-01-12 09:34:44.773804: I tensorflow/core/common_runtime/function_utils.cc:82] || 
2023-01-12 09:34:44.773861: I tensorflow/core/common_runtime/function_utils.cc:82] || (n2:double) -> (n3:double) {
2023-01-12 09:34:44.773889: I tensorflow/core/common_runtime/function_utils.cc:82] ||   n3 = _EagerConst[T=double, _XlaHasReferenceVars=false, device=CPU:0](n2)
2023-01-12 09:34:44.773912: I tensorflow/core/common_runtime/function_utils.cc:82] || }
2023-01-12 09:34:44.773933: I tensorflow/core/common_runtime/function_utils.cc:82] || 
2023-01-12 09:34:44.773955: I tensorflow/core/common_runtime/function_utils.cc:164] Removing list array converter
2023-01-12 09:34:44.774096: I tensorflow/core/common_runtime/function_utils.cc:78] Graph Before #nodes 5 #edges 6
2023-01-12 09:34:44.774731: I tensorflow/core/common_runtime/function_utils.cc:82] || 
2023-01-12 09:34:44.774782: I tensorflow/core/common_runtime/function_utils.cc:82] || (n2:double) -> (n3:double) {
2023-01-12 09:34:44.774819: I tensorflow/core/common_runtime/function_utils.cc:82] ||   n3 = _EagerConst[T=double, _XlaHasReferenceVars=false, device=CPU:0](n2)
2023-01-12 09:34:44.774837: I tensorflow/core/common_runtime/function_utils.cc:82] || }
2023-01-12 09:34:44.774849: I tensorflow/core/common_runtime/function_utils.cc:82] || 
2023-01-12 09:34:44.775018: I tensorflow/core/common_runtime/constant_folding.cc:613] No constant foldable nodes found
2023-01-12 09:34:44.777740: I tensorflow/core/graph/graph.cc:529] AddNode: no type constructor for _SOURCE
2023-01-12 09:34:44.777852: I tensorflow/core/graph/graph.cc:529] AddNode: no type constructor for _SINK
2023-01-12 09:34:44.777946: I tensorflow/core/common_runtime/function_utils.cc:78] Graph ReCopy #nodes 5 #edges 7
2023-01-12 09:34:44.778099: I tensorflow/core/common_runtime/function_utils.cc:82] || 
2023-01-12 09:34:44.778123: I tensorflow/core/common_runtime/function_utils.cc:82] || (n2:double) -> (n3:double) {
2023-01-12 09:34:44.778133: I tensorflow/core/common_runtime/function_utils.cc:82] ||   n3 = _EagerConst[T=double, _XlaHasReferenceVars=false, device=CPU:0](n2)
2023-01-12 09:34:44.778144: I tensorflow/core/common_runtime/function_utils.cc:82] || }
2023-01-12 09:34:44.778154: I tensorflow/core/common_runtime/function_utils.cc:82] || 
2023-01-12 09:34:44.778285: W tensorflow/core/util/dump_graph.cc:134] Failed to dump EnsureMemoryTypes because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-01-12 09:34:44.899549: I tensorflow/tsl/platform/status.cc:176] Generated non-OK status: "INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified". *** Begin stack trace ***

        tsl::Status::Status(tensorflow::error::Code, std::basic_string_view<char, std::char_traits<char> >, tsl::SourceLocation)
        tsl::Status tsl::errors::InvalidArgument<char const*>(char const*)


        tensorflow::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
        tensorflow::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
        tensorflow::EnsureMemoryTypes(tsl::DeviceType const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph*)
        tensorflow::FunctionLibraryRuntimeImpl::CreateItem(tensorflow::FunctionLibraryRuntimeImpl::Item**)
        tensorflow::FunctionLibraryRuntimeImpl::GetOrCreateItem(unsigned long, tensorflow::FunctionLibraryRuntimeImpl::Item**)
        tensorflow::FunctionLibraryRuntimeImpl::PrepareRunSync(unsigned long, tensorflow::FunctionLibraryRuntime::Options*, tensorflow::FunctionLibraryRuntimeImpl::Item**, std::unique_ptr<tensorflow::PrivateIntraProcessRendezvous, std::default_delete<tensorflow::PrivateIntraProcessRendezvous> >*)
        tensorflow::FunctionLibraryRuntimeImpl::RunSync(tensorflow::FunctionLibraryRuntime::Options, unsigned long, absl::lts_20220623::Span<tensorflow::Tensor const>, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*)
        tensorflow::ProcessFunctionLibraryRuntime::RunMultiDeviceSync(tensorflow::FunctionLibraryRuntime::Options const&, unsigned long, std::vector<std::variant<tensorflow::Tensor, tensorflow::TensorShape>, std::allocator<std::variant<tensorflow::Tensor, tensorflow::TensorShape> > >*, std::function<tsl::Status (tensorflow::ProcessFunctionLibraryRuntime::ComponentFunctionData const&, tensorflow::ProcessFunctionLibraryRuntime::InternalArgs*)>) const
        tensorflow::ProcessFunctionLibraryRuntime::RunSync(tensorflow::FunctionLibraryRuntime::Options const&, unsigned long, absl::lts_20220623::Span<tensorflow::Tensor const>, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*) const
        tensorflow::KernelAndDeviceFunc::Run(tensorflow::ScopedStepContainer*, tensorflow::EagerKernelArgs const&, std::vector<std::variant<tensorflow::Tensor, tensorflow::TensorShape>, std::allocator<std::variant<tensorflow::Tensor, tensorflow::TensorShape> > >*, tsl::CancellationManager*, std::optional<tensorflow::EagerFunctionParams> const&, std::optional<tensorflow::ManagedStackTrace> const&, tensorflow::CoordinationServiceAgent*)
        tensorflow::EagerKernelExecute(tensorflow::EagerContext*, absl::lts_20220623::InlinedVector<tensorflow::TensorHandle*, 4ul, std::allocator<tensorflow::TensorHandle*> > const&, std::optional<tensorflow::EagerFunctionParams> const&, std::unique_ptr<tensorflow::KernelAndDevice, tsl::core::RefCountDeleter> const&, tensorflow::GraphCollector*, tsl::CancellationManager*, absl::lts_20220623::Span<tensorflow::TensorHandle*>, std::optional<tensorflow::ManagedStackTrace> const&)
        tensorflow::ExecuteNode::Run()
        tensorflow::EagerExecutor::SyncExecute(tensorflow::EagerNode*)


        tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
        tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
        tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
        TFE_Execute
        tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
        tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
        tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
        EagerTensor_init
        _PyObject_MakeTpCall
        _PyEval_EvalFrameDefault

        _PyFunction_Vectorcall

        _PyEval_EvalFrameDefault

        _PyFunction_Vectorcall

        _PyEval_EvalFrameDefault

        _PyFunction_Vectorcall

        _PyEval_EvalFrameDefault

        _PyFunction_Vectorcall

        _PyEval_EvalFrameDefault

        _PyFunction_Vectorcall

        _PyEval_EvalFrameDefault

        _PyFunction_Vectorcall
        PyObject_Call
        _PyEval_EvalFrameDefault

        _PyFunction_Vectorcall

        _PyEval_EvalFrameDefault

        _PyFunction_Vectorcall
        _PyEval_EvalFrameDefault

        _PyFunction_Vectorcall
        _PyEval_EvalFrameDefault

        _PyFunction_Vectorcall

        _PyEval_EvalFrameDefault


        PyEval_EvalCode



        _PyEval_EvalFrameDefault

        _PyFunction_Vectorcall

        _PyEval_EvalFrameDefault

        _PyFunction_Vectorcall

        _PyEval_EvalFrameDefault

        _PyFunction_Vectorcall

        _PyEval_EvalFrameDefault
        _PyFunction_Vectorcall
        _PyEval_EvalFrameDefault
        _PyFunction_Vectorcall
        _PyEval_EvalFrameDefault

        PyEval_EvalCode


        _PyEval_EvalFrameDefault
        _PyFunction_Vectorcall
        _PyEval_EvalFrameDefault
        _PyFunction_Vectorcall

        Py_RunMain
        Py_BytesMain

        __libc_start_main
        _start
*** End stack trace ***

2023-01-12 09:34:44.900159: I tensorflow/core/common_runtime/memory_types.cc:210] Dumped graph after EnsureMemoryTypes to (failed to create writable file: INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified)
2023-01-12 09:34:44.900750: I tensorflow/core/framework/op_kernel.cc:1689] Instantiating kernel for node: {{node _EagerConst}} = _EagerConst[T=DT_DOUBLE, _XlaHasReferenceVars=false, _device="/job:localhost/replica:0/task:0/device:CPU:0"](input)
2023-01-12 09:34:44.902136: I tensorflow/core/framework/op_kernel.cc:1689] Instantiating kernel for node: {{node output_retval_RetVal}} = _Retval[T=DT_DOUBLE, index=0](_EagerConst)
2023-01-12 09:34:44.903925: I tensorflow/core/common_runtime/process_function_library_runtime.cc:1370] Component function execution succeeded.
2023-01-12 09:34:44.904177: I tensorflow/core/common_runtime/eager/tensor_handle.cc:253] Creating Local TensorHandle: 0x56197e75c6a0 device: [] tensor: Tensor<type: double shape: [3,3]>
2023-01-12 09:34:44.904292: I tensorflow/core/common_runtime/eager/tensor_handle.cc:422] Releasing tensor handle 0x56197e5a2bf0
2023-01-12 09:34:44.904316: I tensorflow/core/common_runtime/eager/tensor_handle.cc:419] Deleting tensor handle 0x56197e5a2bf0
2023-01-12 09:34:45.448185: I tensorflow/core/common_runtime/eager/tensor_handle.cc:683] HasLocalMirror on TensorHandle: 0x56197e75c6a0 device: 0
2023-01-12 09:34:45.448268: I tensorflow/core/common_runtime/eager/tensor_handle.cc:458] Tensor on TensorHandle: 0x56197e75c6a0
2023-01-12 09:34:45.458941: I tensorflow/core/common_runtime/eager/tensor_handle.cc:683] HasLocalMirror on TensorHandle: 0x56197e75c6a0 device: 0
2023-01-12 09:34:45.459036: I tensorflow/core/common_runtime/eager/tensor_handle.cc:458] Tensor on TensorHandle: 0x56197e75c6a0














========================摘要===============
tensorflow::EagerContext::SelectDevice(tensorflow::DeviceNameUtils::ParsedName, tensorflow::NodeDef const&, tensorflow::Device**) const
        tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
        tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
        tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
        TFE_Execute
        tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
        tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
        tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
        EagerTensor_init

tensorflow::EagerContext::FindCompositeDeviceFromName(std::basic_string_view<char, std::char_traits<char> >, tensorflow::CompositeDevice**) const
        tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
        tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
        tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
        TFE_Execute
        tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
        tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
        tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
        EagerTensor_init

tensorflow::OpRegistry::LookUp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::OpRegistrationData const**) const
        tensorflow::OpRegistryInterface::LookUpOpDef(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::OpDef const**) const
        tensorflow::FunctionLibraryDefinition::AddFunctionDefHelper()
        tensorflow::FunctionLibraryDefinition::AddFunctionDef()
        tensorflow::EagerContext::AddFunctionDef()
        tensorflow::EagerContext::AddFunctionDef(tensorflow::FunctionDef const&)
        tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
        tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
        tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
        TFE_Execute
        tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
        tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
        tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
        EagerTensor_init

tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:180] None of the MLIR Optimization Passes are enabled (registered 3)

tensorflow/core/common_runtime/function_utils.cc:78] Graph Before running PRE_PLACEMENT passes #nodes 5 #edges 5
tensorflow/core/common_runtime/optimization_registry.cc:54] Starting optimization of a group 0
tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)
            tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
            tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
            tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
            tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
            tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
            tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
            tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
            TFE_Execute
            tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
            tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
            tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
            EagerTensor_init
tensorflow/core/common_runtime/optimization_registry.cc:87] Finished optimization of a group 0

tensorflow/core/common_runtime/function_utils.cc:78] Graph Before calling Placer #nodes 5 #edges 6
tensorflow/core/common_runtime/placer.cc:178
tensorflow/core/common_runtime/placer.cc:120
tensorflow::Placer::Run()
        tensorflow::ProcessFunctionLibraryRuntime::OptimizeFunctionGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, std::shared_ptr<tensorflow::DeviceSet> const&)
        tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
        tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
        tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
        tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
        tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
        tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
        tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
        TFE_Execute
        tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
        tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
        tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
        EagerTensor_init

tensorflow/core/common_runtime/function_utils.cc:78] Graph Before running POST_PLACEMENT passes #nodes 5 #edges 6

tensorflow/core/common_runtime/optimization_registry.cc:54] Starting optimization of a group 1
调用栈与group 0一样
tensorflow/core/common_runtime/optimization_registry.cc:87] Finished optimization of a group 1

tensorflow/core/common_runtime/function_utils.cc:78] Graph Before running POST_REWRITE_FOR_EXEC passes #nodes 5 #edges 6

tensorflow/core/common_runtime/optimization_registry.cc:54] Starting optimization of a group 2
调用栈与group 0一样
tensorflow/core/common_runtime/optimization_registry.cc:87] Finished optimization of a group 2


tensorflow/core/common_runtime/replicate_per_replica_nodes.cc:277] No nodes with composiste device found

tensorflow/core/common_runtime/process_function_library_runtime.cc:993] Main function graph to be partitioned:
tensorflow/core/graph/graph_partition.cc:1251] Added send/recv: controls=0, data=0
tensorflow::Partition()
        tensorflow::PartitionFunctionGraph()
        tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
        tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
        tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
        tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
        tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
        tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
        tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
        TFE_Execute
        tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
        tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
        tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
        EagerTensor_init

tensorflow/core/graph/graph.cc:529] AddNode: no type constructor for _SOURCE
tensorflow/core/graph/graph.cc:529] AddNode: no type constructor for _SINK
tensorflow/core/graph/graph.cc:529] AddNode: no type constructor for input
tensorflow/core/graph/graph.cc:529] AddNode: no type constructor for _EagerConst
tensorflow/core/graph/graph.cc:529] AddNode: no type constructor for output_RetVal

tensorflow/core/common_runtime/function_utils.cc:78] Graph Before running POST_PARTITIONING passes (/job:localhost/replica:0/task:0/device:CPU:0) #nodes 5 #edges 5

tensorflow/core/common_runtime/optimization_registry.cc:54] Starting optimization of a group 3
调用栈与group 0一样
tensorflow/core/common_runtime/optimization_registry.cc:87] Finished optimization of a group 3

tensorflow/core/common_runtime/function_utils.cc:78] Graph After all optimization passes (/job:localhost/replica:0/task:0/device:CPU:0) #nodes 5 #edges 5

tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
        tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
        tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
        tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
        tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
        tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
        tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
        TFE_Execute
        tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
        tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
        tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
        EagerTensor_init

tensorflow::AttrSlice::CheckFind(std::basic_string_view<char, std::char_traits<char> >, tensorflow::AttrValue const*) const
        tensorflow::AttrSlice::Find(std::basic_string_view<char, std::char_traits<char> >, tensorflow::AttrValue const**) const
        tensorflow::UpdateArgAndRetvalMetadata()
        std::function<void ()>::operator()() const
        tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
        tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
        tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
        tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
        tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
        tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
        tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
        TFE_Execute
        tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
        tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
        tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
        EagerTensor_init

tensorflow::OpRegistry::LookUp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::OpRegistrationData const**) const
        tensorflow::OpRegistryInterface::LookUpOpDef(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::OpDef const**) const
        tensorflow::FunctionLibraryDefinition::AddFunctionDefHelper()
        tensorflow::FunctionLibraryDefinition::AddFunctionDef()
        std::function<void ()>::operator()() const
        tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
        tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)
        tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
        tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)
        tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
        tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
        tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
        TFE_Execute
        tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
        tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
        tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
        EagerTensor_init

tensorflow/core/framework/op.cc:80] NOT_FOUND: Op type not registered '__wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0_4619141710927497548_0' in binary running on docker-desktop. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.

tensorflow/core/common_runtime/process_function_library_runtime.cc:1150] Start instantiating component function __wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0_4619141710927497548_0 on device /job:localhost/replica:0/task:0/device:CPU:0
tensorflow/core/framework/function.cc:742] Instantiate function definition: name=__wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0_4619141710927497548_0 #input_args=1 #output_args=1 #control_output=0
tensorflow/core/common_runtime/process_function_library_runtime.cc:1159] Finished instantiating component function

tensorflow/core/common_runtime/process_function_library_runtime.cc:1195] Instantiated MultiDevice function "__wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0" with handle 1

tensorflow/core/common_runtime/eager/execute.cc:1445] Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0
tensorflow/core/common_runtime/eager/tensor_handle.cc:495] TensorValue on TensorHandle: 0x56197e5a2bf0 device: 0
tensorflow/core/common_runtime/process_function_library_runtime.cc:1347] Running component function on device /job:localhost/replica:0/task:0/device:CPU:0 from __wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0 with handle 0

tensorflow/core/common_runtime/function.cc:893] Pruning function body: function_name=__wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0_4619141710927497548_0
tensorflow/core/graph/algorithm.cc:235] Reverse reach : output_retval_RetVal from _EagerConst

tensorflow/core/common_runtime/function_utils.cc:78] Graph Initial #nodes 5 #edges 6
tensorflow/core/common_runtime/function_utils.cc:164] Removing list array converter
tensorflow/core/common_runtime/function_utils.cc:78] Graph Before #nodes 5 #edges 6
tensorflow/core/common_runtime/constant_folding.cc:613] No constant foldable nodes found
tensorflow/core/common_runtime/function_utils.cc:78] Graph ReCopy #nodes 5 #edges 7

tensorflow::EnsureMemoryTypes(tsl::DeviceType const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph*)
        tensorflow::FunctionLibraryRuntimeImpl::CreateItem(tensorflow::FunctionLibraryRuntimeImpl::Item**)
        tensorflow::FunctionLibraryRuntimeImpl::GetOrCreateItem(unsigned long, tensorflow::FunctionLibraryRuntimeImpl::Item**)
        tensorflow::FunctionLibraryRuntimeImpl::PrepareRunSync(unsigned long, tensorflow::FunctionLibraryRuntime::Options*, tensorflow::FunctionLibraryRuntimeImpl::Item**, std::unique_ptr<tensorflow::PrivateIntraProcessRendezvous, std::default_delete<tensorflow::PrivateIntraProcessRendezvous> >*)
        tensorflow::FunctionLibraryRuntimeImpl::RunSync(tensorflow::FunctionLibraryRuntime::Options, unsigned long, absl::lts_20220623::Span<tensorflow::Tensor const>, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*)
        tensorflow::ProcessFunctionLibraryRuntime::RunMultiDeviceSync() const
        tensorflow::ProcessFunctionLibraryRuntime::RunSync(tensorflow::FunctionLibraryRuntime::Options const&, unsigned long, absl::lts_20220623::Span<tensorflow::Tensor const>, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*) const
        tensorflow::KernelAndDeviceFunc::Run()
        tensorflow::EagerKernelExecute()
        tensorflow::ExecuteNode::Run()
        tensorflow::EagerExecutor::SyncExecute(tensorflow::EagerNode*)
        tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)
        tensorflow::EagerOperation::Execute(absl::lts_20220623::Span<tensorflow::AbstractTensorHandle*>, int*)
        tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)
        TFE_Execute
        tensorflow::EagerConst(TFE_Context*, TFE_TensorHandle*, char const*, TF_Status*)
        tensorflow::ConvertToEagerTensorUncached(TFE_Context*, _object*, tensorflow::DataType, char const*)
        tensorflow::ConvertToEagerTensor(TFE_Context*, _object*, tensorflow::DataType, char const*)
        EagerTensor_init

tensorflow/core/framework/op_kernel.cc:1689] Instantiating kernel for node: {{node _EagerConst}} = _EagerConst[T=DT_DOUBLE, _XlaHasReferenceVars=false, _device="/job:localhost/replica:0/task:0/device:CPU:0"](input)
tensorflow/core/common_runtime/process_function_library_runtime.cc:1370] Component function execution succeeded.
tensorflow/core/common_runtime/eager/tensor_handle.cc:253] Creating Local TensorHandle: 0x56197e75c6a0 device: [] tensor: Tensor<type: double shape: [3,3]>
