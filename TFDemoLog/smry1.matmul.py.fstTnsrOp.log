
        
/Users/butter/Library/Python/3.8/lib/python/site-packages/tensorflow/python/ops/math_ops.py:3491 tf.matmul(a,b)
:3631 'a = ops.convert_to_tensor(a, name="a")'
如下是已经执行了context.ensure_initialized()方法
然后执行'ops.EagerTensor(value, ctx.device_name, dtype)'

//BTBT tfe是tf eager mode的意思        
        
        

EagerTensor_init  python/eager/pywrap_tensor.cc:499//BTBT 转py传入的参数和Ctx
  'PyArg_ParseTupleAndKeywords' 从py端传入的PyObject中提取各种参数,使用 'ConvertDeviceName'得到 device_name,使用 'ConvertDataType'得到 dtype(data type) //BT设备 BT张量
tensorflow::ConvertToEagerTensor(ctx, valFromPy, DataType, device_name) python/eager/pywrap_tensor.cc:392 //BTBT 从缓存取TensorHandler,若没有则调ConvertToEagerTensorUncached.  ??? TFE_TensorHandleCache的K和V是什么 //BT张量 //BT缓存
tensorflow::ConvertToEagerTensorUncached(ctx, valFromPy, DataType, device_name) python/eager/pywrap_tensor.cc:292 
                                                    //BT张量 基于Py端传入的入参创建TensorHandle
                                                    创建包含了Tensor的TensorHandle:python/lib/core/py_seq_tensor.cc:716.PySeqToTFE_TensorHandle>'FloatConverter::Convert(ctx, obj, &state, &handle, &error)'
                                                      其实就是调EagerCtx中类似CreateFloatScalar()的方法创建Tensor然后把Tensor通过类似CreateLocalHandle()的方法封装到TensorHandle中返回,最终拿到的是可操作Tensor的TensorHandle
:377 tensorflow::EagerConst(ctx, valTsrHdl, device_name, out_status) python/eager/pywrap_tensor.cc:269
                                                    //BT算子 到了py端算子对应的c端算子粒度的API时,创建并初始化EagerOperation
                                                      创建 EagerOperation:c/eager/c_api.cc:629.TFE_NewOp()>'unwrap(ctx)->CreateOperation()'>core/common_runtime/eager/core.cc:155.EagerContext::CreateOperation()
                                                      设置 EagerOperation 的相关属性:在TFE_NewOp中调EagerOperation.Reset(),以及在EagerConst()调TFE_OpSetDevice,TFE_OpAddInput,TFE_OpSetAttrType(其实这三函数起的只是解warp的作用,实际调的也是EagerOperation对应的函数) //BT设备 BT张量
                                                        'EagerOperation::Reset(//BT算子 用op name对应的注册信息,属性等对本EagerOperation进行初始化'core/common_runtime/eager/eager_operation.cc:316 此时并没传入device_name
                                                          设置 is_function_,默认false,但调 AttrTypeMapForOp()时如果无法从 OpRegistry 找到对应的OpDef,则是true并返回func op默认的attrName和对应typ的map,否则如果是false,即不是func op则返回注册时的attrName和对应的typ的map
                                                          设置 colocation_exempt_,如果是func op或者InputColocationExemptionRegistry中有注册的op是可以不与其所需的resource放在同一个device上的,即设为true //BT算子 BT调度 BT设备
                                                          具体看函数的注释
:280 TFE_Execute c/eager/c_api.cc:888      
  获取 ImmediateExecutionOperation<EagerOperation> 以调 CustomDeviceOpHandler::Execute().  ImmediateExecutionOperation见tf.mdj.                              
:892 tensorflow::CustomDeviceOpHandler::Execute(ImmediateExecutionOperation op<EagerOperation>, ImmediateExecutionTensorHandle retvals, num_retvals)core/common_runtime/eager/custom_device_op_handler.cc:58
  //BT张量 BT调度 若是CustomDevice上的input张量,则转移到op的设备
  如果 'MaybePinToCustomDevice' op是基于CustomDevice的话,则 'custom_device->Execute(op' 在自定义设备:CustomDevice 上执行op (???CustomDevice是啥?)
  如果 'if (tensorflow::CustomDeviceTensorHandle::classof(inputs[i]))' 有input来自CustomDevice,则 'previous->device()->CopyTensorFromDevice(' 把CustomDevice中的tensor复制到op所在的target_device(一般是op中设置的,如果没设,则用 'op->GetContext()->HostCPUName()')
  然后'op->Execute(' 本场景是直接调EagerOperation.Execute()
:92 tensorflow::EagerOperation::Execute(AbstractTensorHandle retvals, num_retvals)core/common_runtime/eager/core.cc:163 
  //BT张量 BT设备
  'WaitUnknownDevice()' TensorHandle::WaitUnknownDevice() //If the devices are unknown at creation time, block until the actual devices //are set (data is ready). //BT张量 BT多线程 等待input的各tensor所属的device都准备完毕
  //BT调度 做PinToResourceDevice和PinSmallOpsToCpu相关调度(EagerOperation.SetDevice)
  'MaybePinToResourceDevice(&device, *this)' //BT算子 BT调度 core/common_runtime/eager/placement_utils.cc:138 在 'op.colocation_exempt()'为false时,将op的device设置到input tensor的设备(tensor_handle->resource_device())上(colocation_exempt_在EagerOperation.Reset()中设置)
  'MaybePinSmallOpsToCpu(' //BT算子 BT性能 BT调度 检查op是否能pin到CPU,MaybePinSmallOpsToCpu()中有判断规则:比如非func op, 非collocation exempt等等,详见函数内注释
  //BT设备 若之前MaybePinToResourceDevice和MaybePinSmallOpsToCpu函数确定了EagerOperation的所属Device,则这里调用EagerOperation.SetDevice()设置device.
  然后调用下面EagerExecute
:190 tensorflow::EagerExecute(EagerOperation, TensorHandle retvals, num_retvals)core/common_runtime/eager/execute.cc:1787 *72分支点*
  'if (!op->Executor().Async())' 该场景是异步,故不进入该代码块 //BT异步
  'EagerOpRewriteRegistry::PRE_EXECUTION, op, &out_op)' 在pre_execution的点加入算子rewrite的优化点.//BT图优 PRE_EXECUTION貌似没有相关pass???
    其注册机制为:调 eager_op_rewrite_registry.h 中的 REGISTER_REWRITE 宏进行注册,然后通过 eager_op_rewrite_registry.cc 的 EagerOpRewriteRegistry::Global()->RunRewrite() 进行调用 
  'if (op->IsLocal()) {' 本场景是 local 故执行下面的EagerLocalExecute. 但 'op = out_op.get()'和 'MaybePackInputTensor(op)'没搞懂 ???
  :1816 EagerLocalExecute() core/common_runtime/eager/execute.cc:1400
    :1411 和 1433???....GetOrCreateKernelAndDevice(EagerOperation, TensorHandle retvals, num_retvals, out_kernel) core/common_runtime/eager/execute.cc:1056 //BT算子 创建和初始化KernelAndDevice赋给out_kernel
      :1064 调 SetOpDevice() core/common_runtime/eager/execute.cc:1015 < ('if (device == nullptr && !op->is_function())' 同时 GetCachedDevice 找不到device) //BT设备 // Set the EagerOperation's device prior to extracting the input_device_ptrs// to avoid any redundant H2D/D2H copies. ???
        //BT设备 BT调度 拿到传入的op和ctx中的dev信息 preferredDevice, 以及从op的attr信息中得到NodeDef给SelectDevice()去获取可支持该Node的设备.
        'op->GetDeviceParsedName()' 这个值在EagerConst()时通过op.SetDeviceName()设置.即//BT算子 到了py端算子对应的c端算子粒度的API时,创建并初始化EagerOperation时设置op的device_parsed_name_和device_name_
        :1033 EagerContext::SelectDevice(preferredDevice,nodeDef,output) core/common_runtime/eager/context.cc:353
                                                      //BT设备 BT调度
                                                        三个设备来源:
                                                          传入的 preferredDevice(含op中设置的,以及ctx中的本地cpu);
                                                          SupportedDeviceTypesForNode()core/framework/op_kernel.cc:1529 得到该ctx中的支持传入的nodeDef的所有设备;
                                                            来源<ctx.prioritized_device_type_list_<EagerContext::InitPrioritizedDeviceTypeList()
                                                              InitPrioritizedDeviceTypeList()被调用的地方:EagerContext::EagerContext()&AddDevices&StoreCollectiveOpsServer&UpdateRemoteMaster&SetMasterContextState&InitializeRemoteWorker&UpdateRemoteWorker
                                                          'pflr_device_set->prioritized_devices()'得到的existingDevices;  pflr.device_set_貌似是ctx.prioritized_device_type_list_的子集???
                                                            来源<在创建EagerContext时会调它的ctx.ResetRFLR()去创建ProcessFunctionLibraryRuntime,
                                                              <在ProcessFunctionLibraryRuntime()里面会调rflr.InitializeDeviceAndFlr()初始化rflr.device_set_
                                                              <在EagerContext.UpdateRemoteMaster()&UpdateRemoteWorker()中也会调rflr.InitializeDeviceAndFlr()去更新rflr.device_set_
                                                        :371 通过context.cc.SelectBestMatchingDevice()确定合适的设备    //???如何确定最合适设备?
                                                        :383 若第一次找不到合适的,则考虑'AllowSoftPlacement()'去SelectBestMatchingDevice找合适的设备
        log: core/common_runtime/eager/execute.cc:1036] PreferredDevice _EagerConst: /job:localhost/replica:0/task:0  //BT算子 op_name=_EagerConst python/eager/pywrap_tensor.cc:269.EagerConst()中设置,即在调用到py端算子对应的c端算子粒度API时设置.
        log: core/common_runtime/eager/execute.cc:1037] Placer place op [_EagerConst] on device: /job:localhost/replica:0/t
        log: core/common_runtime/eager/execute.cc:1039] Available kernels for _EagerConst are  调 core/framework/op_kernel.cc:1623.KernelsRegisteredForOp()打印注册在该op_name下的各个kernel, ??? 怎么为op注册kernel的
                                                                                                device='GPU'; T in [DT_BOOL]
                                                                                                device='GPU'; T in [DT_VARIANT]
                                                                                                device='GPU'; T in [DT_COMPLEX128]
                                                                                                device='GPU'; T in [DT_COMPLEX64]
                                                                                                device='GPU'; T in [DT_INT8]
                                                                                                device='GPU'; T in [DT_UINT8]
                                                                                                device='GPU'; T in [DT_INT16]
                                                                                                device='GPU'; T in [DT_UINT16]
                                                                                                device='GPU'; T in [DT_UINT32]
                                                                                                device='GPU'; T in [DT_INT64]
                                                                                                device='GPU'; T in [DT_UINT64]
                                                                                                device='GPU'; T in [DT_DOUBLE]
                                                                                                device='GPU'; T in [DT_FLOAT]
                                                                                                device='GPU'; T in [DT_BFLOAT16]
                                                                                                device='GPU'; T in [DT_HALF]
                                                                                                device='CPU'
                                                                                                device='DEFAULT'; T in [DT_RESOURCE]
                                                                                                device='DEFAULT'; T in [DT_STRING]
                                                                                                device='DEFAULT'; T in [DT_INT32]
                                                                                                device='DEFAULT'; T in [DT_BOOL]
                                                                                                device='DEFAULT'; T in [DT_VARIANT]
                                                                                                device='DEFAULT'; T in [DT_COMPLEX128]
                                                                                                device='DEFAULT'; T in [DT_COMPLEX64]
                                                                                                device='DEFAULT'; T in [DT_INT8]
                                                                                                device='DEFAULT'; T in [DT_UINT8]
                                                                                                device='DEFAULT'; T in [DT_INT16]
                                                                                                device='DEFAULT'; T in [DT_UINT16]
                                                                                                device='DEFAULT'; T in [DT_UINT32]
                                                                                                device='DEFAULT'; T in [DT_INT64]
                                                                                                device='DEFAULT'; T in [DT_UINT64]
                                                                                                device='DEFAULT'; T in [DT_DOUBLE]
                                                                                                device='DEFAULT'; T in [DT_FLOAT]
                                                                                                device='DEFAULT'; T in [DT_BFLOAT16]
                                                                                                device='DEFAULT'; T in [DT_HALF]
        'op->SetDevice(*device)'最终的placement用EagerOperation.SetDevice()确定
      1064:'ctx.AddDeviceToCache(device_cache_key, device)' 把SetOpDevice()中拿到的device放入cache //BT设备 BT缓存
      'bool reuse_rendezvous_for_functions =' 判断是否要为各个function设置共用的通信会合点 ??? // When running in eager_op_as_function mode Send/Recv ops need to be // placed on the same rendezvous to match the behaviour of eager mode. //BT自定函 BT通信 
        <'(ctx.RunEagerOpAsFunction() && !op->is_function()) ||' log: core/common_runtime/eager/context.cc:743] RunEagerOpAsFunction: 1  该场景下ctx.中RunEagerOpAsFunction返回true,且op->is_function=tue,因此与操作后,赋值true给reuse_rendezvous_for_functions
          ?*?何时初始化或确定ctx.eager_op_as_function:在context.py.ensure_initialized()创建c端EagerContext时,通过TFE_ContextOptionsSetRunEagerOpAsFunction()设true
      1086: 'if (!op->is_function())'>'kernel_def = GetKernelDef(*op, node_def, device)'core/common_runtime/eager/execute.cc:298>:300 FindKernelDef(deviceType,nodeDef,kernelDef,kernelClassName)tensorflow/core/framework/op_kernel.cc:1477
        通过EagerOperation,NodeDef从注册器KernelRegistry中找对应的KernelDef //BT算子 ???貌似并没创建 kernel
        :1479 'FindKernelRegistration(' core/framework/op_kernel.cc:1379 
          到kernel注册器 KernelRegistry 中搜索与 key(opName,deviceType,label)对应的KernelRegistration. KernelRegistration中包含了创建kernel实体所需的(KernelDef,kernel_class_name,OpKernelFactory)
          'typed_registry = GlobalKernelRegistryTyped()'core/framework/op_kernel.cc:1308 获取注册器
            'LoadDynamicKernels()' //BT算子 需要用宏AUTOLOAD_DYNAMIC_KERNELS打开.用于加载用户自定义的kernel. 见: https://tensorflow.google.cn/api_docs/python/tf/load_library?hl=en 
            'registry = reinterpret_cast<KernelRegistry*>(GlobalKernelRegistry())'获取注册器 KernelRegistry
          TODO:
            tensorflow/core/kernels/identity_op.cc中搜索'Name("_EagerConst")'可见一个Op类型可对应多个kernel;但一个op_name,一个device,一套label对应一个kernel
            tensorflow/core/framework/op_kernel.h:1389 'class Name : public KernelDefBuilder'
            'REGISTER_KERNEL_BUILDER(Name("_EagerConst").Device(DEVICE_CPU), IdentityOp);'中的'Name("_EagerConst").Device(DEVICE_CPU)'就是创建一个 KernelDefBuilder 的Name子类,然后传入"_EagerConst"这个opName到构造方法,然后再链式调用这个KernelDefBuilder的各个方法传入对应信息
            而其中'REGISTER_KERNEL_BUILDER'宏是如何起作用的,见 core/framework/op_kernel.h:1448 中的 '//BT算子 注册宏[1-5]'的注释
            把 KernelDefBuilder.Build()得到的kernel传入OpKernelRegistrar构造函数>OpKernelRegistrar::InitInternal()tensorflow/core/framework/op_kernel.cc:1321
            以'Key(kernel_def->op(), DeviceType(kernel_def->device_type()), kernel_def->label())'为键,'KernelRegistration(*kernel_def, kernel_class_name, std::move(factory))'为值传入GlobalKernelRegistry()->registry这个 unordered_multimap<string, KernelRegistration>中,也就是说,kernel是在要用的时候,再基于key拿到KernelRegistration,然后调它的'unique_ptr<kernel_factory::OpKernelFactory> factory'创建的
            貌似NodeDef.op()和op_type和op_name是一个东西???
            :1413 //BT设备 ??? '!IsSymbolicExecutionDevice(device_type.type_string())'啥意思
            返回最终的 KernelRegistration
        返回的KernelDef和kernel_class_name也是从KernelRegistration获取
      :1090 ExtractFunctionInputInfo()core/common_runtime/eager/execute.cc:967 <因这里'if (op->is_function() || ctx.RunEagerOpAsFunction())'中RunEagerOpAsFunction返回true
        //BT张量 BT设备 BT调度 BT算子 为op的每个input的device信息,包括input所属的device,CompositionDevice的underlying_devices,以及对 resouce input 的处理.具体看含税注释.
        // Extracts function input info for `op` with `kernel_def`.
        // The following are extracted:
        //   `input_device_ptrs` - The input devices of `op`.
        //   `composite_devices` - Maps from a CompositeDevice name to a list of
        //     physical device names.
        //   `input_resource_variable_dtypes_shape` - A map from input index
        //     to dtype and shapes for resource inputs.
        CompositeDevice ??? 'resource inputs'? 'resource'? //BT设备 //BT数据类型???
        'op->TensorHandleInputs('从op中获取input
        'for (int i = 0, end = inputs->size(); i < end; ++i) {'循环每个input
        'IsHostMemoryArg(*op, node_def, op_device, kernel_def, i);//BT算子 BT张量 BT设备 检查第i个input是否在host memory.注意这个i是port_idx而非arg_idx,前者指某个in/out的tensor,后者指某个in/out的参数.具体区别与转换逻辑,以及检查逻辑请看IsHostMemoryArg函数注释'
        log: core/common_runtime/eager/execute.cc:987] _EagerConst:input:0 /job:localhost/replica:0/task:0/device:CPU:0
        'if (ctx.FindCompositeDeviceFromName(input_device->name(), &composite_device)//BT算子 BT张量 BT设备 BT调度 如果给input分配的device是CompositeDevice,那么该device应由多个device组成,把该device作为key而它的underlying_devices作为val对应起来. ???ctx.composite_devices_ 在哪里如何初始化的?'
          >EagerContext::FindCompositeDeviceFromName() log:"NOT_FOUND: Unknown composite device: /job:localhost/replica:0/task:0/device:CPU:0"
        'if (input->dtype == DT_RESOURCE) {//BT数据类型 ??? input TensorHandle.type是如何设置?DT_RESOURCE是啥?'
      'GetKernelCacheKey(*op, op->MutableAttrs()->CacheKey(op->DeviceName())'>GetKernelCacheKey() log:ctx.RunEagerOpAsFunction(): 1
      'if (kernel == nullptr)'如果上一行从cache中找不到已有的kernel则走此代码块创建一个
      log: /core/common_runtime/eager/execute.cc:1118] Creating new kernel for _EagerConst on device /job:localhost/replica:0/task:0/device:CPU:0
      'if (op->is_function()) {'该代码块处理@tf.fn的场景,此时不走该代码块 ???不确定
      log: /core/common_runtime/eager/execute.cc:1143] _EagerConst function_outputs_on_op_device: 0
      :1145 'if (device == nullptr)' 不成立,因为刚进 GetOrCreateKernelAndDevice() 时就在 :1064 调了 SetOpDevice()去设device
         所以打印 log: /core/common_runtime/eager/execute.cc:1148] Device for [_EagerConst] already set to: /job:localhost/replica:0/task:0/device:CPU:0
      :1171 'if (ctx.RunEagerOpAsFunction() && !op->is_function()) {' 满足条件并进入该代码块
        该代码块主要是讲不是func却又要按func的玩法运行的op,封装成func op.....//BT算子 ??? 这里的func可能就是@tf.fn的意思? 基本上eager模式都是这种func op?
      :1174 'WrapInCallOp(op, &wrapped_op)'>WrapInCallOp() core/common_runtime/eager/execute.cc:803 负责封装op为func op. 
        'VerifyWrappableInCallOp(opdef, op)' // Raise an error for ops which don't support wrapping yet. //BT算子 看实现的确'list inputs/outputs'已支持,只是排查pravate attr这种不支持的情况
        'BuildWrappedOpName(op, opdef, op_attrs, &fname)' //BT算子 构建wrappable CallOp名字的规则没搞懂??? variadic input/output是指维度是可变形状的出入参的意思?比如a[?,3]之类的?
        :822 'if (!op->EagerContext().GetFunctionDef(fname)) {' 先通过 'BuildWrappedOpName(op, opdef, op_attrs, &fname)' 构造func name,如果该func name在ctx的缓存中无法找到,则走该代码块构建一个对应的FunctionDef //BT算子 BT自定函
        'BuildWrappedOpSignature(op, opdef, fname, *fdef.mutable_signature()))' 和 BuildWrappedOpName() 类似,没看懂注释 ??? //BT算子 BT张量
        创建一个 FunctionDef 并用已有的'op, opdef, fname'信息对其初始化. 这里FunctionDef和NodeDef是啥关系?一个FunctionDef包含一个NodeDef??? //BT算子 BT图 BT节点 
        :858 log: core/common_runtime/eager/execute.cc:858]   .... 打印FunctionDef.DebugString()
                signature {  
                  name: "__wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0"
                  input_arg {
                    name: "input"
                    type_attr: "T"
                  }
                  output_arg {
                    name: "output"
                    type_attr: "T"
                  }
                  attr {
                    name: "T"
                    type: "type"
                  }
                }
                node_def {
                  name: "_EagerConst"
                  op: "_EagerConst"
                  input: "input:0"
                  device: "/job:localhost/replica:0/task:0/device:CPU:0"
                  attr {
                    key: "T"
                    value {
                      placeholder: "T"

                    }
                  }
                }
                ret {
                  key: "output"
                  value: "_EagerConst:output:0"
                }
        :859 'EagerContext().AddFunctionDef(std::move(fdef))'>core/common_runtime/eager/context.cc:943.EagerContext::AddFunctionDef()
          :979 'func_lib_def_.AddFunctionDef(fdef, stack_traces)'>tensorflow\core\framework\function.cc:1278.FunctionLibraryDefinition::AddFunctionDef()
            :1282 'AddFunctionDefHelper(fdef, stack_traces, &added)'>tensorflow\core\framework\function.cc:1285.FunctionLibraryDefinition::AddFunctionDefHelper()
              'default_registry_->LookUpOpDef(fdef.signature().name(), &op_def)'>tensorflow\core\framework\op.cc:44.OpRegistryInterface::LookUpOpDef()
                'LookUp(op_type_name, &op_reg_data)'>op.cc:91.OpRegistry::LookUp(const string& op_type_name)
                  找不到报错
                  log: tensorflow/core/framework/op.cc:130] All registered Ops
                  log: Op type not registered => trace:tensorflow::EagerContext::AddFunctionDef
        :861 // Build the call op.
        'ctx = op->EagerContext()'>'call_op(ctx.CreateOperation())'>'call_op->Reset(fname.c_str(), op->DeviceName().c_str())'通过op得到EagerContext并新建一个EagerOperation,把EagerOperation的名字Reset()为fname,
          //BT算子 BT自定函 新建的call_op以fname为名字,会使它无法在OpRegistry中找到,进而变成一个is_function_=true的func op
        新建op赋值给wrapped_op并用原op的input和attr对其进行初始化后返回
      :1192 core/common_runtime/eager/execute.cc::1208 BT算子 BT自定函 //BT??? ctx.pflr_和ProcessFunctionLibraryRuntime::flr_map_是如何设置的  //BT算子 BT自定函 从 FunctionLibraryRuntime 获取 Executor::Args::Runner ??? 这是干嘛的? 如何设置的 TODO
      'if (run_function_with_flr)'
        // Treat the function as multi_device only when we are not compiling
        // it wholly with XLA. When compiling wholly with XLA, flr->CreateKernel
        // will create an XlaLaunchOp kernel to compile and run the function.
        // Multi-device functions don't use the rendezvous from eager context.
        // If we use that rendezvous, multiple concurrent calls to the same
        // function will likely result in collisions. However, this also means
        // that we don't support legitimate sending/receiving across function
        // boundary.
        log:tensorflow/core/common_runtime/eager/execute.cc:1214: "Running " << ndef.op() << " using multi-device function. "<< "Full node_def=" << ndef.DebugString();
          ndef.op(): __wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0
          ndef.DebugString():
            Full node_def=name: "__wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0"
            op: "__wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0"
            input: "dummy_input"
            attr {
              key: "T"
              value {
                type: DT_DOUBLE
              }
            }
        ....一顿 reuse_rendezvous_for_functions 相关的操作 ???
        'kernel.reset(new KernelAndDeviceFunc('构造 KernelAndDeviceFunc,貌似只初始化属性,没调其它函数
      'kernel->Init(ctx.LogDevicePlacement(), ndef, graph_collector))'>common_runtime\eager\kernel_and_device.cc:244.KernelAndDeviceFunc::Init()
        'InstantiateFunc(log_device_placement, ndef, graph_collector)'>kernel_and_device.cc:139.KernelAndDeviceFunc::InstantiateFunc()
          .... 好多 ???
          :240 'pflr_->Instantiate(ndef.op(), AttrSlice(ndef), options, &handle_)'>common_runtime\process_function_library_runtime.cc:1509.ProcessFunctionLibraryRuntime::Instantiate()
            :934.ProcessFunctionLibraryRuntime::InstantiateMultiDevice()<'if (options.is_multi_device_function)'>'InstantiateMultiDevice(function_name, attrs, options, handle)'>process_function_library_runtime.cc:934.ProcessFunctionLibraryRuntime::InstantiateMultiDevice()
              // Check if this function has already been instantiated.
              开始创建 mutlDeviceFunc
              log: process_function_library_runtime.cc:951 << "Instantiating MultiDevice function " << function_name << " on default device " << options.target 
                function_name: "__wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0"
                options.target: "/job:localhost/replica:0/task:0/device:CPU:0"
              log: Requested input devices: [input 0] /job:localhost/replica:0/task:0/device:CPU:0
              ....
              :970 'OptimizeFunctionGraph(function_name, attrs, options, dev_set)'>process_function_library_runtime.cc:759.ProcessFunctionLibraryRuntime::OptimizeFunctionGraph()
                ....
                log: core/common_runtime/process_function_library_runtime.cc:483] Trying to determine device for node output_RetVal[T=double]
                for ....
                  log: :496] Considering src: _EagerConst src_device: /job:localhost/replica:0/task:0/device:CPU:0 colo group: 
                  :508 while .... 没进该循环,因没log
                .... 好多
                :602 log: process_function_library_runtime.cc:602] Setting output device to /job:localhost/replica:0/task:0/device:CPU:0 for node {{node output_RetVal}} = _Retval[T=DT_DOUBLE, index=0](_EagerConst)
              ....好多 ???
              :847 'FunctionOptimizationPassRegistry::Global().Run(' 调用tensorflow/core/common_runtime/function_optimization_registry.h:55.FunctionOptimizationPassRegistry 中注册的优化方法
                //BT图优 注册机制???
                调用到 tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:130.MlirFunctionOptimizationPass::Run()
                  <该优化方法在tensorflow/compiler/mlir/mlir_graph_optimization_pass_registration.cc:24.'register_mlir_passes(std::make_unique<MlirFunctionOptimizationPass>())'通过注册机制加载到 FunctionOptimizationPassRegistry ??? //BT自动优 BT图优 注册机制???
                  ....???
                  :178 'if (overall_state == MlirOptimizationPassState::Disabled)' log: /compiler/mlir/mlir_graph_optimization_pass.cc:180] None of the MLIR Optimization Passes are enabled
              ....
              'GraphOptimizationPassOptions optimization_options'组装优化所需参数
              :885 'DumpGraph("Before running PRE_PLACEMENT passes", graph.get());' log: core/common_runtime/function_utils.cc:78] Graph Before running PRE_PLACEMENT passes #nodes 5 #edges 5
              'OptimizationPassRegistry::Global()->RunGrouping(' 'OptimizationPassRegistry::PRE_PLACEMENT, optimization_options)'
                >RunGrouping() log:tensorflow/core/common_runtime/optimization_registry.cc:54] Starting optimization of a group 0 //BT图优 注册机制 ??? 挑几个pass看看
                log:tensorflow/core/common_runtime/optimization_registry.cc:87] Finished optimization of a group 0
                .... 很多log //BT图优 注册机制 ??? 挑几个pass看看
              'DumpGraph("Before calling Placer", graph.get())' log: tensorflow/core/common_runtime/function_utils.cc:78] Graph Before calling Placer #nodes 5 #edges 6
                .... //BT调度 placement 及其注册 ???
              'DumpGraph("Before running POST_PLACEMENT passes", graph.get())'
              'OptimizationPassRegistry::Global()->RunGrouping(' 'OptimizationPassRegistry::POST_PLACEMENT, optimization_options)'
                log:tensorflow/core/common_runtime/optimization_registry.cc:54] Starting optimization of a group 1
                ....类似 'Before running PRE_PLACEMENT passes' 一堆log //BT图优
              'if (options.optimize_graph_fn)'>'DumpGraph("Before running graph optimization fn"'>'options.optimize_graph_fn(' 由于不是tf.fn所以没走该分支 ....
              'DumpGraph("Before running POST_REWRITE_FOR_EXEC passes"'
              'OptimizationPassRegistry::Global()->RunGrouping(' 'OptimizationPassRegistry::POST_REWRITE_FOR_EXEC, optimization_options)' 
                log:tensorflow/core/common_runtime/optimization_registry.cc:54] Starting optimization of a group 2
                ....类似 'Before running PRE_PLACEMENT passes' 一堆log //BT图优
              'return OptimizedFunctionGraphInfo{' tensorflow/core/common_runtime/process_function_library_runtime.h:387.// Function graph related information after optimizations. 封装了:graph,lib_def,node_name_to_control_ret,ret_types,num_return_nodes
            :981 'ReplicatePerReplicaNodesInFunctionGraph(' >tensorflow/core/common_runtime/replicate_per_replica_nodes.cc:253
              'composite_device_to_cluster_nodes' // Map from a composite device to a cluster of nodes assigned to the // composite device and the numbers of their out edges to process. 
              'if (composite_device_to_cluster_nodes.empty())' > log: core/common_runtime/replicate_per_replica_nodes.cc:277] No nodes with composiste device found
              ....上一行就返回了,后面没执行
            :993 log:process_function_library_runtime.cc:993] Main function graph to be partitioned:
              DebugString(graph->ToGraphDefDebug():
                      (input:double@CPU:0) -> (_EagerConst:double@CPU:0) {
                        _EagerConst = _EagerConst[T=double, _XlaHasReferenceVars=false, device=CPU:0](input)
                      }
            :998.'PartitionFunctionGraph(*dev_set, std::move(graph), &subgraphs))'
              tensorflow/core/common_runtime/partitioning_utils.cc:115.PartitionFunctionGraph()
                'PartitionFunctionGraph(device_set, graph.get(), &partitions,'>:37.PartitionFunctionGraph() // A helper to partiton a `graph` given a `device_set` and a `graph`.// `partitions` maps device names to the graphdef assigned to that device.
                  ....???
                  :70 'return Partition(partition_options, graph, partitions)'
                    core/graph/graph_partition.cc:981.Partition()
                      ....???
                      log:core/graph/graph_partition.cc:1251] Added send/recv: controls=0, data=0
                :124 'for (auto& partition : partitions) {'
                  ....???
                  'new Graph(graph->flib_def().default_registry()))'>tensorflow\core\graph\graph.cc:414&386.构造Graph
                    ....其它操作
                    'source = AddNode(def, &status)'
                    'sink = AddNode(def, &status)'
                    打印 log:  ???
                      AddNode: no type constructor for _SOURCE
                      AddNode: no type constructor for _SINK
                    'AddControlEdge(source, sink)' ???
                  'ConvertGraphDefToGraph(opts, std::move(graph_def), subgraph.get())'>tensorflow\core\common_runtime\graph_constructor.cc:1469.ConvertNodeDefsToGraph()
                    ....BT形状 相关操作 ???
                    'GraphConstructor::Construct(opts, node_defs, nullptr, nullptr, g,'>tensorflow\core\common_runtime\graph_constructor.cc:486.GraphConstructor::Construct()
                      'NodeDefCopyingGraphConstructor c(opts, node_defs, versions, library, g,' //BTBT ???为何不用 NodeDefMovingGraphConstructor,不是性能更好么 //BT性能
                      'c.TryImport()' graph_constructor.cc:188.TryImport()
                        'Convert()'
                          :1250 'MakeNode(std::move(node_def), &node)'
                            :774 'g_->AddNode(std::move(node_def), &status)'
                              这三个log是此触发打印的???
                                AddNode: no type constructor for input
                                AddNode: no type constructor for _EagerConst
                                AddNode: no type constructor for output_RetVal
            :1001 'for (const auto& pair : subgraphs) {' > 'DumpGraph(strings::StrCat("Before running POST_PARTITIONING passes ("'
              log: Graph Before running POST_PARTITIONING passes (/job:localhost/replica:0/task:0/device:CPU:0) #nodes 5 #edges 5
                  || 
                  || (n2:double@CPU:0) -> (n3:double@CPU:0) {
                  ||   n3 = _EagerConst[T=double, _XlaHasReferenceVars=false, device=CPU:0](n2)
                  || }
            :1006 'GraphOptimizationPassOptions optimization_options'
            :1018 'OptimizationPassRegistry::Global()->RunGrouping(' 'OptimizationPassRegistry::POST_PARTITIONING, optimization_options)'
              log:tensorflow/core/common_runtime/optimization_registry.cc:54] Starting optimization of a group 3
              ....类似 'Before running PRE_PLACEMENT passes' 一堆log //BT图优
            :1021 'for (const auto& pair : subgraphs) {' 打印partition后的每个subgraph
              log: Graph After all optimization passes (/job:localhost/replica:0/task:0/device:CPU:0) #nodes 5 #edges 5
                  || 
                  || (n2:double@CPU:0) -> (n3:double@CPU:0) {
                  ||   n3 = _EagerConst[T=double, _XlaHasReferenceVars=false, device=CPU:0](n2)
                  || }
            :1035 'metrics::UpdateFunctionGraphOptimizationTime(optimization_end_time_usecs -' //BT性测
            ....
            :1073 'auto runner = [this, num_subgraphs](std::function<void()> fn) {' //BT性能 这是传入的fn的一个wrapper,用于当subgraph太多时启用线程池.这个runner会用于下面的处理每一个subgraph
            ....
            :1086 'if (options.allow_small_function_optimizations) {' //BT性能 BT自动优
            :1101 'for (const auto& pair : subgraphs) {' // Instantiate each component function (subgraph).
              对于每个subgraph的初始化, 将:1105 到:1184 整个代码块作为fn传入上面提到的wrapper: runner 去执行
                ....
                :1116 'status->Update(UpdateArgAndRetvalMetadata(' tensorflow/core/common_runtime/partitioning_utils.cc:197.UpdateArgAndRetvalMetadata()
                  partitioning_utils.cc:197 ....
                  :208 'for (Node* node : graph->op_nodes()) {' and 'if (node->IsArg()) {' // Find the Arg and Retval nodes, along with their corresponding indices // in the original function.
                    ....
                    :213 'if (node->attrs().Find("sub_index", &attr_value).ok()) {' 
                      log: No attr named 'sub_index' in NodeDef
                    ....
                  ...
                ....
                :1126 'GraphToFunctionDef(*subgraph, unique_name, control_ret, &shard)' ..... ???
                :1131 'status->Update(data_lib_def->AddFunctionDef(shard))'>tensorflow/core/framework/function.cc:1278.FunctionLibraryDefinition::AddFunctionDef()
                  core/framework/function.cc:1282 'AddFunctionDefHelper(fdef, stack_traces, &added)'>:1285.FunctionLibraryDefinition::AddFunctionDefHelper()
                    如果在 function_defs_ 中有同签名 FunctionDef 存在,则认为该 FunctionDef 已创建,返回ok
                    :1301 'if (default_registry_->LookUpOpDef(fdef.signature().name(), &op_def).ok())' 如果 default_registry_ 中有同签名 FunctionDef 存在,则认为已有Op注册过,返回 error
                    如果找不到同签名的 func 或 op,则基于 FunctionDef 新建一个 FunctionDefAndOpRegistration 插入 function_defs_,并返回 ok
                :1136.'FunctionLibraryRuntime::InstantiateOptions opts' 封装初始化 component function ??? 所需要的参数
              'GetGraphAndArgRets('>process_function_library_runtime.cc:722.ProcessFunctionLibraryRuntime::GetGraphAndArgRets()
                'FunctionDefToBodyHelper(*fdef, attrs, lib_def, &fbody)'>tensorflow\core\common_runtime\function_def_utils.cc:82.定义了一个 get_func_sig 的闭包函数传给:29.FunctionDefToBodyHelper()
                  'InstantiateFunction(fdef, attrs, get_func_sig, &result)'>tensorflow\core\framework\function.cc:737.InstantiateFunction()
                    log: 打印func签名和 func body
                         tensorflow/core/framework/function.cc:742] Instantiate function definition: name=__wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0 #input_args=1 #output_args=1 #control_output=0
                         tensorflow/core/framework/function.cc:747] || 
                         tensorflow/core/framework/function.cc:747] || __wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0[T:<Unknown AttrValue type>](input:T) -> (output:T) {
                         tensorflow/core/framework/function.cc:747] ||   _EagerConst = _EagerConst[T=$T, device=CPU:0](input:0)
                         tensorflow/core/framework/function.cc:747] ||   return output = _EagerConst:output:0
                         tensorflow/core/framework/function.cc:747] || }
                         tensorflow/core/framework/function.cc:747] || 
                    ....其它操作 ???
                  'graph = std::make_unique<Graph>(lib_def)'>tensorflow\core\graph\graph.cc:414&386.构造Graph
                    ....其它操作
                    'source = AddNode(def, &status)'
                    'sink = AddNode(def, &status)'
                    打印 log:  ???
                      AddNode: no type constructor for _SOURCE
                      AddNode: no type constructor for _SINK
                    'AddControlEdge(source, sink)' ???
                  'ConvertNodeDefsToGraph(opts, result.nodes, graph.get())'>tensorflow\core\common_runtime\graph_constructor.cc:1469.ConvertNodeDefsToGraph()
                    ....BT形状 相关操作 ???
                    'GraphConstructor::Construct(opts, node_defs, nullptr, nullptr, g,'>tensorflow\core\common_runtime\graph_constructor.cc:486.GraphConstructor::Construct()
                      'NodeDefCopyingGraphConstructor c(opts, node_defs, versions, library, g,' //BTBT ???为何不用 NodeDefMovingGraphConstructor,不是性能更好么 //BT性能
                      'c.TryImport()' graph_constructor.cc:188.TryImport()
                        'Convert()'
                          :1250 'MakeNode(std::move(node_def), &node)'
                            :774 'g_->AddNode(std::move(node_def), &status)'
                              这三个log是此触发打印的???
                                AddNode: no type constructor for input
                                AddNode: no type constructor for _EagerConst
                                AddNode: no type constructor for output_RetVal
              ....???
              :821 'PinArgsAndRets('>tensorflow\core\common_runtime\process_function_library_runtime.cc:461.ProcessFunctionLibraryRuntime::PinArgsAndRets()
                ....
                log: core/common_runtime/process_function_library_runtime.cc:483] Trying to determine device for node output_RetVal[T=double]
                for ....
                  log: :496] Considering src: _EagerConst src_device: /job:localhost/replica:0/task:0/device:CPU:0 colo group: 
                  :508 while .... 没进该循环,因没log
                .... 好多
                :602 log: process_function_library_runtime.cc:602] Setting output device to /job:localhost/replica:0/task:0/device:CPU:0 for node {{node output_RetVal}} = _Retval[T=DT_DOUBLE, index=0](_EagerConst)
              ....好多 ???
              :847 'FunctionOptimizationPassRegistry::Global().Run(' 调用tensorflow/core/common_runtime/function_optimization_registry.h:55.FunctionOptimizationPassRegistry 中注册的优化方法
                //BT图优 注册机制???
                调用到 tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:130.MlirFunctionOptimizationPass::Run()
                  <该优化方法在tensorflow/compiler/mlir/mlir_graph_optimization_pass_registration.cc:24.'register_mlir_passes(std::make_unique<MlirFunctionOptimizationPass>())'通过注册机制加载到 FunctionOptimizationPassRegistry ??? //BT自动优 BT图优 注册机制???
                  ....???
                  :178 'if (overall_state == MlirOptimizationPassState::Disabled)' log: /compiler/mlir/mlir_graph_optimization_pass.cc:180] None of the MLIR Optimization Passes are enabled
              ....
              'GraphOptimizationPassOptions optimization_options'组装优化所需参数
              :885 'DumpGraph("Before running PRE_PLACEMENT passes", graph.get());' log: core/common_runtime/function_utils.cc:78] Graph Before running PRE_PLACEMENT passes #nodes 5 #edges 5
              'OptimizationPassRegistry::Global()->RunGrouping(' 'OptimizationPassRegistry::PRE_PLACEMENT, optimization_options)'
                >RunGrouping() log:tensorflow/core/common_runtime/optimization_registry.cc:54] Starting optimization of a group 0 //BT图优 注册机制 ??? 挑几个pass看看
                log:tensorflow/core/common_runtime/optimization_registry.cc:87] Finished optimization of a group 0
                .... 很多log //BT图优 注册机制 ??? 挑几个pass看看
              'DumpGraph("Before calling Placer", graph.get())' log: tensorflow/core/common_runtime/function_utils.cc:78] Graph Before calling Placer #nodes 5 #edges 6
                .... //BT调度 placement 及其注册 ???
              'DumpGraph("Before running POST_PLACEMENT passes", graph.get())'
              'OptimizationPassRegistry::Global()->RunGrouping(' 'OptimizationPassRegistry::POST_PLACEMENT, optimization_options)'
                log:tensorflow/core/common_runtime/optimization_registry.cc:54] Starting optimization of a group 1
                ....类似 'Before running PRE_PLACEMENT passes' 一堆log //BT图优
              'if (options.optimize_graph_fn)'>'DumpGraph("Before running graph optimization fn"'>'options.optimize_graph_fn(' 由于不是tf.fn所以没走该分支 ....
              'DumpGraph("Before running POST_REWRITE_FOR_EXEC passes"'
              'OptimizationPassRegistry::Global()->RunGrouping(' 'OptimizationPassRegistry::POST_REWRITE_FOR_EXEC, optimization_options)' 
                log:tensorflow/core/common_runtime/optimization_registry.cc:54] Starting optimization of a group 2
                ....类似 'Before running PRE_PLACEMENT passes' 一堆log //BT图优
              'return OptimizedFunctionGraphInfo{' tensorflow/core/common_runtime/process_function_library_runtime.h:387.// Function graph related information after optimizations. 封装了:graph,lib_def,node_name_to_control_ret,ret_types,num_return_nodes
            :981 'ReplicatePerReplicaNodesInFunctionGraph(' >tensorflow/core/common_runtime/replicate_per_replica_nodes.cc:253
              'composite_device_to_cluster_nodes' // Map from a composite device to a cluster of nodes assigned to the // composite device and the numbers of their out edges to process. 
              'if (composite_device_to_cluster_nodes.empty())' > log: core/common_runtime/replicate_per_replica_nodes.cc:277] No nodes with composiste device found
              ....上一行就返回了,后面没执行
            :993 log:process_function_library_runtime.cc:993] Main function graph to be partitioned:
              DebugString(graph->ToGraphDefDebug():
                      (input:double@CPU:0) -> (_EagerConst:double@CPU:0) {
                        _EagerConst = _EagerConst[T=double, _XlaHasReferenceVars=false, device=CPU:0](input)
                      }
            :998.'PartitionFunctionGraph(*dev_set, std::move(graph), &subgraphs))'
              tensorflow/core/common_runtime/partitioning_utils.cc:115.PartitionFunctionGraph()
                'PartitionFunctionGraph(device_set, graph.get(), &partitions,'>:37.PartitionFunctionGraph() // A helper to partiton a `graph` given a `device_set` and a `graph`.// `partitions` maps device names to the graphdef assigned to that device.
                  ....???
                  :70 'return Partition(partition_options, graph, partitions)'
                    core/graph/graph_partition.cc:981.Partition()
                      ....???
                      log:core/graph/graph_partition.cc:1251] Added send/recv: controls=0, data=0
                :124 'for (auto& partition : partitions) {'
                  ....???
                  'new Graph(graph->flib_def().default_registry()))'>tensorflow\core\graph\graph.cc:414&386.构造Graph
                    ....其它操作
                    'source = AddNode(def, &status)'
                    'sink = AddNode(def, &status)'
                    打印 log:  ???
                      AddNode: no type constructor for _SOURCE
                      AddNode: no type constructor for _SINK
                    'AddControlEdge(source, sink)' ???
                  'ConvertGraphDefToGraph(opts, std::move(graph_def), subgraph.get())'>tensorflow\core\common_runtime\graph_constructor.cc:1469.ConvertNodeDefsToGraph()
                    ....BT形状 相关操作 ???
                    'GraphConstructor::Construct(opts, node_defs, nullptr, nullptr, g,'>tensorflow\core\common_runtime\graph_constructor.cc:486.GraphConstructor::Construct()
                      'NodeDefCopyingGraphConstructor c(opts, node_defs, versions, library, g,' //BTBT ???为何不用 NodeDefMovingGraphConstructor,不是性能更好么 //BT性能
                      'c.TryImport()' graph_constructor.cc:188.TryImport()
                        'Convert()'
                          :1250 'MakeNode(std::move(node_def), &node)'
                            :774 'g_->AddNode(std::move(node_def), &status)'
                              这三个log是此触发打印的???
                                AddNode: no type constructor for input
                                AddNode: no type constructor for _EagerConst
                                AddNode: no type constructor for output_RetVal
            :1001 'for (const auto& pair : subgraphs) {' > 'DumpGraph(strings::StrCat("Before running POST_PARTITIONING passes ("'
              log: Graph Before running POST_PARTITIONING passes (/job:localhost/replica:0/task:0/device:CPU:0) #nodes 5 #edges 5
                  || 
                  || (n2:double@CPU:0) -> (n3:double@CPU:0) {
                  ||   n3 = _EagerConst[T=double, _XlaHasReferenceVars=false, device=CPU:0](n2)
                  || }
            :1006 'GraphOptimizationPassOptions optimization_options'
            :1018 'OptimizationPassRegistry::Global()->RunGrouping(' 'OptimizationPassRegistry::POST_PARTITIONING, optimization_options)'
              log:tensorflow/core/common_runtime/optimization_registry.cc:54] Starting optimization of a group 3
              ....类似 'Before running PRE_PLACEMENT passes' 一堆log //BT图优
            :1021 'for (const auto& pair : subgraphs) {' 打印partition后的每个subgraph
              log: Graph After all optimization passes (/job:localhost/replica:0/task:0/device:CPU:0) #nodes 5 #edges 5
                  || 
                  || (n2:double@CPU:0) -> (n3:double@CPU:0) {
                  ||   n3 = _EagerConst[T=double, _XlaHasReferenceVars=false, device=CPU:0](n2)
                  || }
            :1035 'metrics::UpdateFunctionGraphOptimizationTime(optimization_end_time_usecs -' //BT性测
            ....
            :1073 'auto runner = [this, num_subgraphs](std::function<void()> fn) {' //BT性能 这是传入的fn的一个wrapper,用于当subgraph太多时启用线程池.这个runner会用于下面的处理每一个subgraph
            ....
            :1086 'if (options.allow_small_function_optimizations) {' //BT性能 BT自动优
            :1101 'for (const auto& pair : subgraphs) {' // Instantiate each component function (subgraph).
              对于每个subgraph的初始化, 将:1105 到:1184 整个代码块作为fn传入上面提到的wrapper: runner 去执行
                ....
                :1116 'status->Update(UpdateArgAndRetvalMetadata(' tensorflow/core/common_runtime/partitioning_utils.cc:197.UpdateArgAndRetvalMetadata()
                  partitioning_utils.cc:197 ....
                  :208 'for (Node* node : graph->op_nodes()) {' and 'if (node->IsArg()) {' // Find the Arg and Retval nodes, along with their corresponding indices // in the original function.
                    ....
                    :213 'if (node->attrs().Find("sub_index", &attr_value).ok()) {' 
                      log: No attr named 'sub_index' in NodeDef
                    ....
                  ...
                ....
                :1126 'GraphToFunctionDef(*subgraph, unique_name, control_ret, &shard)' ..... ???
                :1131 'status->Update(data_lib_def->AddFunctionDef(shard))'>tensorflow/core/framework/function.cc:1278.FunctionLibraryDefinition::AddFunctionDef()
                  core/framework/function.cc:1282 'AddFunctionDefHelper(fdef, stack_traces, &added)'>:1285.FunctionLibraryDefinition::AddFunctionDefHelper()
                    如果在 function_defs_ 中有同签名 FunctionDef 存在,则认为该 FunctionDef 已创建,返回ok
                    :1301 'if (default_registry_->LookUpOpDef(fdef.signature().name(), &op_def).ok())' 如果 default_registry_ 中有同签名 FunctionDef 存在,则认为已有Op注册过,返回 error
                    如果找不到同签名的 func 或 op,则基于 FunctionDef 新建一个 FunctionDefAndOpRegistration 插入 function_defs_,并返回 ok
                :1136.'FunctionLibraryRuntime::InstantiateOptions opts' 封装初始化 component function ??? 所需要的参数
                ....
                log: tensorflow/core/common_runtime/process_function_library_runtime.cc:1150] Start instantiating component function __wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0_4619141710927497548_0 on device /job:localhost/replica:0/task:0/device:CPU:0
                    'DebugString(shard)' log :
                        __wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0_4619141710927497548_0(input:double) -> (output_retval:double) {
                          _EagerConst = _EagerConst[T=double, _XlaHasReferenceVars=false, device=CPU:0](input)
                          return output_retval = _EagerConst:output:0
                        }
                :1155 'auto done = [this, status, unique_name, comp_data, component_handle,' 初始化 component function 成功后的回调函数
                  回调函数主要是更新 status 和其它状态,并打印如下log
                  log: core/common_runtime/process_function_library_runtime.cc:1150] Start instantiating component function __wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0_4619141710927497548_0 on device /job:localhost/replica:0/task:0/device:CPU:0
                :1175 'if (flr != nullptr) {' 如果 'flr = GetFLR(opts.target)' 非空,
                  则 // Initialize local function synchronously. > 'Status s = flr->Instantiate(unique_name, attrs, opts, component_handle)' .... ???
                    是 tensorflow/core/common_runtime/function.cc:745.FunctionLibraryRuntimeImpl::Instantiate() ???
                    还是 tensorflow/core/common_runtime/function.cc:209.FunctionLibraryRuntimeOverlay::Instantiate() ???
                    但 FunctionLibraryRuntimeOverlay::Instantiate() 是不是通过 'base_flr_->Instantiate(' 最终还是会调到 FunctionLibraryRuntimeImpl::Instantiate()
                    tensorflow/core/common_runtime/function.cc:745.FunctionLibraryRuntimeImpl::Instantiate()
                      :808 'FunctionDefToBody(*fdef, attrs, lib_def, &fbody)'>:677.FunctionLibraryRuntimeImpl::FunctionDefToBody()
                        tensorflow/core/common_runtime/function_def_utils.cc:29.FunctionDefToBodyHelper()
                          tensorflow/core/framework/function.cc:737.InstantiateFunction()
                            log: tensorflow/core/framework/function.cc:742] Instantiate function definition: name=__wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0_4619141710927497548_0 #input_args=1 #output_args=1 #control_output=0
                                  __wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0_4619141710927497548_0(input:double) -> (output_retval:double) {
                                    _EagerConst = _EagerConst[T=double, _XlaHasReferenceVars=false, device=CPU:0](input)
                                    return output_retval = _EagerConst:output:0
                                  }
                            ??? log: tensorflow/core/graph/graph.cc:529] AddNode: no type constructor for _SOURCE
                                AddNode: no type constructor for _SINK
                                AddNode: no type constructor for input
                                AddNode: no type constructor for _EagerConst
                                AddNode: no type constructor for output_retval_RetVal
                :1182 否则
                  // Initialize remote function asynchronously. > 'InstantiateRemote(unique_name, attrs, opts, component_handle, done)' .... ???
            :1194 '*handle = AddMultiDeviceHandle(std::move(data), function_key)' ???
            log: tensorflow/core/common_runtime/process_function_library_runtime.cc:1195] Instantiated MultiDevice function "__wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:CPU:0" with handle 1
            .... ??? 处理不是 is_multi_device_function 的情况
          回到 common_runtime\eager\kernel_and_device.cc:241 kernel_and_device.cc:139.KernelAndDeviceFunc::InstantiateFunc()
          'return pflr_->IsCrossProcess(handle_, &is_cross_process_)' ???
        kernel_and_device.cc:249 'return pflr_->GetOutputDevices(handle_, &output_devices_)' ???
      :1247 对于 'if (op->is_function())' 好像是走else块???
    :1433 ??? 'status = GetOrCreateKernelAndDevice(op, retvals, num_retvals, &kernel)' 这个GetOrCreateKernelAndDevice有没有被调?
    :1439 'ValidateInputTypeAndPlacement(&ctx, op, kernel)' >tensorflow\core\common_runtime\eager\execute.cc:208
      // `op_device_name` the name of the device on which the op will run, if any. // For functions running using function library runtime, the device can be // unspecified.
      ....
      log: common_runtime/eager/execute.cc:245] !is_function: 0
           common_runtime/eager/execute.cc:246] handle->Type(): 0
      ....
    ....
    log: common_runtime/eager/execute.cc:1445] Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0
    :1449 'AddOrExecuteNode(std::move(kernel), op, retvals)' TODO









TODO:
整理注册机制,以及能学到的.比如宏如何剥离Node,node和device,kernel的关系如何定义等等
op, node, kernle, device, func之间的关系

        
